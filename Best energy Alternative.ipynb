{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cell 0 — Imports + financial helper functions (the “accounting layer”)\n\nThis cell sets up the Python environment and defines the *financial math* that later converts an hourly storage dispatch (which produces euros per hour) into a **net present value (NPV)** over many years.\n\n## What happens here\n- **Imports**: `numpy` (numerical arrays), `pandas` (tables/time series), `matplotlib` (plots), and `gurobipy` (Gurobi solver interface).\n- **Hard stop if Gurobi is missing**: the optimisation model is solved with Gurobi; without it the notebook cannot run.\n- **Defines helper functions** used by the optimisation objective:\n  - `pw_factor(r, H)`: the present-worth factor \\(P/A\\) that converts a constant annual cashflow into its present value:\n    \\[\n    P/A(r,H) = \\sum_{k=1}^{H}\\frac{1}{(1+r)^k} = \\frac{1-(1+r)^{-H}}{r}.\n    \\]\n  - `pw_factor_shifted(r, H, start_delay)`: same factor, but cashflows start after a delay (e.g., commissioning delay).\n  - `pw_factor_growth_shifted(r, g, H, start_delay)`: present-worth factor when the annual cashflow grows by a constant drift \\(g\\) (used to model long-run price drift).\n  - `as_2d(a)`: forces vectors into a 2D array shape \\((S,T)\\) so “scenario × time” operations are consistent.\n  - `build_capex_multiplier_series(...)`: builds a year-by-year multiplier vector that tells the model **when CAPEX is paid** (multi‑year construction), **when it repeats** (replacements), and **how it changes by year** (either a constant escalation rate or an explicit year-index vector).\n\n## Why this cell exists (conceptually)\nYour optimisation has two time scales:\n1. **Operational**: hourly charging/discharging decisions over one representative year (\\(T=8760\\)).\n2. **Financial**: investment, O&M, subsidies and salvage over a project horizon of \\(H\\) years.\n\nThe helper functions are what let the model say:\n- “This dispatch makes X €/year in *expected* operating profit”  \n  **and then**\n- “Over H years, discounted at rate r, that is worth PV = … € today.”\n\nThis separation is important: it keeps the optimisation linear and interpretable, while still producing NPV (the metric you compare technologies on).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "783ea46f-4a01-4b98-b771-5e62c3b7f4ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# 0) Imports\n",
    "# =========================\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "try:\n",
    "    import gurobipy as gp\n",
    "    from gurobipy import GRB\n",
    "except Exception as e:\n",
    "    raise RuntimeError(\n",
    "        \"This notebook cell requires gurobipy + a working Gurobi license.\\n\"\n",
    "        f\"Import error: {repr(e)}\"\n",
    "    )\n",
    "\n",
    "# -------------------------\n",
    "# Helpers\n",
    "# -------------------------\n",
    "def pw_factor(r: float, H: int) -> float:\n",
    "    \"\"\"Present-worth factor P/A(r,H).\"\"\"\n",
    "    if H <= 0:\n",
    "        return 0.0\n",
    "    if abs(r) < 1e-12:\n",
    "        return float(H)\n",
    "    return (1.0 - (1.0 + r) ** (-H)) / r\n",
    "\n",
    "def as_2d(a):\n",
    "    a = np.asarray(a)\n",
    "    if a.ndim == 1:\n",
    "        return a[None, :]\n",
    "    return a\n",
    "\n",
    "# -------------------------\n",
    "# Cashflow helpers (construction delays, drift, CAPEX schedules)\n",
    "# -------------------------\n",
    "def pw_factor_shifted(r: float, H: int, start_delay_years: int = 0) -> float:\n",
    "    \"\"\"Present-worth factor for an annual cashflow received at end of each year,\n",
    "    starting after `start_delay_years` full years (i.e., first cashflow at end of year start_delay_years+1).\"\"\"\n",
    "    start_delay_years = int(max(0, start_delay_years))\n",
    "    if H <= start_delay_years:\n",
    "        return 0.0\n",
    "    return (1.0 + r) ** (-start_delay_years) * pw_factor(r, H - start_delay_years)\n",
    "\n",
    "def pw_factor_growth_shifted(r: float, g: float, H: int, start_delay_years: int = 0) -> float:\n",
    "    \"\"\"Present-worth factor for an annual cashflow received at end of each year that grows by (1+g) per year.\n",
    "    Growth applies to the *cashflow level* in year k relative to year 0 (k=0..H-1).\n",
    "    Cashflows start after `start_delay_years` full years (first at end of year start_delay_years+1).\"\"\"\n",
    "    start_delay_years = int(max(0, start_delay_years))\n",
    "    if H <= start_delay_years:\n",
    "        return 0.0\n",
    "\n",
    "    # PV = sum_{k=start_delay..H-1} (1+g)^k / (1+r)^{k+1} = (1/(1+r)) * sum_{k=start_delay..H-1} q^k\n",
    "    if abs(r) < 1e-12:\n",
    "        # r ~ 0: PV = sum_{k=start_delay..H-1} (1+g)^k\n",
    "        if abs(g) < 1e-12:\n",
    "            return float(H - start_delay_years)\n",
    "        return ((1.0 + g) ** start_delay_years) * ((1.0 + g) ** (H - start_delay_years) - 1.0) / g\n",
    "\n",
    "    q = (1.0 + g) / (1.0 + r)\n",
    "    if abs(q - 1.0) < 1e-12:\n",
    "        # q ~ 1 => each term is ~1/(1+r); start_delay adds a q^start_delay factor ~1\n",
    "        return (H - start_delay_years) / (1.0 + r)\n",
    "\n",
    "    geom = (q ** start_delay_years) * (1.0 - q ** (H - start_delay_years)) / (1.0 - q)\n",
    "    return geom / (1.0 + r)\n",
    "\n",
    "def build_capex_multiplier_series(\n",
    "    H: int,\n",
    "    lifetime_years: int | None,\n",
    "    construction_years: int = 0,\n",
    "    capex_payment_profile: list[float] | None = None,\n",
    "    replacement_required: bool = True,\n",
    "    capex_escalation_annual: float = 0.0,\n",
    "    capex_index_by_year: np.ndarray | None = None,\n",
    ") -> np.ndarray:\n",
    "    \"\"\"Return an array mult[y] such that:\n",
    "\n",
    "        PV(CAPEX) = CAPEX_base * sum_y mult[y] / (1+r)^y.\n",
    "\n",
    "    Where:\n",
    "    - CAPEX_base is the (discounted/grant-adjusted) CAPEX associated with the chosen design (E,Pch,Pdis),\n",
    "      stated in *base-year* euros.\n",
    "    - construction_years spreads each build over multiple years (payments at the *start* of each year y).\n",
    "    - lifetime_years triggers reinvestment every `lifetime_years` (if replacement_required=True).\n",
    "    - capex_escalation_annual scales replacement CAPEX at install year y0 by (1+capex_escalation_annual)^y0.\n",
    "\n",
    "    If `capex_index_by_year` is provided, it overrides the escalation logic and applies a year-specific\n",
    "    multiplier to each payment year y:\n",
    "        mult[y] += frac * capex_index_by_year[y]\n",
    "    This supports arbitrary CAPEX paths (e.g., learning curves, discrete policy changes).\n",
    "    The array must have length >= H and be relative to the base year (base year multiplier = 1.0).\n",
    "    \"\"\"\n",
    "    if construction_years <= 0:\n",
    "        capex_payment_profile = [1.0]\n",
    "    else:\n",
    "        if capex_payment_profile is None:\n",
    "            capex_payment_profile = [1.0 / construction_years] * construction_years\n",
    "        else:\n",
    "            # Normalize if slightly off due to rounding\n",
    "            s = float(sum(capex_payment_profile))\n",
    "            if s <= 0:\n",
    "                raise ValueError(\"capex_payment_profile must sum to a positive value.\")\n",
    "            capex_payment_profile = [float(x) / s for x in capex_payment_profile]\n",
    "\n",
    "    if (capex_index_by_year is not None) and (len(capex_index_by_year) < H):\n",
    "        raise ValueError(\"capex_index_by_year must have length at least H.\")\n",
    "\n",
    "    if (lifetime_years is None) or (not replacement_required) or (lifetime_years <= 0):\n",
    "        install_years = [0]\n",
    "    else:\n",
    "        L = int(lifetime_years)\n",
    "        install_years = list(range(0, H, L))\n",
    "\n",
    "    mult = np.zeros(H, dtype=float)\n",
    "    for y0 in install_years:\n",
    "        if capex_index_by_year is None:\n",
    "            install_multiplier = (1.0 + capex_escalation_annual) ** y0\n",
    "            for j, frac in enumerate(capex_payment_profile):\n",
    "                y = y0 + j\n",
    "                if y >= H:\n",
    "                    break\n",
    "                mult[y] += float(frac) * install_multiplier\n",
    "        else:\n",
    "            # Apply the index at the *payment year* (not the install year),\n",
    "            # which matches how contracts/invoices are typically indexed.\n",
    "            for j, frac in enumerate(capex_payment_profile):\n",
    "                y = y0 + j\n",
    "                if y >= H:\n",
    "                    break\n",
    "                mult[y] += float(frac) * float(capex_index_by_year[y])\n",
    "    return mult\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cell 1 — Build a 8760-hour “typical year” production profile from a (month, hour) lookup table\n\nThis cell defines a utility function that converts a compact seasonal profile (12 months × 24 hours = 288 rows) into a full **hour-by-hour** time series of length 8760 (one non‑leap year).\n\n## What the function does\n`build_hourly_profile_from_month_hour_csv(...)`:\n1. **Reads a CSV** containing average power values indexed by `(month, hour)`.\n2. **Validates completeness**: it checks that all 288 combinations exist. If any are missing, it stops with an error (this prevents silent gaps later).\n3. **Creates a non-leap-year hourly timestamp index** (e.g., 2021-01-01 .. 2022-01-01, 8760 hours).\n4. **Maps each timestamp to its (month, hour)** and merges with the lookup table.\n5. **Checks for NaNs** after the merge (meaning the mapping failed).\n6. **Returns a NumPy array** of 8760 hourly values, clipped at zero to avoid negative power.\n\n## Why this matters for the optimisation model\nLater, the storage model needs a time series `surplus[t]` that represents *how much power is available for charging* at each hour. For example:\n- If you use a wind farm production profile, `surplus[t]` is “available wind power (or curtailment)”.\n- If you use a price-proxy, `surplus[t]` is “available charging power during low-price hours”.\n\nThis function provides the first option: a realistic *seasonal-and-diurnal* profile that can be used as `surplus`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "95abdafa-ac1d-4d33-8ce7-5362c94531f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_hourly_profile_from_month_hour_csv(\n",
    "    csv_path: str = \"gemini_avg_power_month_hour_2017_2019_long.csv\",\n",
    "    month_col: str = \"month\",\n",
    "    hour_col: str = \"hour\",\n",
    "    value_col: str = \"avg_power\",\n",
    "    base_year: int = 2021,     # non-leap year => 8760 hours\n",
    "    tz: str = \"UTC\",\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Converts a (month, hour)->value table (288 rows) into a chronological 8760-hour profile.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    profile : np.ndarray shape (8760,)\n",
    "        Hourly values for a typical year.\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(csv_path)\n",
    "\n",
    "    required = {month_col, hour_col, value_col}\n",
    "    missing = required - set(df.columns)\n",
    "    if missing:\n",
    "        raise ValueError(f\"Missing columns in {csv_path}: {missing}. Found: {list(df.columns)}\")\n",
    "\n",
    "    df = df[[month_col, hour_col, value_col]].copy()\n",
    "    df[month_col] = df[month_col].astype(int)\n",
    "    df[hour_col] = df[hour_col].astype(int)\n",
    "    df[value_col] = df[value_col].astype(float)\n",
    "\n",
    "    # Ensure full 12x24 coverage\n",
    "    all_pairs = pd.MultiIndex.from_product(\n",
    "        [range(1, 13), range(0, 24)],\n",
    "        names=[month_col, hour_col]\n",
    "    )\n",
    "    df = df.set_index([month_col, hour_col]).reindex(all_pairs)\n",
    "\n",
    "    if df[value_col].isna().any():\n",
    "        missing_pairs = df[df[value_col].isna()].index.tolist()[:10]\n",
    "        raise ValueError(\n",
    "            f\"Incomplete month-hour table in {csv_path}. Missing examples: {missing_pairs}. \"\n",
    "            \"Need all 12*24=288 combinations.\"\n",
    "        )\n",
    "\n",
    "    # Create hourly timestamps for a non-leap year\n",
    "    idx = pd.date_range(\n",
    "        start=f\"{base_year}-01-01\",\n",
    "        end=f\"{base_year+1}-01-01\",\n",
    "        freq=\"h\",\n",
    "        inclusive=\"left\",\n",
    "        tz=tz\n",
    "    )\n",
    "    if len(idx) != 8760:\n",
    "        raise RuntimeError(f\"Expected 8760 hours, got {len(idx)} for base_year={base_year}.\")\n",
    "\n",
    "    tmp = pd.DataFrame({\"ts\": idx})\n",
    "    tmp[\"month\"] = tmp[\"ts\"].dt.month\n",
    "    tmp[\"hour\"] = tmp[\"ts\"].dt.hour\n",
    "\n",
    "    lut = df.reset_index().rename(columns={value_col: \"val\"})\n",
    "    tmp = tmp.merge(lut, on=[\"month\", \"hour\"], how=\"left\")\n",
    "\n",
    "    if tmp[\"val\"].isna().any():\n",
    "        raise RuntimeError(\"Mapping month-hour -> hourly series failed (NaNs after merge).\")\n",
    "\n",
    "    profile = tmp[\"val\"].to_numpy(dtype=float)\n",
    "    profile = np.clip(profile, 0.0, None)\n",
    "    return profile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cell 2 — Load price data, create price scenarios, and define “surplus” charging availability\n\nThis cell turns raw historical day-ahead prices into the model inputs needed for stochastic optimisation:\n- `prices[s,t]`: electricity price for scenario \\(s\\) at hour \\(t\\)\n- `scenario_prob[s]`: probability of each scenario\n- `surplus[s,t]`: the *maximum charging power* available at each hour (per scenario)\n\n## Step-by-step overview\n\n### A) Load and clean the price time series\nThe code reads the combined day-ahead dataset and enforces a clean hourly grid:\n- parse timestamps with timezones,\n- sort and deduplicate,\n- reindex to hourly frequency,\n- fill missing hours (interpolation),\n- ensure each year has exactly 8760 hours (no leap-day).\n\nThis matters because the optimisation model assumes a fixed time index and would otherwise misalign constraints (e.g., SOC dynamics).\n\n### B) Build **pricing scenarios**\nYou can run with different scenario modes (controlled by `SCENARIO_MODE`):\n- **Historical-years mode**: each full year becomes one scenario (empirical distribution).\n- **Synthetic 3-case mode**: creates three stylised scenarios (BEST / NORMAL / BAD).  \n  NORMAL is constructed as a seasonal mean plus block-bootstrap residuals to preserve autocorrelation (so price spikes occur in realistic clusters rather than independently).\n\nThis is the key stochastic element: you are not optimising for a single price path, but for an expected value across multiple plausible price worlds.\n\n### C) Define `year_scale`\nIf you ever run a shorter time horizon (e.g., a subset of hours for testing), `year_scale = 8760/(T·dt)` rescales annual profits so the NPV remains comparable.\n\n### D) Define **surplus charging availability**\nThe model needs a constraint like:\n\\[\n\\text{charge}_{s,t} \\le \\text{surplus}_{s,t}.\n\\]\nThis cell supports two interpretations:\n- **Gemini / profile-based surplus**: surplus comes from a production profile (e.g., wind).\n- **Price-proxy surplus**: surplus is “available during the lowest-price quantile hours” to mimic congestion/curtailment periods.\n\nThe critical modelling point is that `surplus` is not “free energy”; it is a *power limit* on how much charging you are allowed to do. Economic value still comes from price arbitrage and subsidies.\n\n## Outputs created by this cell\nAfter this cell runs, the optimisation has all time-series inputs it needs:\n- `prices` (shape \\(S,T\\))\n- `scenario_prob` (length \\(S\\))\n- `surplus` (shape \\(S,T\\))\n- `dt`, `T`, and the scaling factors used in the NPV objective.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "10ef1a54-06b4-406a-a8f4-3b8beafd47d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scenario mode: synthetic_3cases | scenarios=['BEST_2020', 'NORMAL_SYNTH', 'BAD_2022']\n",
      "prices shape: (S,T)=(3,8760), year_scale=1\n",
      "price stats: min=-384.93, mean=118.27, max=1091.10\n",
      "Estimated price drift (annual): +18.2091%  (override via PRICE_DRIFT_ANNUAL_OVERRIDE)\n",
      "Surplus mode: gemini | surplus shape: (3, 8760)\n",
      "surplus stats: min=266.16, mean=417.05, max=558.43\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# 1) Price scenarios + surplus\n",
    "#\n",
    "# Goal:\n",
    "# - Keep the optimization model at \"one-year resolution\" (T=8760) but allow long horizons (H_years up to 100)\n",
    "# - Provide: (i) scenario year-profiles (best/normal/bad) and (ii) a drift parameter for long-run price level change\n",
    "# - Provide optional explicit multi-year price paths for reporting/plotting (not used directly in the MILP)\n",
    "# =========================\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "dt = 1.0\n",
    "hours_per_year = 8760\n",
    "\n",
    "# -------------------------\n",
    "# Paths (work both in notebook folder and in /mnt/data)\n",
    "# -------------------------\n",
    "def _resolve_path(p: str) -> str:\n",
    "    pth = Path(p)\n",
    "    if pth.exists():\n",
    "        return str(pth)\n",
    "    alt = Path(\"/mnt/data\") / p\n",
    "    if alt.exists():\n",
    "        return str(alt)\n",
    "    return str(pth)  # let pandas raise a clear error\n",
    "\n",
    "price_path = _resolve_path(\"day_ahead_prices_2020_2025_combined.csv\")\n",
    "ts_col = \"timestamp\"\n",
    "price_col = \"price\"\n",
    "\n",
    "# Gemini profile (month, hour) -> 8760 hourly profile\n",
    "gemini_power_path = _resolve_path(r\"C:\\Users\\User\\OneDrive\\Univerity of Twente\\IEM\\Module 6\\CM&E\\Project\\CM-E-Project\\gemini_avg_power_month_hour_2017_2019_long.csv\")\n",
    "\n",
    "# -------------------------\n",
    "# Test mode (optional)\n",
    "# -------------------------\n",
    "TEST_MODE = False          # True => use a short window\n",
    "TEST_START_UTC = \"2022-01-03 00:00:00\"  # inclusive, UTC\n",
    "TEST_DAYS = 7              # 7 days = 168 hours\n",
    "TEST_TILE_TO_YEAR = False  # True => repeat the short window to 8760 hours\n",
    "\n",
    "# -------------------------\n",
    "# Scenario mode\n",
    "# -------------------------\n",
    "# \"historical_years\"   => each full calendar year in the dataset becomes a scenario\n",
    "# \"synthetic_3cases\"   => build best/normal/bad year-profiles + estimate drift for long horizons\n",
    "SCENARIO_MODE = \"synthetic_3cases\"\n",
    "\n",
    "# Manual override if you want (example: -0.03 for -3%/yr)\n",
    "PRICE_DRIFT_ANNUAL_OVERRIDE = None\n",
    "\n",
    "# Volatility scaling inside each scenario profile (keeps seasonality, changes sd)\n",
    "BEST_VOL_MULT = 0.85\n",
    "NORMAL_VOL_MULT = 1.00\n",
    "BAD_VOL_MULT = 1.35\n",
    "\n",
    "# Optional level shifts (€/MWh) applied after volatility scaling\n",
    "BEST_LEVEL_SHIFT = 0.0\n",
    "NORMAL_LEVEL_SHIFT = 0.0\n",
    "BAD_LEVEL_SHIFT = 0.0\n",
    "\n",
    "# Scenario probabilities (must sum to 1)\n",
    "SCENARIO_PROB = {\"BEST\": 1/3, \"NORMAL\": 1/3, \"BAD\": 1/3}\n",
    "\n",
    "# -------------------------\n",
    "# Load and clean prices (hourly grid, interpolate gaps, drop Feb-29)\n",
    "# -------------------------\n",
    "dfp = pd.read_csv(r\"C:\\Users\\User\\OneDrive\\Univerity of Twente\\IEM\\Module 6\\CM&E\\Project\\CM-E-Project\\day_ahead_prices_2020_2025_combined.csv\")\n",
    "dfp[ts_col] = pd.to_datetime(dfp[ts_col], utc=True, errors=\"coerce\")\n",
    "dfp = dfp.dropna(subset=[ts_col, price_col]).sort_values(ts_col).set_index(ts_col)\n",
    "\n",
    "# If testing, cut down early (faster)\n",
    "if TEST_MODE:\n",
    "    start_ts = pd.Timestamp(TEST_START_UTC, tz=\"UTC\")\n",
    "    end_ts = start_ts + pd.Timedelta(days=TEST_DAYS)\n",
    "    dfp = dfp[(dfp.index >= start_ts) & (dfp.index < end_ts)]\n",
    "\n",
    "price_series = (\n",
    "    dfp[price_col].astype(float)\n",
    "    .resample(\"h\").mean()\n",
    "    .interpolate(\"time\")\n",
    ")\n",
    "\n",
    "# Drop Feb 29 so any \"calendar year\" is exactly 8760 hours\n",
    "is_feb29 = (price_series.index.month == 2) & (price_series.index.day == 29)\n",
    "price_series = price_series[~is_feb29]\n",
    "\n",
    "# -------------------------\n",
    "# Build scenario year-profiles\n",
    "# -------------------------\n",
    "def _extract_full_year_arrays(ps: pd.Series) -> dict[int, np.ndarray]:\n",
    "    years = sorted(ps.index.year.unique())\n",
    "    out = {}\n",
    "    for y in years:\n",
    "        ys = ps[ps.index.year == y]\n",
    "        if len(ys) == hours_per_year:\n",
    "            out[int(y)] = ys.to_numpy(dtype=float)\n",
    "    return out\n",
    "\n",
    "def _robust_drift_estimate(year_means: pd.Series) -> float:\n",
    "    '''\n",
    "    Estimate annual drift as a geometric growth rate from annual average prices.\n",
    "    Uses a robust outlier filter (MAD) so a single spike-year (e.g., 2022) doesn't dominate.\n",
    "    Returns g such that expected level scales by (1+g)^year.\n",
    "    '''\n",
    "    if len(year_means) < 2:\n",
    "        return 0.0\n",
    "\n",
    "    med = float(year_means.median())\n",
    "    mad = float(np.median(np.abs(year_means.values - med)))\n",
    "    if mad <= 1e-12:\n",
    "        keep = year_means\n",
    "    else:\n",
    "        sigma = 1.4826 * mad\n",
    "        keep = year_means[np.abs(year_means - med) <= 3.0 * sigma]\n",
    "        if len(keep) < 2:\n",
    "            keep = year_means\n",
    "\n",
    "    x = (keep.index.to_numpy(dtype=float) - float(keep.index.min()))\n",
    "    y = np.log(np.clip(keep.to_numpy(dtype=float), 1e-6, None))\n",
    "    slope = float(np.polyfit(x, y, 1)[0])\n",
    "    return float(np.exp(slope) - 1.0)\n",
    "\n",
    "def _vol_level_transform(p: np.ndarray, vol_mult: float, level_shift: float) -> np.ndarray:\n",
    "    mu = float(np.mean(p))\n",
    "    return (mu + vol_mult * (p - mu) + level_shift).astype(float)\n",
    "\n",
    "full_years = _extract_full_year_arrays(price_series)\n",
    "\n",
    "if TEST_MODE and not TEST_TILE_TO_YEAR:\n",
    "    # One scenario = the week (T=168)\n",
    "    prices = price_series.to_numpy(dtype=float)[None, :]\n",
    "    kept_years = [f\"TEST_WEEK_FROM_{TEST_START_UTC}\"]\n",
    "    scenario_names = kept_years\n",
    "    price_drift_annual = 0.0\n",
    "else:\n",
    "    if TEST_MODE and TEST_TILE_TO_YEAR:\n",
    "        # Repeat test window to 8760 (index no longer needed for optimization)\n",
    "        reps = hours_per_year // len(price_series)\n",
    "        rem = hours_per_year - reps * len(price_series)\n",
    "        tiled = np.concatenate([\n",
    "            np.tile(price_series.to_numpy(float), reps),\n",
    "            price_series.to_numpy(float)[:rem],\n",
    "        ])\n",
    "        prices = tiled[None, :]\n",
    "        kept_years = [f\"TEST_TILED_FROM_{TEST_START_UTC}\"]\n",
    "        scenario_names = kept_years\n",
    "        price_drift_annual = 0.0\n",
    "\n",
    "    else:\n",
    "        if len(full_years) == 0:\n",
    "            raise ValueError(\"No full 8760-hour years found in the price dataset after cleaning.\")\n",
    "\n",
    "        year_means = pd.Series({y: float(np.mean(arr)) for y, arr in full_years.items()}).sort_index()\n",
    "\n",
    "        # Identify best and bad years from available full years\n",
    "        bad_year = 2022 if 2022 in full_years else int(year_means.idxmax())\n",
    "        best_year = int(year_means.idxmin())\n",
    "\n",
    "        if SCENARIO_MODE == \"historical_years\":\n",
    "            kept_years = sorted(full_years.keys())\n",
    "            prices = np.vstack([full_years[y] for y in kept_years])\n",
    "            scenario_names = [str(y) for y in kept_years]\n",
    "\n",
    "        elif SCENARIO_MODE == \"synthetic_3cases\":\n",
    "            # Build NORMAL from a mean seasonal profile (hour-of-year) + a block-bootstrap residual.\n",
    "            years_for_normal = [y for y in full_years.keys() if y != bad_year] or list(full_years.keys())\n",
    "            mat = np.vstack([full_years[y] for y in years_for_normal])  # (Ny,8760)\n",
    "            seasonal_mean = mat.mean(axis=0)\n",
    "            resid = mat - seasonal_mean  # (Ny,8760)\n",
    "\n",
    "            rng = np.random.default_rng(42)\n",
    "            block = 24  # daily blocks\n",
    "            n_blocks = hours_per_year // block  # 365\n",
    "            resid_blocks = resid.reshape(resid.shape[0], n_blocks, block)\n",
    "            pick_y = rng.integers(0, resid.shape[0], size=n_blocks)\n",
    "            pick_b = rng.integers(0, n_blocks, size=n_blocks)\n",
    "            boot = resid_blocks[pick_y, pick_b].reshape(-1)\n",
    "\n",
    "            normal_raw = seasonal_mean + boot\n",
    "            best_raw = full_years[best_year]\n",
    "            bad_raw = full_years[bad_year]\n",
    "\n",
    "            best = _vol_level_transform(best_raw, BEST_VOL_MULT, BEST_LEVEL_SHIFT)\n",
    "            normal = _vol_level_transform(normal_raw, NORMAL_VOL_MULT, NORMAL_LEVEL_SHIFT)\n",
    "            bad = _vol_level_transform(bad_raw, BAD_VOL_MULT, BAD_LEVEL_SHIFT)\n",
    "\n",
    "            prices = np.vstack([best, normal, bad])\n",
    "            kept_years = [f\"BEST_{best_year}\", \"NORMAL_SYNTH\", f\"BAD_{bad_year}\"]\n",
    "            scenario_names = kept_years\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown SCENARIO_MODE={SCENARIO_MODE}\")\n",
    "\n",
    "        # Drift estimate (unless overridden)\n",
    "        drift_est = _robust_drift_estimate(year_means)\n",
    "        price_drift_annual = float(drift_est if PRICE_DRIFT_ANNUAL_OVERRIDE is None else PRICE_DRIFT_ANNUAL_OVERRIDE)\n",
    "\n",
    "# Scenario probabilities vector aligned with 'scenario_names'\n",
    "if (not TEST_MODE) and (SCENARIO_MODE == \"synthetic_3cases\"):\n",
    "    scenario_prob = np.array([SCENARIO_PROB[\"BEST\"], SCENARIO_PROB[\"NORMAL\"], SCENARIO_PROB[\"BAD\"]], dtype=float)\n",
    "    scenario_prob = scenario_prob / scenario_prob.sum()\n",
    "else:\n",
    "    S_tmp = int(np.asarray(prices).shape[0])\n",
    "    scenario_prob = np.ones(S_tmp, dtype=float) / S_tmp\n",
    "\n",
    "prices = np.asarray(prices, dtype=float)\n",
    "S, T = prices.shape\n",
    "year_scale = float(hours_per_year / (T * dt))  # =1.0 for T=8760; >1.0 for test windows\n",
    "\n",
    "print(f\"Scenario mode: {SCENARIO_MODE} | scenarios={scenario_names}\")\n",
    "print(f\"prices shape: (S,T)=({S},{T}), year_scale={year_scale:.6g}\")\n",
    "print(f\"price stats: min={prices.min():.2f}, mean={prices.mean():.2f}, max={prices.max():.2f}\")\n",
    "print(f\"Estimated price drift (annual): {price_drift_annual:+.4%}  (override via PRICE_DRIFT_ANNUAL_OVERRIDE)\")\n",
    "\n",
    "# -------------------------\n",
    "# Surplus (choose proxy from low prices OR Gemini profile)\n",
    "# -------------------------\n",
    "def make_surplus_proxy_from_prices(prices_ST: np.ndarray, surplus_max_mw: float = 50.0, low_quantile: float = 0.20) -> np.ndarray:\n",
    "    thresh = np.quantile(prices_ST, low_quantile, axis=1, keepdims=True)\n",
    "    return np.where(prices_ST <= thresh, surplus_max_mw, 0.0).astype(float)\n",
    "\n",
    "# Build Gemini 8760-hour profile (avg power by month-hour)\n",
    "gemini_profile = build_hourly_profile_from_month_hour_csv(\n",
    "    gemini_power_path,\n",
    "    month_col=\"month\",\n",
    "    hour_col=\"hour\",\n",
    "    value_col=\"avg_power\",\n",
    "    base_year=2021,\n",
    "    tz=\"UTC\",\n",
    ")\n",
    "gemini_profile = np.asarray(gemini_profile, dtype=float).ravel()\n",
    "\n",
    "if len(gemini_profile) != hours_per_year:\n",
    "    raise ValueError(f\"Gemini profile length {len(gemini_profile)} must be {hours_per_year} after build.\")\n",
    "\n",
    "if T == hours_per_year:\n",
    "    gemini_aligned = gemini_profile\n",
    "else:\n",
    "    gemini_aligned = gemini_profile[:T]\n",
    "\n",
    "curtailment_fraction = 1.0  # set e.g. 0.3 if only 30% is realistically available\n",
    "surplus_gemini_1y = np.clip(curtailment_fraction * gemini_aligned, 0.0, None)\n",
    "\n",
    "# Per-scenario surplus (optionally vary year-to-year)\n",
    "rng = np.random.default_rng(42)\n",
    "year_sigma = 0.10  # 10% multiplicative variation across scenarios\n",
    "scale_factors = rng.normal(1.0, year_sigma, size=(S, 1))\n",
    "\n",
    "surplus_gemini = np.clip(np.tile(surplus_gemini_1y[None, :], (S, 1)) * scale_factors, 0.0, None)\n",
    "surplus_proxy = make_surplus_proxy_from_prices(prices, surplus_max_mw=50.0, low_quantile=0.20)\n",
    "\n",
    "SURPLUS_MODE = \"gemini\"  # \"gemini\" or \"proxy\"\n",
    "surplus = surplus_gemini if SURPLUS_MODE.lower() == \"gemini\" else surplus_proxy\n",
    "\n",
    "print(f\"Surplus mode: {SURPLUS_MODE} | surplus shape: {surplus.shape}\")\n",
    "print(f\"surplus stats: min={surplus.min():.2f}, mean={surplus.mean():.2f}, max={surplus.max():.2f}\")\n",
    "\n",
    "# -------------------------\n",
    "# Optional helper: explicit multi-year hourly price paths (for reporting/plots).\n",
    "# Not used directly by the MILP (keeps the optimization size manageable for H_years up to 100).\n",
    "# -------------------------\n",
    "def generate_multi_year_price_cube(\n",
    "    base_prices_ST: np.ndarray,\n",
    "    H_years: int,\n",
    "    price_drift_annual: float = 0.0,\n",
    "    vol_growth_annual: float = 0.0,\n",
    ") -> np.ndarray:\n",
    "    '''\n",
    "    Returns price_cube[S,H,T]. Year y applies:\n",
    "      level_y = (1+price_drift_annual)^y\n",
    "      vol_y   = (1+vol_growth_annual)^y\n",
    "      p_y,t = level_y * (mu + vol_y*(p0_t - mu))\n",
    "    where mu is the within-year mean of p0 in each scenario.\n",
    "    '''\n",
    "    base_prices_ST = np.asarray(base_prices_ST, dtype=float)\n",
    "    S0, T0 = base_prices_ST.shape\n",
    "    H_years = int(H_years)\n",
    "    mu = base_prices_ST.mean(axis=1, keepdims=True)  # (S,1)\n",
    "    centered = base_prices_ST - mu\n",
    "    cube = np.zeros((S0, H_years, T0), dtype=float)\n",
    "    for y in range(H_years):\n",
    "        level = (1.0 + price_drift_annual) ** y\n",
    "        vol = (1.0 + vol_growth_annual) ** y\n",
    "        cube[:, y, :] = level * (mu + vol * centered)\n",
    "    return cube\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cell 3 — Technology parameterisation (costs, efficiencies, subsidies, and CAPEX paths)\n\nThis cell defines the *technology catalogue* that the optimisation will evaluate. Each entry in `TECH` is a complete set of parameters that lets the solver:\n1. choose an optimal design size (energy capacity \\(E\\), charge power \\(P^{ch}\\), discharge power \\(P^{dis}\\)),\n2. operate it hourly under each price scenario, and\n3. compute an NPV over \\(H\\) years.\n\n## A) Subsidy configuration\nThis cell encodes the subsidy rules you collected as *model-ready parameters*:\n- **Hydropower (SDE++)**: a fixed €/kWh paid on generated electricity for 15 years, converted to €/MWh and applied to discharged energy.\n- **Hydrogen (SDE++)**: a fixed €/kWh_HHV on hydrogen output for 15 years, converted to €/MWh_HHV and applied to produced hydrogen energy (HHV basis).\n- **EIA (tax deduction)**: represented as an “effective CAPEX discount factor” (a pragmatic modelling approximation).\n- **SPRILA (battery)**: represented as a CAPEX grant €/kWh with a cap in euros (converted to €/MWh and applied as a min(rate·E, cap)).\n\nThe key point: subsidies appear directly in the objective function as cash inflows that depend on dispatch (for production subsidies) or investment size (for CAPEX grants).\n\n## B) Efficiency interpretation (avoiding a common modelling error)\nMany sources report **round-trip efficiency**. Your model uses two efficiencies:\n\\[\n\\eta_{RT} = \\eta_{ch}\\cdot\\eta_{dis}.\n\\]\nSo if the document says “90% round-trip” and you set both legs to 0.90, you would accidentally model 81%.  \nThis cell therefore converts round-trip efficiency into per-leg values using:\n\\[\n\\eta_{ch}=\\eta_{dis}=\\sqrt{\\eta_{RT}}.\n\\]\n\n## C) CAPEX that changes over time (component-aware)\nThis notebook supports CAPEX variation in two ways:\n- a constant escalation rate (`capex_escalation_annual`), *or*\n- explicit year-by-year **index vectors**.\n\nImportantly, this version is **component-aware**: you can index energy CAPEX (€/MWh) differently from power CAPEX (€/MW). That matters because learning curves and supply-chain effects often differ between:\n- storage medium (tanks, caverns, battery cells) and\n- power conversion equipment (inverters, turbines, electrolysers).\n\n## D) The `TECH` dictionary structure\nFor each technology you specify:\n- **physical performance**: `eta_ch`, `eta_dis`, `self_dis`\n- **design bounds**: `Emax`, `Pch_max`, `Pdis_max`\n- **costs**: `capex_E`, `capex_Pch`, `capex_Pdis`, fixed O&M, variable O&M\n- **subsidy parameters**\n- **lifetime and replacement settings**\n- **construction timing**: multi-year CAPEX payments and commissioning delay\n\nThis creates an explicit, auditable mapping from “technology assumptions” to “optimisation inputs”, which is essential for transparent comparison and later sensitivity analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "86acf34b-e9f3-4cb3-b178-99bcc5eb6320",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# 2) Technology data\n",
    "#    NOTE: Some parameters are filled from your \"storage capacity alternatives\" document.\n",
    "#    Remaining items are explicitly tagged as # STILL_PLACEHOLDER.\n",
    "# =========================\n",
    "\n",
    "# --- Subsidy values (configurable) ---\n",
    "# Select the year and the specific subsidy *type* you want to analyse.\n",
    "# All rates are stored in €/kWh (or €/kWh_HHV for H2) and converted to the model units.\n",
    "\n",
    "SUBSIDY_YEAR = \"2024\"  # \"2023\" or \"2024\" (extend if you add more years)\n",
    "\n",
    "# Hydropower (SDE++) – duration 15 years\n",
    "# Types:\n",
    "#   - \"drop_gt_50cm\":        drop height > 50 cm\n",
    "#   - \"fish_friendly_retro\": renovation / fish-friendly turbines\n",
    "#   - \"drop_lt_50cm\":        drop height < 50 cm (tides / movement)\n",
    "HYDRO_SUB_EUR_PER_KWH = {\n",
    "    \"2023\": {\n",
    "        \"drop_gt_50cm\": 0.1709,\n",
    "        \"fish_friendly_retro\": 0.1225,\n",
    "        # \"drop_lt_50cm\": not provided for 2023 in your notes\n",
    "    },\n",
    "    \"2024\": {\n",
    "        \"drop_gt_50cm\": 0.1693,\n",
    "        \"fish_friendly_retro\": 0.1217,\n",
    "        \"drop_lt_50cm\": 0.2372,\n",
    "    },\n",
    "}\n",
    "HYDRO_SUB_TYPE = \"drop_gt_50cm\"\n",
    "hydro_sub_eur_per_MWh = HYDRO_SUB_EUR_PER_KWH[SUBSIDY_YEAR][HYDRO_SUB_TYPE] * 1000.0  # €/MWh_e discharged\n",
    "\n",
    "\n",
    "# Hydrogen (SDE++) – duration 15 years\n",
    "# Rates are in €/kWh_HHV H2 produced.\n",
    "H2_SUB_EUR_PER_KWH_HHV = {\n",
    "    \"from_waste\": 0.0517,\n",
    "    \"grid_connected_electrolysis\": 0.3796,\n",
    "    \"direct_line_wind_100MW\": 0.2727,\n",
    "    \"direct_line_solar_100MW\": 0.4427,\n",
    "    \"direct_line_wind100_solar100_combined_cable_100MW\": 0.2482,\n",
    "    \"ppa_offshore_wind\": 0.4082,\n",
    "}\n",
    "H2_SUB_TYPE = \"grid_connected_electrolysis\"\n",
    "h2_sub_eur_per_MWh_HHV = H2_SUB_EUR_PER_KWH_HHV[H2_SUB_TYPE] * 1000.0  # €/MWh_HHV produced\n",
    "\n",
    "\n",
    "# EIA (Energy Investment Deduction) – modelled as an *effective CAPEX discount*\n",
    "# Your notes: \"on average this is a ~10% advantage\" (via reduced taxes).\n",
    "EIA_ENABLED = True\n",
    "EIA_EFFECTIVE_DISCOUNT = 0.10  # 10% CAPEX advantage proxy\n",
    "\n",
    "\n",
    "# SPRILA – stationary / integrated battery subsidy (only relevant for Battery tech here)\n",
    "# Choose company class:\n",
    "#   - \"sme\": 100 €/kWh\n",
    "#   - \"big\":  70 €/kWh\n",
    "# Cap: 350,000 € (per your notes) for the programme year.\n",
    "SPRILA_ENABLED = True\n",
    "SPRILA_COMPANY_CLASS = \"big\"  # \"sme\" or \"big\"\n",
    "SPRILA_GRANT_EUR_PER_KWH = {\"sme\": 100.0, \"big\": 70.0}[SPRILA_COMPANY_CLASS]\n",
    "sprila_grant_per_MWh_store = (SPRILA_GRANT_EUR_PER_KWH * 1000.0) if SPRILA_ENABLED else 0.0  # €/MWh_store\n",
    "sprila_grant_cap_total = 350_000.0 if SPRILA_ENABLED else 0.0\n",
    "\n",
    "\n",
    "# Windfarm neighbourhood/environment fund cost – OPTIONAL (only if you model a wind-owner perspective)\n",
    "# Your notes: 0.40–0.50 €/MWh generated. In this notebook, charging is restricted to 'surplus',\n",
    "# so if surplus is interpreted as wind generation owned by the investor, you can apply it as an\n",
    "# additional marginal cost on charging energy.\n",
    "APPLY_WIND_ENV_FUND_TO_SURPLUS = False\n",
    "WIND_ENV_FUND_EUR_PER_MWH = 0.45  # midpoint of 0.40–0.50 €/MWh\n",
    "SURPLUS_CHARGE_EXTRA_COST_EUR_PER_MWH = float(WIND_ENV_FUND_EUR_PER_MWH) if APPLY_WIND_ENV_FUND_TO_SURPLUS else 0.0\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# Conversions from the \"technologies\" document\n",
    "# -------------------------\n",
    "# The document often reports *round-trip* efficiency. In this model:\n",
    "#   round_trip_efficiency = eta_ch * eta_dis\n",
    "# If only round-trip efficiency is known, assume symmetric legs:\n",
    "#   eta_ch = eta_dis = sqrt(round_trip_efficiency)\n",
    "\n",
    "# PHS efficiency ~90% (document).\n",
    "phs_eta_rt = 0.90\n",
    "phs_eta = float(np.sqrt(phs_eta_rt))\n",
    "\n",
    "# Flywheel efficiency 85–95% (document); use midpoint 90%.\n",
    "fly_eta_rt = 0.90\n",
    "fly_eta = float(np.sqrt(fly_eta_rt))\n",
    "\n",
    "# Flywheel investment cost (document Table 1): €6000/kWh (energy) and €1000/(kW) (power)\n",
    "# (Table header is [kW]; the row label shows €1000/kWh, which appears to be a unit typo in the figure.\n",
    "#  We treat it as €1000/kW to match the column header.)\n",
    "# Convert to the notebook units: €/MWh and €/MW.\n",
    "fly_capex_E_per_MWh = 6000.0 * 1000.0\n",
    "fly_capex_P_per_MW  = 1000.0 * 1000.0\n",
    "\n",
    "# Flywheel O&M (document Table 1): 1–2% of total investment cost per year.\n",
    "# The model uses fixed O&M as linear terms: fom_E * E + fom_P * (Pch + Pdis).\n",
    "# Use midpoint (1.5%) and apply it to both energy and power CAPEX coefficients.\n",
    "fly_fom_frac = 0.015\n",
    "fly_fom_E_per_MWhyr = fly_fom_frac * fly_capex_E_per_MWh\n",
    "fly_fom_P_per_MWyr  = fly_fom_frac * fly_capex_P_per_MW\n",
    "\n",
    "# Hydrogen storage vessel cost (document): $500–$1000 per kg of stored H2.\n",
    "# This model's E is in MWh_HHV, so convert using HHV ≈ 39.4 kWh/kg (engineering constant).\n",
    "# NOTE: currency-year conversion ($ -> € and base-year escalation) is NOT applied here.\n",
    "h2_vessel_cost_per_kg = 750.0  # midpoint of $500–$1000/kg\n",
    "h2_HHV_kWh_per_kg = 39.4\n",
    "h2_capex_E_per_MWh_HHV = h2_vessel_cost_per_kg / (h2_HHV_kWh_per_kg / 1000.0)\n",
    "\n",
    "\n",
    "TECH = {\n",
    "    \"PHS\": {\n",
    "        \"eta_ch\": phs_eta,           # from doc (converted from round-trip)\n",
    "        \"eta_dis\": phs_eta,          # from doc (converted from round-trip)\n",
    "        \"self_dis\": 0.0,             # STILL_PLACEHOLDER (model assumption; not provided by doc)\n",
    "        \"Emax\": 5000.0,              # STILL_PLACEHOLDER (chosen design upper bound)\n",
    "        \"Pch_max\": 500.0,            # STILL_PLACEHOLDER (chosen design upper bound)\n",
    "        \"Pdis_max\": 500.0,           # STILL_PLACEHOLDER (chosen design upper bound)\n",
    "\n",
    "        # Costs for PHS are NOT provided in your doc in €/MWh and €/MW split:\n",
    "        \"capex_E\": 150000.0,         # STILL_PLACEHOLDER €/MWh_store\n",
    "        \"capex_Pch\": 50000.0,        # STILL_PLACEHOLDER €/MW\n",
    "        \"capex_Pdis\": 50000.0,       # STILL_PLACEHOLDER €/MW\n",
    "        \"fom_E\": 2000.0,             # STILL_PLACEHOLDER €/MWh_store/year\n",
    "        \"fom_P\": 5000.0,             # STILL_PLACEHOLDER €/MW/year\n",
    "        \"vom_ch\": 0.5,               # STILL_PLACEHOLDER €/MWh_e\n",
    "        \"vom_dis\": 0.5,              # STILL_PLACEHOLDER €/MWh_e\n",
    "\n",
    "        \"subsidy_on_discharge_eur_per_MWh_e\": hydro_sub_eur_per_MWh,\n",
    "        \"subsidy_on_h2_MWh_HHV\": 0.0,\n",
    "\n",
    "        \"capex_grant_per_MWh_store\": 0.0,\n",
    "        \"capex_grant_cap_total\": 0.0,\n",
    "        \"capex_discount_factor\": 0.0,  # STILL_PLACEHOLDER (if using a proxy reduction)\n",
    "        \"salvage_frac\": 0.10,          # modelling assumption\n",
    "\n",
    "        # Multi-year CAPEX / lifetime modelling (assumptions unless you calibrate them)\n",
    "        \"lifetime_years\": 60,          # doc: dams ~50–100y; turbines/generators ~30–50y\n",
    "        \"replacement_required\": True,\n",
    "        \"capex_escalation_annual\": 0.0,\n",
    "        \"capex_payment_years\": 10,\n",
    "        \"capex_payment_profile\": None,\n",
    "        \"commissioning_delay_years\": 10,\n",
    "        \"grant_repeats\": False,\n",
    "    },\n",
    "\n",
    "    \"Flywheel\": {\n",
    "        \"eta_ch\": fly_eta,            # from doc (converted from round-trip)\n",
    "        \"eta_dis\": fly_eta,           # from doc (converted from round-trip)\n",
    "\n",
    "        \"self_dis\": 0.001,            # STILL_PLACEHOLDER (doc reports annual degradation, not per-step self-discharge)\n",
    "\n",
    "        # Doc typical module/container sizing: 2..>5000 kWh and 20..>20000 kW\n",
    "        # Use upper-end typical values as conservative bounds:\n",
    "        \"Emax\": 5.0,                  # 5000 kWh -> 5 MWh\n",
    "        \"Pch_max\": 20.0,              # 20000 kW -> 20 MW\n",
    "        \"Pdis_max\": 20.0,             # 20000 kW -> 20 MW\n",
    "\n",
    "        \"capex_E\": fly_capex_E_per_MWh,      # from doc (Table 1)\n",
    "        \"capex_Pch\": fly_capex_P_per_MW,     # from doc (Table 1)\n",
    "        \"capex_Pdis\": fly_capex_P_per_MW,    # from doc (Table 1)\n",
    "        \"fom_E\": fly_fom_E_per_MWhyr,         # from doc (1–2% of CAPEX; midpoint used)\n",
    "        \"fom_P\": fly_fom_P_per_MWyr,          # from doc (1–2% of CAPEX; midpoint used)\n",
    "\n",
    "        \"vom_ch\": 1.0,               # STILL_PLACEHOLDER €/MWh_e\n",
    "        \"vom_dis\": 1.0,              # STILL_PLACEHOLDER €/MWh_e\n",
    "\n",
    "        \"subsidy_on_discharge_eur_per_MWh_e\": 0.0,\n",
    "        \"subsidy_on_h2_MWh_HHV\": 0.0,\n",
    "\n",
    "        \"capex_grant_per_MWh_store\": 0.0,\n",
    "        \"capex_grant_cap_total\": 0.0,\n",
    "        \"capex_discount_factor\": (EIA_EFFECTIVE_DISCOUNT if EIA_ENABLED else 0.0),  # modelling assumption / proxy\n",
    "        \"salvage_frac\": 0.10,           # modelling assumption\n",
    "\n",
    "        \"lifetime_years\": 25,           # doc: ~20–30 years\n",
    "        \"replacement_required\": True,\n",
    "        \"capex_escalation_annual\": 0.0,\n",
    "        \"capex_payment_years\": 1,\n",
    "        \"capex_payment_profile\": [1.0],\n",
    "        \"commissioning_delay_years\": 0,\n",
    "        \"grant_repeats\": False,\n",
    "    },\n",
    "\n",
    "    \"Battery\": {\n",
    "        \"eta_ch\": 0.95,               # STILL_PLACEHOLDER (doc gives 80–95% round-trip)\n",
    "        \"eta_dis\": 0.95,              # STILL_PLACEHOLDER (doc gives 80–95% round-trip)\n",
    "        \"self_dis\": 0.0005,           # STILL_PLACEHOLDER (doc gives annual degradation, not per-step self-discharge)\n",
    "\n",
    "        \"Emax\": 1000.0,               # STILL_PLACEHOLDER\n",
    "        \"Pch_max\": 500.0,             # STILL_PLACEHOLDER\n",
    "        \"Pdis_max\": 500.0,            # STILL_PLACEHOLDER\n",
    "\n",
    "        \"capex_E\": 250000.0,          # STILL_PLACEHOLDER €/MWh_store\n",
    "        \"capex_Pch\": 60000.0,         # STILL_PLACEHOLDER €/MW\n",
    "        \"capex_Pdis\": 60000.0,        # STILL_PLACEHOLDER €/MW\n",
    "        \"fom_E\": 5000.0,              # STILL_PLACEHOLDER €/MWh_store/year\n",
    "        \"fom_P\": 7000.0,              # STILL_PLACEHOLDER €/MW/year\n",
    "\n",
    "        \"vom_ch\": 2.0,                # STILL_PLACEHOLDER €/MWh_e\n",
    "        \"vom_dis\": 2.0,               # STILL_PLACEHOLDER €/MWh_e\n",
    "\n",
    "        \"subsidy_on_discharge_eur_per_MWh_e\": 0.0,\n",
    "        \"subsidy_on_h2_MWh_HHV\": 0.0,\n",
    "\n",
    "        # SPRILA example (big company): 70 €/kWh => 70,000 €/MWh (cap applies)\n",
    "        \"capex_grant_per_MWh_store\": sprila_grant_per_MWh_store,   # €/MWh_store (SPRILA)\n",
    "        \"capex_grant_cap_total\": sprila_grant_cap_total,      # € cap (SPRILA)\n",
    "        \"capex_discount_factor\": (EIA_EFFECTIVE_DISCOUNT if EIA_ENABLED else 0.0),\n",
    "        \"salvage_frac\": 0.10,\n",
    "\n",
    "        \"lifetime_years\": 12,          # doc: ~10–20 years\n",
    "        \"replacement_required\": True,\n",
    "        \"capex_escalation_annual\": 0.0,\n",
    "        \"capex_payment_years\": 1,\n",
    "        \"capex_payment_profile\": [1.0],\n",
    "        \"commissioning_delay_years\": 0,\n",
    "        \"grant_repeats\": False,\n",
    "    },\n",
    "\n",
    "    \"Hydrogen\": {\n",
    "        # Interpret SOC as stored H2 energy (MWh_HHV).\n",
    "        # eta_ch: electricity -> H2_HHV conversion\n",
    "        # eta_dis: H2_HHV -> electricity conversion\n",
    "        \"eta_ch\": 0.70,               # STILL_PLACEHOLDER (doc gives 30–45% round-trip only)\n",
    "        \"eta_dis\": 0.55,              # STILL_PLACEHOLDER (doc gives 30–45% round-trip only)\n",
    "        \"self_dis\": 0.0,              # STILL_PLACEHOLDER (standing losses not quantified in doc)\n",
    "\n",
    "        \"Emax\": 20000.0,              # STILL_PLACEHOLDER (chosen design upper bound)\n",
    "        \"Pch_max\": 1000.0,            # STILL_PLACEHOLDER (electrolyser power)\n",
    "        \"Pdis_max\": 500.0,            # STILL_PLACEHOLDER (power block)\n",
    "\n",
    "        \"capex_E\": h2_capex_E_per_MWh_HHV,  # from doc ($/kg converted to $/MWh_HHV)\n",
    "        \"capex_Pch\": 500000.0,        # STILL_PLACEHOLDER €/MW_e electrolysis\n",
    "        \"capex_Pdis\": 700000.0,       # STILL_PLACEHOLDER €/MW_e power block\n",
    "\n",
    "        \"fom_E\": 300.0,               # STILL_PLACEHOLDER €/MWh_HHV/year\n",
    "        \"fom_P\": 15000.0,             # STILL_PLACEHOLDER €/MW/year\n",
    "        \"vom_ch\": 1.0,                # STILL_PLACEHOLDER €/MWh_e\n",
    "        \"vom_dis\": 3.0,               # STILL_PLACEHOLDER €/MWh_e\n",
    "\n",
    "        \"subsidy_on_discharge_eur_per_MWh_e\": 0.0,\n",
    "        \"subsidy_on_h2_MWh_HHV\": h2_sub_eur_per_MWh_HHV,\n",
    "\n",
    "        \"capex_grant_per_MWh_store\": 0.0,\n",
    "        \"capex_grant_cap_total\": 0.0,\n",
    "        \"capex_discount_factor\": 0.0,\n",
    "        \"salvage_frac\": 0.05,\n",
    "\n",
    "        \"lifetime_years\": 25,          # doc: ~20–40 years\n",
    "        \"replacement_required\": True,\n",
    "        \"capex_escalation_annual\": 0.0,\n",
    "        \"capex_payment_years\": 1,\n",
    "        \"capex_payment_profile\": [1.0],\n",
    "        \"commissioning_delay_years\": 0,\n",
    "        \"grant_repeats\": False,\n",
    "    },\n",
    "}\n",
    "\n",
    "# Economic settings (course-consistent assumptions)\n",
    "discount_rate = 0.08\n",
    "H_years = 25\n",
    "subsidy_years = 15\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cell 4 — The optimisation model (Gurobi): design + dispatch under multiple price scenarios\n\nThis is the core of the notebook. It defines and solves a **two-stage stochastic optimisation** problem for one technology at a time.\n\n- **First-stage (design) decisions** are shared across scenarios:\n  - \\(E\\) [MWh]: energy capacity\n  - \\(P^{ch}\\) [MW]: maximum charging power\n  - \\(P^{dis}\\) [MW]: maximum discharging power\n- **Second-stage (dispatch) decisions** are scenario-dependent and hourly:\n  - \\(c_{s,t}\\) [MW]: charging power\n  - \\(d_{s,t}\\) [MW]: discharging power\n  - \\(SOC_{s,t}\\) [MWh]: state of charge\n\nThe solver chooses \\(E, P^{ch}, P^{dis}\\) that maximise **expected NPV** across scenarios, while still allowing each scenario to operate optimally given those design choices.\n\n## 1) Model inputs and data preparation\nThe function:\n- forces `prices` and `surplus` to shape \\((S,T)\\),\n- normalises scenario probabilities,\n- computes present-value multipliers for:\n  - operating cashflows (fixed + variable O&M),\n  - price-based revenues (optionally with a drift rate),\n  - subsidies (only for `subsidy_years`),\n  - CAPEX payments (multi-year payment schedules + replacements + CAPEX indexing),\n  - salvage value at the horizon end.\n\n## 2) Constraints (physics + policy)\nThe dispatch respects:\n- **power limits**  \n  \\(c_{s,t} \\le P^{ch}\\), \\(d_{s,t} \\le P^{dis}\\)\n- **charging availability**  \n  \\(c_{s,t} \\le surplus_{s,t}\\)\n- **energy capacity**  \n  \\(SOC_{s,t} \\le E\\)\n- **state-of-charge dynamics** (energy balance with efficiencies and self-discharge)  \n  \\[\n  SOC_{s,t+1}=(1-\\lambda)SOC_{s,t}+\\eta_{ch}c_{s,t}\\Delta t-\\frac{d_{s,t}\\Delta t}{\\eta_{dis}}\n  \\]\n- **cyclic condition** \\(SOC_{s,0}=SOC_{s,T}\\) so the storage does not “start full and end empty” artificially.\n\n### Optional: prevent simultaneous charge and discharge (MILP logic)\nIf `prevent_simultaneous=True`, the model introduces a binary variable \\(z_{s,t}\\) and big‑M constraints so that each hour is either charging or discharging, not both. This makes the model a **MILP** (integer programme). Without it, the model is a linear programme; it can still be correct, but binaries prevent pathological “charge and discharge at the same hour” solutions.\n\n## 3) Objective: maximise NPV\nThe objective combines:\n- **CAPEX present value**, including multi-year payments and replacements (with optional year indexing),\n- **fixed O&M** present value,\n- **variable O&M** costs on energy throughput,\n- **electricity arbitrage revenue**: buy energy when prices are low (charging), sell when prices are high (discharging),\n- **subsidy cashflows**: hydropower paid per MWh discharged; hydrogen paid per MWh_HHV produced,\n- **salvage value** at the horizon end.\n\nAll scenario-dependent terms are weighted by `scenario_prob[s]`, producing an **expected-value** optimisation.\n\n## 4) Outputs produced\nThe function returns a structured result dictionary containing:\n- optimal design \\(E, P^{ch}, P^{dis}\\),\n- total NPV,\n- an NPV breakdown (CAPEX, O&M, price revenue, subsidy),\n- a per-scenario breakdown,\n- a full hourly dispatch table for scenario 0 (for plotting and diagnostics).\n\nIn short: this cell is where your engineering assumptions become a solvable optimisation problem and produce a comparable “best technology” metric.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "64740dc3-1e03-45a6-90a4-48729f8be0f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_one_tech(\n",
    "    tech_name,\n",
    "    prices,\n",
    "    surplus,\n",
    "    scenario_prob,\n",
    "    dt,\n",
    "    year_scale,\n",
    "    discount_rate,\n",
    "    H_years,\n",
    "    subsidy_years,\n",
    "    output_flag=0,\n",
    "    time_limit=60,\n",
    "    prevent_simultaneous=True,\n",
    "    force_frac_ub=None,\n",
    "    force_min_E=None,\n",
    "    force_min_P=None,\n",
    "    price_drift_annual=None,\n",
    "):\n",
    "    \"\"\"Solve design + dispatch for one technology, with:\n",
    "    - price scenarios (S,T) for a representative year\n",
    "    - long-horizon NPV with optional annual price drift (applies to price-dependent cashflows)\n",
    "    - multi-year CAPEX schedules + replacements (lifetime) + commissioning delays\n",
    "    \"\"\"\n",
    "\n",
    "    td = TECH[tech_name]\n",
    "\n",
    "    # Optional extra marginal cost applied to *charging* energy (e.g., wind neighbourhood/environment fund).\n",
    "    # Defined in the Technology Data cell as SURPLUS_CHARGE_EXTRA_COST_EUR_PER_MWH.\n",
    "    extra_charge_cost = float(globals().get(\"SURPLUS_CHARGE_EXTRA_COST_EUR_PER_MWH\", 0.0))\n",
    "    vom_ch_eff = float(td[\"vom_ch\"]) + extra_charge_cost\n",
    "    vom_dis_eff = float(td[\"vom_dis\"])\n",
    "    prices = as_2d(prices)\n",
    "    surplus = as_2d(surplus)\n",
    "    scenario_prob = np.asarray(scenario_prob, dtype=float)\n",
    "    scenario_prob = scenario_prob / scenario_prob.sum()\n",
    "\n",
    "    S, T = prices.shape\n",
    "\n",
    "    # Default drift: use global variable if present; else 0\n",
    "    if price_drift_annual is None:\n",
    "        price_drift_annual = float(globals().get(\"price_drift_annual\", 0.0))\n",
    "    price_drift_annual = float(price_drift_annual)\n",
    "\n",
    "    r = float(discount_rate)\n",
    "    H_years = int(H_years)\n",
    "    subsidy_years = int(subsidy_years)\n",
    "\n",
    "    commissioning_delay = int(max(0, td.get(\"commissioning_delay_years\", 0)))\n",
    "\n",
    "    # PV factors\n",
    "    PW_ops = pw_factor_shifted(r, H_years, commissioning_delay)                        # constant annual amounts (VOM/FOM)\n",
    "    PW_price = pw_factor_growth_shifted(r, price_drift_annual, H_years, commissioning_delay)  # price-dependent part\n",
    "\n",
    "    # Subsidy applies for the first `subsidy_years` years of operation (starting at commissioning)\n",
    "    H_sub_total = min(H_years, commissioning_delay + max(0, subsidy_years))\n",
    "    PW_sub = pw_factor_shifted(r, H_sub_total, commissioning_delay)\n",
    "\n",
    "    # CAPEX schedule / replacements\n",
    "    lifetime_years = td.get(\"lifetime_years\", None)\n",
    "    replacement_required = bool(td.get(\"replacement_required\", True))\n",
    "    capex_escalation_annual = float(td.get(\"capex_escalation_annual\", 0.0))\n",
    "    capex_payment_years = int(max(0, td.get(\"capex_payment_years\", 0)))\n",
    "    capex_payment_profile = td.get(\"capex_payment_profile\", None)\n",
    "\n",
    "    # Optional: CAPEX index paths (advanced)\n",
    "    # - capex_index_by_year: applies to the whole CAPEX (all components)\n",
    "    # - capex_index_E_by_year / capex_index_Pch_by_year / capex_index_Pdis_by_year (or capex_index_P_by_year)\n",
    "    #   allow different paths for energy vs power components.\n",
    "    capex_index_all = td.get(\"capex_index_by_year\", None)\n",
    "    capex_index_E = td.get(\"capex_index_E_by_year\", None)\n",
    "    capex_index_P = td.get(\"capex_index_P_by_year\", None)\n",
    "    capex_index_Pch = td.get(\"capex_index_Pch_by_year\", None)\n",
    "    capex_index_Pdis = td.get(\"capex_index_Pdis_by_year\", None)\n",
    "\n",
    "    def _as_index(x):\n",
    "        return None if x is None else np.asarray(x, dtype=float)\n",
    "\n",
    "    capex_index_all = _as_index(capex_index_all)\n",
    "    capex_index_E = _as_index(capex_index_E) if capex_index_E is not None else capex_index_all\n",
    "    capex_index_Pch = _as_index(capex_index_Pch) if capex_index_Pch is not None else (_as_index(capex_index_P) if capex_index_P is not None else capex_index_all)\n",
    "    capex_index_Pdis = _as_index(capex_index_Pdis) if capex_index_Pdis is not None else (_as_index(capex_index_P) if capex_index_P is not None else capex_index_all)\n",
    "\n",
    "        # Component-specific PV factors (supports separate CAPEX indices for E / Pch / Pdis)\n",
    "    capex_mult_E = build_capex_multiplier_series(\n",
    "        H=H_years,\n",
    "        lifetime_years=lifetime_years,\n",
    "        construction_years=capex_payment_years,\n",
    "        capex_payment_profile=capex_payment_profile,\n",
    "        replacement_required=replacement_required,\n",
    "        capex_escalation_annual=capex_escalation_annual,\n",
    "        capex_index_by_year=capex_index_E,\n",
    "    )\n",
    "    capex_mult_Pch = build_capex_multiplier_series(\n",
    "        H=H_years,\n",
    "        lifetime_years=lifetime_years,\n",
    "        construction_years=capex_payment_years,\n",
    "        capex_payment_profile=capex_payment_profile,\n",
    "        replacement_required=replacement_required,\n",
    "        capex_escalation_annual=capex_escalation_annual,\n",
    "        capex_index_by_year=capex_index_Pch,\n",
    "    )\n",
    "    capex_mult_Pdis = build_capex_multiplier_series(\n",
    "        H=H_years,\n",
    "        lifetime_years=lifetime_years,\n",
    "        construction_years=capex_payment_years,\n",
    "        capex_payment_profile=capex_payment_profile,\n",
    "        replacement_required=replacement_required,\n",
    "        capex_escalation_annual=capex_escalation_annual,\n",
    "        capex_index_by_year=capex_index_Pdis,\n",
    "    )\n",
    "\n",
    "    disc = (1.0 + r) ** np.arange(H_years)\n",
    "    PV_capex_factor_E = float(np.sum(capex_mult_E / disc))\n",
    "    PV_capex_factor_Pch = float(np.sum(capex_mult_Pch / disc))\n",
    "    PV_capex_factor_Pdis = float(np.sum(capex_mult_Pdis / disc))\n",
    "\n",
    "    # Salvage on the last installed asset (prorated by remaining life)\n",
    "    salvage_frac = float(td.get(\"salvage_frac\", 0.0))\n",
    "    if lifetime_years is None or (not replacement_required) or lifetime_years <= 0:\n",
    "        install_years = [0]\n",
    "        L = H_years\n",
    "    else:\n",
    "        L = int(lifetime_years)\n",
    "        install_years = list(range(0, H_years, L))\n",
    "    last_install = int(max(install_years))\n",
    "    used_years_last = H_years - last_install\n",
    "    remaining_years_last = max(L - used_years_last, 0)\n",
    "    salvage_effective_frac = 0.0 if L <= 0 else salvage_frac * (remaining_years_last / L)\n",
    "    if capex_index_E is None:\n",
    "        salvage_growth_E = (1.0 + capex_escalation_annual) ** last_install\n",
    "    else:\n",
    "        salvage_growth_E = float(capex_index_E[last_install])\n",
    "\n",
    "    if capex_index_Pch is None:\n",
    "        salvage_growth_Pch = (1.0 + capex_escalation_annual) ** last_install\n",
    "    else:\n",
    "        salvage_growth_Pch = float(capex_index_Pch[last_install])\n",
    "\n",
    "    if capex_index_Pdis is None:\n",
    "        salvage_growth_Pdis = (1.0 + capex_escalation_annual) ** last_install\n",
    "    else:\n",
    "        salvage_growth_Pdis = float(capex_index_Pdis[last_install])\n",
    "    salvage_pv_factor_E = float(salvage_effective_frac * salvage_growth_E / (1.0 + r) ** H_years)\n",
    "    salvage_pv_factor_Pch = float(salvage_effective_frac * salvage_growth_Pch / (1.0 + r) ** H_years)\n",
    "    salvage_pv_factor_Pdis = float(salvage_effective_frac * salvage_growth_Pdis / (1.0 + r) ** H_years)\n",
    "\n",
    "    # -------------------------\n",
    "    # Build model\n",
    "    # -------------------------\n",
    "    m = gp.Model(f\"storage_{tech_name}\")\n",
    "    m.Params.OutputFlag = output_flag\n",
    "    if time_limit is not None:\n",
    "        m.Params.TimeLimit = time_limit\n",
    "    if prevent_simultaneous:\n",
    "        m.Params.MIPGap = 0.05\n",
    "\n",
    "    # -------------------------\n",
    "    # Design vars\n",
    "    # -------------------------\n",
    "    E = m.addVar(lb=0.0, ub=td[\"Emax\"], name=\"E\")          # MWh_store (or MWh_HHV for hydrogen)\n",
    "    Pch = m.addVar(lb=0.0, ub=td[\"Pch_max\"], name=\"Pch\")   # MW\n",
    "    Pdis = m.addVar(lb=0.0, ub=td[\"Pdis_max\"], name=\"Pdis\")# MW\n",
    "\n",
    "    # Optional one-time CAPEX grant (linearised min(rate*E, cap))\n",
    "    grant = m.addVar(lb=0.0, ub=td[\"capex_grant_cap_total\"], name=\"capex_grant\")\n",
    "    if td[\"capex_grant_cap_total\"] > 0 and td[\"capex_grant_per_MWh_store\"] > 0:\n",
    "        m.addConstr(grant <= td[\"capex_grant_per_MWh_store\"] * E, name=\"grant_rate\")\n",
    "        m.addConstr(grant <= td[\"capex_grant_cap_total\"], name=\"grant_cap\")\n",
    "    else:\n",
    "        m.addConstr(grant == 0.0, name=\"no_grant\")\n",
    "\n",
    "    # -------------------------\n",
    "    # Operational vars\n",
    "    # -------------------------\n",
    "    c = m.addVars(S, T, lb=0.0, name=\"c\")         # MW charging\n",
    "    d = m.addVars(S, T, lb=0.0, name=\"d\")         # MW discharging\n",
    "    soc = m.addVars(S, T + 1, lb=0.0, name=\"soc\") # MWh state of charge\n",
    "\n",
    "    if prevent_simultaneous:\n",
    "        z = m.addVars(S, T, vtype=GRB.BINARY, name=\"isCharging\")\n",
    "    else:\n",
    "        z = None\n",
    "\n",
    "    eta_ch = float(td[\"eta_ch\"])\n",
    "    eta_dis = float(td[\"eta_dis\"])\n",
    "    self_dis = float(td[\"self_dis\"])\n",
    "\n",
    "    M_ch = float(td[\"Pch_max\"])\n",
    "    M_dis = float(td[\"Pdis_max\"])\n",
    "\n",
    "    # -------------------------\n",
    "    # Constraints\n",
    "    # -------------------------\n",
    "    for s in range(S):\n",
    "        m.addConstr(soc[s, 0] <= E, name=f\"soc0_ub[{s}]\")\n",
    "        m.addConstr(soc[s, 0] >= 0.0, name=f\"soc0_lb[{s}]\")\n",
    "        m.addConstr(soc[s, T] == soc[s, 0], name=f\"cyclic[{s}]\")  # steady-state year\n",
    "\n",
    "        for t in range(T):\n",
    "            m.addConstr(soc[s, t] <= E, name=f\"soc_ub[{s},{t}]\")\n",
    "            m.addConstr(c[s, t] <= Pch, name=f\"pch[{s},{t}]\")\n",
    "            m.addConstr(d[s, t] <= Pdis, name=f\"pdis[{s},{t}]\")\n",
    "            m.addConstr(c[s, t] <= float(surplus[s, t]), name=f\"surplus[{s},{t}]\")\n",
    "            if prevent_simultaneous:\n",
    "                m.addConstr(c[s, t] <= M_ch * z[s, t], name=f\"noSim_c[{s},{t}]\")\n",
    "                m.addConstr(d[s, t] <= M_dis * (1 - z[s, t]), name=f\"noSim_d[{s},{t}]\")\n",
    "            m.addConstr(\n",
    "                soc[s, t + 1]\n",
    "                == (1.0 - self_dis) * soc[s, t]\n",
    "                + eta_ch * c[s, t] * dt\n",
    "                - (d[s, t] * dt) / eta_dis,\n",
    "                name=f\"dyn[{s},{t}]\"\n",
    "            )\n",
    "\n",
    "    # ============================================================\n",
    "    # Counterfactual: force a non-zero investment to explain \"why 0?\"\n",
    "    # ============================================================\n",
    "    m.update()\n",
    "\n",
    "    def _safe_ub(var, td, fallback_keys):\n",
    "        try:\n",
    "            return float(var.UB)\n",
    "        except Exception:\n",
    "            for k in fallback_keys:\n",
    "                if k in td and td[k] is not None:\n",
    "                    try:\n",
    "                        return float(td[k])\n",
    "                    except Exception:\n",
    "                        pass\n",
    "            return float(\"inf\")\n",
    "\n",
    "    def _finite_pos(x):\n",
    "        try:\n",
    "            x = float(x)\n",
    "            return np.isfinite(x) and x > 0.0\n",
    "        except Exception:\n",
    "            return False\n",
    "\n",
    "    applied_any = False\n",
    "\n",
    "    if force_frac_ub is not None:\n",
    "        ub_E = _safe_ub(E, td, [\"Emax\"])\n",
    "        ub_Pch = _safe_ub(Pch, td, [\"Pch_max\"])\n",
    "        ub_Pdis = _safe_ub(Pdis, td, [\"Pdis_max\"])\n",
    "        if not (_finite_pos(ub_E) and _finite_pos(ub_Pch) and _finite_pos(ub_Pdis)):\n",
    "            raise RuntimeError(\"Cannot apply force_frac_ub: non-finite UB(s) detected.\")\n",
    "\n",
    "        frac = float(force_frac_ub)\n",
    "        if frac <= 0.0 or frac >= 1.0:\n",
    "            raise ValueError(\"force_frac_ub must be in (0,1).\")\n",
    "\n",
    "        m.addConstr(E >= frac * ub_E, name=\"force_E_min\")\n",
    "        m.addConstr(Pch >= frac * ub_Pch, name=\"force_Pch_min\")\n",
    "        m.addConstr(Pdis >= frac * ub_Pdis, name=\"force_Pdis_min\")\n",
    "        applied_any = True\n",
    "\n",
    "    if force_min_E is not None:\n",
    "        m.addConstr(E >= float(force_min_E), name=\"force_E_abs_min\")\n",
    "        applied_any = True\n",
    "\n",
    "    if force_min_P is not None:\n",
    "        m.addConstr(Pch + Pdis >= float(force_min_P), name=\"force_P_total_min\")\n",
    "        applied_any = True\n",
    "\n",
    "    # -------------------------\n",
    "    # Economics (annual cashflow components)\n",
    "    # -------------------------\n",
    "    capex_discount_factor = float(td.get(\"capex_discount_factor\", 0.0))\n",
    "\n",
    "    capex_raw_E = td[\"capex_E\"] * E\n",
    "    capex_raw_Pch = td[\"capex_Pch\"] * Pch\n",
    "    capex_raw_Pdis = td[\"capex_Pdis\"] * Pdis\n",
    "    capex_raw = capex_raw_E + capex_raw_Pch + capex_raw_Pdis\n",
    "\n",
    "    # CAPEX after discount factor, before grant (component-wise so year-indexing can differ)\n",
    "    capex_net_E = (1.0 - capex_discount_factor) * capex_raw_E\n",
    "    capex_net_Pch = (1.0 - capex_discount_factor) * capex_raw_Pch\n",
    "    capex_net_Pdis = (1.0 - capex_discount_factor) * capex_raw_Pdis\n",
    "    capex_net = capex_net_E + capex_net_Pch + capex_net_Pdis\n",
    "\n",
    "    fom = td[\"fom_E\"] * E + td[\"fom_P\"] * (Pch + Pdis)  # €/year, costs\n",
    "\n",
    "    sub_on_dis = float(td.get(\"subsidy_on_discharge_eur_per_MWh_e\", 0.0))\n",
    "    sub_on_h2 = float(td.get(\"subsidy_on_h2_MWh_HHV\", 0.0))\n",
    "\n",
    "    exp_annual_arbitrage = gp.LinExpr()\n",
    "    exp_annual_vom = gp.LinExpr()\n",
    "    exp_annual_subsidy = gp.LinExpr()\n",
    "\n",
    "    for s in range(S):\n",
    "        scen_arbitrage = gp.LinExpr()\n",
    "        scen_vom = gp.LinExpr()\n",
    "        scen_sub = gp.LinExpr()\n",
    "\n",
    "        for t in range(T):\n",
    "            p = float(prices[s, t])\n",
    "            scen_arbitrage += p * (d[s, t] - c[s, t]) * dt\n",
    "            scen_vom += -(vom_ch_eff * c[s, t] + vom_dis_eff * d[s, t]) * dt\n",
    "            if sub_on_dis != 0.0:\n",
    "                scen_sub += sub_on_dis * d[s, t] * dt\n",
    "            if sub_on_h2 != 0.0:\n",
    "                # subsidy on produced H2_HHV (MWh_HHV) = eta_ch * charged electricity (MWh_e)\n",
    "                scen_sub += sub_on_h2 * (eta_ch * c[s, t] * dt)\n",
    "\n",
    "        w = float(scenario_prob[s])\n",
    "        exp_annual_arbitrage += w * scen_arbitrage\n",
    "        exp_annual_vom += w * scen_vom\n",
    "        exp_annual_subsidy += w * scen_sub\n",
    "\n",
    "    # Scale short test windows up to annualised values\n",
    "    exp_annual_arbitrage *= float(year_scale)\n",
    "    exp_annual_vom *= float(year_scale)\n",
    "    exp_annual_subsidy *= float(year_scale)\n",
    "\n",
    "    # PV terms\n",
    "    pv_capex_cost = -(\n",
    "        PV_capex_factor_E * capex_net_E\n",
    "        + PV_capex_factor_Pch * capex_net_Pch\n",
    "        + PV_capex_factor_Pdis * capex_net_Pdis\n",
    "    ) + grant  # grant is one-time at t=0 (default)\n",
    "\n",
    "    pv_salvage = (\n",
    "        salvage_pv_factor_E * capex_net_E\n",
    "        + salvage_pv_factor_Pch * capex_net_Pch\n",
    "        + salvage_pv_factor_Pdis * capex_net_Pdis\n",
    "    )  # salvage is a fraction of last installed CAPEX\n",
    "    pv_ops_const = PW_ops * (exp_annual_vom - fom)        # constant annual costs (VOM + FOM)\n",
    "    pv_price = PW_price * exp_annual_arbitrage            # price-dependent part with drift\n",
    "    pv_sub = PW_sub * exp_annual_subsidy                  # subsidies only for subsidy_years of operation\n",
    "\n",
    "    m.setObjective(pv_capex_cost + pv_salvage + pv_ops_const + pv_price + pv_sub, GRB.MAXIMIZE)\n",
    "\n",
    "    m.optimize()\n",
    "\n",
    "    if m.Status not in (GRB.OPTIMAL, GRB.TIME_LIMIT, GRB.SUBOPTIMAL):\n",
    "        return {\"tech\": tech_name, \"status\": int(m.Status), \"npv\": None}\n",
    "\n",
    "    # -------------------------\n",
    "    # Collect results\n",
    "    # -------------------------\n",
    "    E_val = float(E.X)\n",
    "    Pch_val = float(Pch.X)\n",
    "    Pdis_val = float(Pdis.X)\n",
    "    npv_val = float(m.ObjVal)\n",
    "\n",
    "    c0 = np.array([c[0, t].X for t in range(T)], dtype=float)\n",
    "    d0 = np.array([d[0, t].X for t in range(T)], dtype=float)\n",
    "    soc0 = np.array([soc[0, t].X for t in range(T + 1)], dtype=float)\n",
    "    soc_pct = (soc0[:-1] / E_val * 100.0) if E_val > 1e-9 else np.zeros(T)\n",
    "\n",
    "    # Numeric breakdown (recompute with solution values)\n",
    "    # Annual expectations\n",
    "    arb_s = []\n",
    "    vom_s = []\n",
    "    sub_s = []\n",
    "    for s in range(S):\n",
    "        arb = float(np.sum(prices[s, :] * (np.array([d[s, t].X for t in range(T)]) - np.array([c[s, t].X for t in range(T)])) * dt))\n",
    "        vom = -float(np.sum((vom_ch_eff * np.array([c[s, t].X for t in range(T)]) + vom_dis_eff * np.array([d[s, t].X for t in range(T)])) * dt))\n",
    "        sub = 0.0\n",
    "        if sub_on_dis != 0.0:\n",
    "            sub += float(sub_on_dis * np.sum(np.array([d[s, t].X for t in range(T)]) * dt))\n",
    "        if sub_on_h2 != 0.0:\n",
    "            sub += float(sub_on_h2 * np.sum(eta_ch * np.array([c[s, t].X for t in range(T)]) * dt))\n",
    "        arb_s.append(arb * year_scale)\n",
    "        vom_s.append(vom * year_scale)\n",
    "        sub_s.append(sub * year_scale)\n",
    "\n",
    "    exp_arb_num = float(np.dot(scenario_prob, arb_s))\n",
    "    exp_vom_num = float(np.dot(scenario_prob, vom_s))\n",
    "    exp_sub_num = float(np.dot(scenario_prob, sub_s))\n",
    "    fom_num = float(td[\"fom_E\"] * E_val + td[\"fom_P\"] * (Pch_val + Pdis_val))\n",
    "\n",
    "    capex_raw_num = float(td[\"capex_E\"] * E_val + td[\"capex_Pch\"] * Pch_val + td[\"capex_Pdis\"] * Pdis_val)\n",
    "    capex_net_num = float((1.0 - float(td.get(\"capex_discount_factor\", 0.0))) * capex_raw_num)\n",
    "    grant_num = float(grant.X)\n",
    "\n",
    "    capex_net_E_num = float((1.0 - float(td.get(\"capex_discount_factor\", 0.0))) * td[\"capex_E\"] * E_val)\n",
    "    capex_net_Pch_num = float((1.0 - float(td.get(\"capex_discount_factor\", 0.0))) * td[\"capex_Pch\"] * Pch_val)\n",
    "    capex_net_Pdis_num = float((1.0 - float(td.get(\"capex_discount_factor\", 0.0))) * td[\"capex_Pdis\"] * Pdis_val)\n",
    "\n",
    "    pv_capex_num = -(\n",
    "        PV_capex_factor_E * capex_net_E_num\n",
    "        + PV_capex_factor_Pch * capex_net_Pch_num\n",
    "        + PV_capex_factor_Pdis * capex_net_Pdis_num\n",
    "    ) + grant_num\n",
    "\n",
    "    pv_salvage_num = (\n",
    "        salvage_pv_factor_E * capex_net_E_num\n",
    "        + salvage_pv_factor_Pch * capex_net_Pch_num\n",
    "        + salvage_pv_factor_Pdis * capex_net_Pdis_num\n",
    "    )\n",
    "    pv_price_num = PW_price * exp_arb_num\n",
    "    pv_ops_num = PW_ops * (exp_vom_num - fom_num)\n",
    "    pv_sub_num = PW_sub * exp_sub_num\n",
    "\n",
    "    npv_breakdown = {\n",
    "        \"PV_CAPEX\": pv_capex_num,\n",
    "        \"PV_SALVAGE\": pv_salvage_num,\n",
    "        \"PV_PRICE_ARBITRAGE\": pv_price_num,\n",
    "        \"PV_VOM_FOM\": pv_ops_num,\n",
    "        \"PV_SUBSIDY\": pv_sub_num,\n",
    "        \"NPV_TOTAL\": pv_capex_num + pv_salvage_num + pv_price_num + pv_ops_num + pv_sub_num,\n",
    "    }\n",
    "\n",
    "    scenario_breakdown = pd.DataFrame({\n",
    "        \"scenario\": scenario_names if \"scenario_names\" in globals() and len(globals().get(\"scenario_names\", [])) == S else [f\"s{s}\" for s in range(S)],\n",
    "        \"prob\": scenario_prob,\n",
    "        \"annual_arbitrage\": arb_s,\n",
    "        \"annual_vom\": vom_s,\n",
    "        \"annual_subsidy\": sub_s,\n",
    "    })\n",
    "\n",
    "    out = {\n",
    "        \"tech\": tech_name,\n",
    "        \"status\": int(m.Status),\n",
    "        \"npv\": npv_val,\n",
    "        \"E\": E_val,\n",
    "        \"Pch\": Pch_val,\n",
    "        \"Pdis\": Pdis_val,\n",
    "        \"assumptions\": {\n",
    "            \"discount_rate\": r,\n",
    "            \"H_years\": H_years,\n",
    "            \"subsidy_years\": subsidy_years,\n",
    "            \"commissioning_delay_years\": commissioning_delay,\n",
    "            \"price_drift_annual\": price_drift_annual,\n",
    "            \"PV_capex_factor_E\": PV_capex_factor_E,\n",
    "            \"PV_capex_factor_Pch\": PV_capex_factor_Pch,\n",
    "            \"PV_capex_factor_Pdis\": PV_capex_factor_Pdis,\n",
    "            \"PW_ops\": PW_ops,\n",
    "            \"PW_price\": PW_price,\n",
    "            \"PW_sub\": PW_sub,\n",
    "            \"salvage_pv_factor_E\": salvage_pv_factor_E,\n",
    "            \"salvage_pv_factor_Pch\": salvage_pv_factor_Pch,\n",
    "            \"salvage_pv_factor_Pdis\": salvage_pv_factor_Pdis,\n",
    "            \"lifetime_years\": lifetime_years,\n",
    "            \"capex_payment_years\": capex_payment_years,\n",
    "            \"capex_escalation_annual\": capex_escalation_annual,\n",
    "        },\n",
    "        \"npv_breakdown\": npv_breakdown,\n",
    "        \"scenario_breakdown\": scenario_breakdown,\n",
    "        \"capex_mult_by_year\": {\n",
    "            \"E\": capex_mult_E,\n",
    "            \"Pch\": capex_mult_Pch,\n",
    "            \"Pdis\": capex_mult_Pdis,\n",
    "        },\n",
    "        \"dispatch_s0\": pd.DataFrame({\n",
    "            \"t\": np.arange(T),\n",
    "            \"price\": prices[0],\n",
    "            \"surplus\": surplus[0],\n",
    "            \"charge_MW\": c0,\n",
    "            \"discharge_MW\": d0,\n",
    "            \"soc_MWh\": soc0[:-1],\n",
    "            \"soc_pct\": soc_pct,\n",
    "        }),\n",
    "    }\n",
    "\n",
    "    if prevent_simultaneous:\n",
    "        out[\"simultaneous_hours_s0\"] = int(np.sum((c0 > 1e-6) & (d0 > 1e-6)))\n",
    "\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cell 5 — Run the model for every technology and diagnose “NPV = 0” outcomes\n\nThis cell executes the optimisation (Cell 4) once per technology and summarises the results.\n\n## What it does\n1. **Loop over `TECH`**: for each technology name, call `solve_one_tech(...)`.\n2. **Store outputs** in `results` (a list of dictionaries).\n3. **Build a summary table** showing, per technology:\n   - solver status,\n   - best NPV,\n   - optimal design sizes \\(E, P^{ch}, P^{dis}\\).\n4. **Diagnostic re-solve when NPV is ~0**:\n   - If a technology chooses \\(E=P^{ch}=P^{dis}=0\\), its NPV will be close to zero.\n   - That does *not* necessarily mean the technology is “bad”; it can also mean “under current CAPEX/OPEX assumptions, investment is not justified.”\n   - To understand *why*, the code re-solves the model while forcing a minimum design size (e.g., ≥10% of upper bounds).\n   - It then prints the NPV breakdown so you can see which component dominates (CAPEX too high, low arbitrage value, etc.).\n\n## Why this is valuable\nThis is a typical operations research workflow:\n- first obtain an optimal solution,\n- then run controlled counterfactuals to understand sensitivity and failure modes.\n\nIt turns the model into an explanatory tool, not just a black box that outputs a number.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "16dad337-c121-464e-bc62-9b956ce4824d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set parameter Username\n",
      "Set parameter LicenseID to value 2661894\n",
      "Academic license - for non-commercial use only - expires 2026-05-07\n",
      "Set parameter OutputFlag to value 1\n",
      "Set parameter TimeLimit to value 60\n",
      "Set parameter MIPGap to value 0.05\n",
      "Gurobi Optimizer version 12.0.3 build v12.0.3rc0 (win64 - Windows 11+.0 (26200.2))\n",
      "\n",
      "CPU model: Intel(R) Core(TM) i7-10750H CPU @ 2.60GHz, instruction set [SSE2|AVX|AVX2]\n",
      "Thread count: 6 physical cores, 12 logical processors, using up to 12 threads\n",
      "\n",
      "Non-default parameters:\n",
      "TimeLimit  60\n",
      "MIPGap  0.05\n",
      "\n",
      "Optimize a model with 183970 rows, 105127 columns and 394216 nonzeros\n",
      "Model fingerprint: 0x0b2afe89\n",
      "Variable types: 78847 continuous, 26280 integer (26280 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [9e-01, 5e+02]\n",
      "  Objective range  [3e-02, 1e+05]\n",
      "  Bounds range     [1e+00, 5e+03]\n",
      "  RHS range        [3e+02, 6e+02]\n",
      "Found heuristic solution: objective -0.0000000\n",
      "Presolve removed 26290 rows and 4 columns\n",
      "Presolve time: 1.10s\n",
      "Presolved: 157680 rows, 105123 columns, 367920 nonzeros\n",
      "Variable types: 78843 continuous, 26280 integer (26280 binary)\n",
      "Root relaxation presolved: 131400 rows, 78843 columns, 315360 nonzeros\n",
      "\n",
      "Deterministic concurrent LP optimizer: primal and dual simplex\n",
      "Showing primal log only...\n",
      "\n",
      "\n",
      "Root simplex log...\n",
      "\n",
      "Iteration    Objective       Primal Inf.    Dual Inf.      Time\n",
      "   63743    7.8578846e+03   0.000000e+00   3.788224e+08      5s\n",
      "   64823    1.0505509e+04   0.000000e+00   4.449488e+08     10s\n",
      "Concurrent spin time: 0.00s\n",
      "\n",
      "Solved with dual simplex\n",
      "\n",
      "Root simplex log...\n",
      "\n",
      "Iteration    Objective       Primal Inf.    Dual Inf.      Time\n",
      "    6252    6.9222748e+09   0.000000e+00   0.000000e+00     10s\n",
      "\n",
      "Root relaxation: objective 6.922275e+09, 6252 iterations, 8.51 seconds (7.85 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0 6.9223e+09    0  793   -0.00000 6.9223e+09      -     -   11s\n",
      "H    0     0                    6.914418e+09 6.9223e+09  0.11%     -   12s\n",
      "\n",
      "Explored 1 nodes (14008 simplex iterations) in 12.75 seconds (9.97 work units)\n",
      "Thread count was 12 (of 12 available processors)\n",
      "\n",
      "Solution count 2: 6.91442e+09 -0 \n",
      "\n",
      "Optimal solution found (tolerance 5.00e-02)\n",
      "Best objective 6.914418117602e+09, best bound 6.922274761215e+09, gap 0.1136%\n",
      "Set parameter OutputFlag to value 1\n",
      "Set parameter TimeLimit to value 60\n",
      "Set parameter MIPGap to value 0.05\n",
      "Gurobi Optimizer version 12.0.3 build v12.0.3rc0 (win64 - Windows 11+.0 (26200.2))\n",
      "\n",
      "CPU model: Intel(R) Core(TM) i7-10750H CPU @ 2.60GHz, instruction set [SSE2|AVX|AVX2]\n",
      "Thread count: 6 physical cores, 12 logical processors, using up to 12 threads\n",
      "\n",
      "Non-default parameters:\n",
      "TimeLimit  60\n",
      "MIPGap  0.05\n",
      "\n",
      "Optimize a model with 183970 rows, 105127 columns and 394216 nonzeros\n",
      "Model fingerprint: 0x2ff95d89\n",
      "Variable types: 78847 continuous, 26280 integer (26280 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [9e-01, 2e+02]\n",
      "  Objective range  [8e-02, 5e+05]\n",
      "  Bounds range     [1e+00, 2e+02]\n",
      "  RHS range        [2e+02, 6e+02]\n",
      "Found heuristic solution: objective -0.0000000\n",
      "Presolve removed 26290 rows and 4 columns\n",
      "Presolve time: 1.09s\n",
      "Presolved: 157680 rows, 105123 columns, 367920 nonzeros\n",
      "Variable types: 78843 continuous, 26280 integer (26280 binary)\n",
      "Root relaxation presolved: 131400 rows, 78843 columns, 315360 nonzeros\n",
      "\n",
      "Deterministic concurrent LP optimizer: primal and dual simplex\n",
      "Showing primal log only...\n",
      "\n",
      "\n",
      "Root simplex log...\n",
      "\n",
      "Iteration    Objective       Primal Inf.    Dual Inf.      Time\n",
      "   57833    9.2947701e+03   0.000000e+00   2.115171e+08      5s\n",
      "Concurrent spin time: 0.00s\n",
      "\n",
      "Solved with dual simplex\n",
      "\n",
      "Root simplex log...\n",
      "\n",
      "Iteration    Objective       Primal Inf.    Dual Inf.      Time\n",
      "   28963    7.7253265e+08   0.000000e+00   0.000000e+00      6s\n",
      "\n",
      "Root relaxation: objective 7.725327e+08, 28963 iterations, 4.63 seconds (3.37 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0 7.7253e+08    0  758   -0.00000 7.7253e+08      -     -    6s\n",
      "H    0     0                    7.594242e+08 7.7253e+08  1.73%     -    9s\n",
      "\n",
      "Explored 1 nodes (29602 simplex iterations) in 9.18 seconds (5.65 work units)\n",
      "Thread count was 12 (of 12 available processors)\n",
      "\n",
      "Solution count 2: 7.59424e+08 -0 \n",
      "\n",
      "Optimal solution found (tolerance 5.00e-02)\n",
      "Best objective 7.594241597184e+08, best bound 7.725326524923e+08, gap 1.7261%\n",
      "Set parameter OutputFlag to value 1\n",
      "Set parameter TimeLimit to value 60\n",
      "Set parameter MIPGap to value 0.05\n",
      "Gurobi Optimizer version 12.0.3 build v12.0.3rc0 (win64 - Windows 11+.0 (26200.2))\n",
      "\n",
      "CPU model: Intel(R) Core(TM) i7-10750H CPU @ 2.60GHz, instruction set [SSE2|AVX|AVX2]\n",
      "Thread count: 6 physical cores, 12 logical processors, using up to 12 threads\n",
      "\n",
      "Non-default parameters:\n",
      "TimeLimit  60\n",
      "MIPGap  0.05\n",
      "\n",
      "Optimize a model with 183971 rows, 105127 columns and 394218 nonzeros\n",
      "Model fingerprint: 0x1f4b41a1\n",
      "Variable types: 78847 continuous, 26280 integer (26280 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [9e-01, 7e+04]\n",
      "  Objective range  [2e-01, 4e+05]\n",
      "  Bounds range     [1e+00, 4e+05]\n",
      "  RHS range        [3e+02, 4e+05]\n",
      "Found heuristic solution: objective -0.0000000\n",
      "Presolve removed 26290 rows and 3 columns\n",
      "Presolve time: 0.78s\n",
      "Presolved: 157681 rows, 105124 columns, 367922 nonzeros\n",
      "Variable types: 78844 continuous, 26280 integer (26280 binary)\n",
      "Root relaxation presolved: 131401 rows, 78844 columns, 315362 nonzeros\n",
      "\n",
      "Deterministic concurrent LP optimizer: primal and dual simplex\n",
      "Showing primal log only...\n",
      "\n",
      "\n",
      "Root simplex log...\n",
      "\n",
      "Iteration    Objective       Primal Inf.    Dual Inf.      Time\n",
      "   54654    1.0129893e+04   0.000000e+00   4.121073e+08      5s\n",
      "Concurrent spin time: 0.00s\n",
      "\n",
      "Solved with dual simplex\n",
      "\n",
      "Root simplex log...\n",
      "\n",
      "Iteration    Objective       Primal Inf.    Dual Inf.      Time\n",
      "   35654    3.9455678e+09   0.000000e+00   0.000000e+00      9s\n",
      "\n",
      "Root relaxation: objective 3.945568e+09, 35654 iterations, 7.98 seconds (5.19 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0 3.9456e+09    0  536   -0.00000 3.9456e+09      -     -    9s\n",
      "H    0     0                    3.934254e+09 3.9456e+09  0.29%     -   14s\n",
      "\n",
      "Explored 1 nodes (37868 simplex iterations) in 14.28 seconds (8.57 work units)\n",
      "Thread count was 12 (of 12 available processors)\n",
      "\n",
      "Solution count 2: 3.93425e+09 -0 \n",
      "\n",
      "Optimal solution found (tolerance 5.00e-02)\n",
      "Best objective 3.934253542884e+09, best bound 3.945567793280e+09, gap 0.2876%\n",
      "Set parameter OutputFlag to value 1\n",
      "Set parameter TimeLimit to value 60\n",
      "Set parameter MIPGap to value 0.05\n",
      "Gurobi Optimizer version 12.0.3 build v12.0.3rc0 (win64 - Windows 11+.0 (26200.2))\n",
      "\n",
      "CPU model: Intel(R) Core(TM) i7-10750H CPU @ 2.60GHz, instruction set [SSE2|AVX|AVX2]\n",
      "Thread count: 6 physical cores, 12 logical processors, using up to 12 threads\n",
      "\n",
      "Non-default parameters:\n",
      "TimeLimit  60\n",
      "MIPGap  0.05\n",
      "\n",
      "Optimize a model with 183970 rows, 105127 columns and 394216 nonzeros\n",
      "Model fingerprint: 0x15a4544a\n",
      "Variable types: 78847 continuous, 26280 integer (26280 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [7e-01, 1e+03]\n",
      "  Objective range  [5e-02, 9e+05]\n",
      "  Bounds range     [1e+00, 2e+04]\n",
      "  RHS range        [3e+02, 6e+02]\n",
      "Found heuristic solution: objective -0.0000000\n",
      "Presolve removed 26290 rows and 4 columns\n",
      "Presolve time: 0.63s\n",
      "Presolved: 157680 rows, 105123 columns, 367920 nonzeros\n",
      "Variable types: 78843 continuous, 26280 integer (26280 binary)\n",
      "Root relaxation presolved: 131400 rows, 78843 columns, 315360 nonzeros\n",
      "\n",
      "Deterministic concurrent LP optimizer: primal and dual simplex\n",
      "Showing primal log only...\n",
      "\n",
      "\n",
      "Root simplex log...\n",
      "\n",
      "Iteration    Objective       Primal Inf.    Dual Inf.      Time\n",
      "   58063    6.8071390e+03   0.000000e+00   2.611806e+08      5s\n",
      "   59493    1.0020572e+04   0.000000e+00   3.030340e+08     10s\n",
      "   60573    1.3368644e+04   0.000000e+00   2.839470e+08     16s\n",
      "   61653    1.7125510e+04   0.000000e+00   2.388983e+08     21s\n",
      "   62613    2.1786070e+04   0.000000e+00   6.657971e+08     25s\n",
      "Concurrent spin time: 0.00s\n",
      "\n",
      "Solved with dual simplex\n",
      "\n",
      "Root simplex log...\n",
      "\n",
      "Iteration    Objective       Primal Inf.    Dual Inf.      Time\n",
      "   20764    5.4854741e+09   0.000000e+00   0.000000e+00     26s\n",
      "\n",
      "Root relaxation: objective 5.485474e+09, 20764 iterations, 24.87 seconds (24.47 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0 5.4855e+09    0   88   -0.00000 5.4855e+09      -     -   26s\n",
      "H    0     0                    5.484055e+09 5.4855e+09  0.03%     -   29s\n",
      "\n",
      "Explored 1 nodes (23847 simplex iterations) in 29.21 seconds (26.67 work units)\n",
      "Thread count was 12 (of 12 available processors)\n",
      "\n",
      "Solution count 2: 5.48405e+09 -0 \n",
      "\n",
      "Optimal solution found (tolerance 5.00e-02)\n",
      "Best objective 5.484054961456e+09, best bound 5.485474113560e+09, gap 0.0259%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tech</th>\n",
       "      <th>status</th>\n",
       "      <th>NPV</th>\n",
       "      <th>E (MWh_store)</th>\n",
       "      <th>Pch (MW)</th>\n",
       "      <th>Pdis (MW)</th>\n",
       "      <th>simultaneous_hours_s0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PHS</td>\n",
       "      <td>2</td>\n",
       "      <td>6.914418e+09</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hydrogen</td>\n",
       "      <td>2</td>\n",
       "      <td>5.484055e+09</td>\n",
       "      <td>20000.0</td>\n",
       "      <td>508.719511</td>\n",
       "      <td>500.000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Battery</td>\n",
       "      <td>2</td>\n",
       "      <td>3.934254e+09</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Flywheel</td>\n",
       "      <td>2</td>\n",
       "      <td>7.594242e+08</td>\n",
       "      <td>200.0</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>183.816</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       tech  status           NPV  E (MWh_store)    Pch (MW)  Pdis (MW)  \\\n",
       "0       PHS       2  6.914418e+09         5000.0  500.000000    500.000   \n",
       "3  Hydrogen       2  5.484055e+09        20000.0  508.719511    500.000   \n",
       "2   Battery       2  3.934254e+09         1000.0  500.000000    500.000   \n",
       "1  Flywheel       2  7.594242e+08          200.0  200.000000    183.816   \n",
       "\n",
       "   simultaneous_hours_s0  \n",
       "0                      0  \n",
       "3                      0  \n",
       "2                      0  \n",
       "1                      0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No technologies with NPV≈0 in baseline solve.\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# 3) Baseline solves\n",
    "# =========================\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "results = []\n",
    "for tech_name in TECH.keys():\n",
    "    res = solve_one_tech(\n",
    "        tech_name=tech_name,\n",
    "        prices=prices,\n",
    "        surplus=surplus,\n",
    "        scenario_prob=scenario_prob,\n",
    "        dt=dt,\n",
    "        year_scale=year_scale,\n",
    "        discount_rate=discount_rate,\n",
    "        H_years=H_years,\n",
    "        subsidy_years=subsidy_years,\n",
    "        output_flag=1,\n",
    "        time_limit=60.0,\n",
    "        prevent_simultaneous=True,\n",
    "        price_drift_annual=price_drift_annual,\n",
    "    )\n",
    "    results.append(res)\n",
    "\n",
    "summary = pd.DataFrame([{\n",
    "    \"tech\": r[\"tech\"],\n",
    "    \"status\": r[\"status\"],\n",
    "    \"NPV\": r.get(\"npv\", np.nan),\n",
    "    \"E (MWh_store)\": r.get(\"E\", np.nan),\n",
    "    \"Pch (MW)\": r.get(\"Pch\", np.nan),\n",
    "    \"Pdis (MW)\": r.get(\"Pdis\", np.nan),\n",
    "    \"simultaneous_hours_s0\": r.get(\"simultaneous_hours_s0\", np.nan),\n",
    "} for r in results]).sort_values(\"NPV\", ascending=False)\n",
    "\n",
    "display(summary)\n",
    "\n",
    "# -------------------------\n",
    "# Counterfactual diagnostics: if a tech optimises to ~0, force a small build to see why\n",
    "# -------------------------\n",
    "r0_list = [r for r in results if (r.get(\"npv\") is not None) and (abs(float(r.get(\"npv\", 0.0))) < 1e-6)]\n",
    "\n",
    "if len(r0_list) > 0:\n",
    "    print(f\"Found {len(r0_list)} technology(ies) with NPV≈0. Running counterfactual forced-build solves...\")\n",
    "    for r0 in r0_list:\n",
    "        tech_name = r0[\"tech\"]\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(f\"Counterfactual (force 10% of UB) for: {tech_name}\")\n",
    "\n",
    "        rbest = solve_one_tech(\n",
    "            tech_name=tech_name,\n",
    "            prices=prices,\n",
    "            surplus=surplus,\n",
    "            scenario_prob=scenario_prob,\n",
    "            dt=dt,\n",
    "            year_scale=year_scale,\n",
    "            discount_rate=discount_rate,\n",
    "            H_years=H_years,\n",
    "            subsidy_years=subsidy_years,\n",
    "            output_flag=1,\n",
    "            time_limit=60.0,\n",
    "            prevent_simultaneous=True,\n",
    "            force_frac_ub=0.10,\n",
    "            price_drift_annual=price_drift_annual,\n",
    "        )\n",
    "\n",
    "        display(pd.Series((rbest or {}).get(\"npv_breakdown\", {}), name=f\"{tech_name} npv_breakdown\"))\n",
    "        display((rbest or {}).get(\"scenario_breakdown\", pd.DataFrame()).head())\n",
    "else:\n",
    "    print(\"No technologies with NPV≈0 in baseline solve.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cell 6 — Select the “best” technology (highest NPV) and expose its dispatch\n\nAt this point, `results` contains one optimisation outcome per technology.\n\nThis cell performs a simple selection step:\n- filters out any technologies with `npv=None` (failed solves),\n- chooses the technology with the **maximum NPV**,\n- stores it in `best`.\n\nThe key idea is that all technologies are evaluated under the *same* scenario set, discounting assumptions, and accounting conventions—so the NPV numbers are directly comparable.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8eb3ef1c-29c5-419f-af61-0a0ec33491b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('PHS', 6914418117.602101)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# =========================\n",
    "# 5) Best alternative + its dispatch (scenario 0)\n",
    "# =========================\n",
    "best = max([r for r in results if r[\"npv\"] is not None], key=lambda x: x[\"npv\"])\n",
    "best[\"tech\"], best[\"npv\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cell 7 — Interactive dispatch visualisation (scenario 0)\n\nThis cell turns the raw dispatch table of the selected technology into an interactive plot. The goal is not only “pretty graphs”, but *model validation*:\n\n- Does the storage charge mainly during low-price hours?\n- Does it respect the surplus charging limits?\n- Does the state of charge behave smoothly and stay within \\([0,E]\\)?\n- Are there suspicious patterns (e.g., simultaneous charge/discharge) that would indicate a modelling issue?\n\n## What is plotted\nFrom `best[\"dispatch_s0\"]` (scenario 0), the cell extracts:\n- `price[t]` (€/MWh),\n- `charge_MW[t]`, `discharge_MW[t]`,\n- `soc_MWh[t]` and `soc_pct[t]`.\n\nIt then builds a multi-trace Plotly figure with linked x-axes so you can inspect:\n1. price over time,\n2. charging/discharging power,\n3. state of charge.\n\n## Why the widgets exist\nA full year has 8760 points. Looking at all of them at once hides structure.\nThe sliders let you zoom into a window (e.g., a week or a day) while keeping the same underlying solution—no re-optimisation is required.\n\nThis is the fastest way to debug and interpret an OR model: you validate behaviour visually against the economic logic you expect.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4784fe32-d67b-4d7f-b385-bb9ec0b22380",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0ca69f6ce9f4de8a5cc027cf3fe5518",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntText(value=0, description='start t'), IntText(value=24, description='end t'))…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "df = best[\"dispatch_s0\"]\n",
    "\n",
    "t = df[\"t\"].to_numpy()\n",
    "price = df[\"price\"].to_numpy()\n",
    "charge = df[\"charge_MW\"].to_numpy()\n",
    "discharge = df[\"discharge_MW\"].to_numpy()\n",
    "\n",
    "soc_mwh = df[\"soc_MWh\"].to_numpy()\n",
    "soc_pct = df[\"soc_pct\"].to_numpy()\n",
    "\n",
    "t_min = int(np.nanmin(t))\n",
    "t_max = int(np.nanmax(t))\n",
    "\n",
    "default_start = max(t_min, 0)\n",
    "default_end = min(t_max, default_start + 24)\n",
    "if default_end <= default_start:\n",
    "    default_end = min(t_max, default_start + 1)\n",
    "\n",
    "def build_fig():\n",
    "    fig = make_subplots(\n",
    "        rows=3, cols=1,\n",
    "        shared_xaxes=True,\n",
    "        vertical_spacing=0.06,\n",
    "        subplot_titles=(\n",
    "            f\"Scenario 0 price - {best['tech']}\",\n",
    "            f\"Charge / discharge - {best['tech']}\",\n",
    "            f\"State of charge - {best['tech']}\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "    fig.add_trace(go.Scatter(x=t, y=price, mode=\"lines\", name=\"Price (€/MWh)\"), row=1, col=1)\n",
    "    fig.add_trace(go.Scatter(x=t, y=charge, mode=\"lines\", name=\"Charge (MW)\"), row=2, col=1)\n",
    "    fig.add_trace(go.Scatter(x=t, y=discharge, mode=\"lines\", name=\"Discharge (MW)\"), row=2, col=1)\n",
    "    fig.add_trace(go.Scatter(x=t, y=soc_pct, mode=\"lines\", name=\"SOC (%)\"), row=3, col=1)\n",
    "\n",
    "    fig.update_yaxes(title_text=\"€/MWh\", row=1, col=1)\n",
    "    fig.update_yaxes(title_text=\"MW\", row=2, col=1)\n",
    "    fig.update_yaxes(title_text=\"Energy\", row=3, col=1)\n",
    "    fig.update_yaxes(title_text=\"SOC (%)\", row=3, col=1, range=[0, 100])\n",
    "    fig.update_xaxes(title_text=\"t\", row=3, col=1)\n",
    "\n",
    "    fig.update_layout(\n",
    "        hovermode=\"x unified\",\n",
    "        height=850,\n",
    "        legend=dict(orientation=\"h\", yanchor=\"bottom\", y=1.02, xanchor=\"left\", x=0),\n",
    "    )\n",
    "\n",
    "    # Optional: range slider on bottom axis (still useful in addition to manual range)\n",
    "    fig.update_xaxes(rangeslider_visible=True, row=3, col=1)\n",
    "    return fig\n",
    "\n",
    "# ---- Controls (start/end inputs + sliders) ----\n",
    "start_box = widgets.IntText(value=default_start, description=\"start t\")\n",
    "end_box   = widgets.IntText(value=default_end, description=\"end t\")\n",
    "\n",
    "start_slider = widgets.IntSlider(\n",
    "    value=default_start, min=t_min, max=t_max-1, step=1,\n",
    "    description=\"start\", continuous_update=False, layout=widgets.Layout(width=\"700px\")\n",
    ")\n",
    "end_slider = widgets.IntSlider(\n",
    "    value=default_end, min=t_min+1, max=t_max, step=1,\n",
    "    description=\"end\", continuous_update=False, layout=widgets.Layout(width=\"700px\")\n",
    ")\n",
    "\n",
    "out = widgets.Output()\n",
    "_lock = {\"busy\": False}\n",
    "\n",
    "def clamp_and_sync(start, end):\n",
    "    start = int(max(t_min, min(start, t_max - 1)))\n",
    "    end   = int(max(start + 1, min(end, t_max)))\n",
    "\n",
    "    # keep end slider feasible\n",
    "    end_slider.min = start + 1\n",
    "    if end < end_slider.min:\n",
    "        end = end_slider.min\n",
    "\n",
    "    return start, end\n",
    "\n",
    "def redraw(start, end):\n",
    "    fig = build_fig()\n",
    "    fig.update_xaxes(range=[start, end])  # applies to all shared x-axes\n",
    "    with out:\n",
    "        clear_output(wait=True)\n",
    "        display(fig)\n",
    "\n",
    "def on_any_change(_):\n",
    "    if _lock[\"busy\"]:\n",
    "        return\n",
    "    _lock[\"busy\"] = True\n",
    "    try:\n",
    "        # take values from boxes (authoritative)\n",
    "        start, end = clamp_and_sync(start_box.value, end_box.value)\n",
    "\n",
    "        # sync everything\n",
    "        start_box.value = start\n",
    "        end_box.value = end\n",
    "        start_slider.value = start\n",
    "        end_slider.value = end\n",
    "\n",
    "        redraw(start, end)\n",
    "    finally:\n",
    "        _lock[\"busy\"] = False\n",
    "\n",
    "def on_slider_change(_):\n",
    "    if _lock[\"busy\"]:\n",
    "        return\n",
    "    _lock[\"busy\"] = True\n",
    "    try:\n",
    "        start, end = clamp_and_sync(start_slider.value, end_slider.value)\n",
    "\n",
    "        start_box.value = start\n",
    "        end_box.value = end\n",
    "        start_slider.value = start\n",
    "        end_slider.value = end\n",
    "\n",
    "        redraw(start, end)\n",
    "    finally:\n",
    "        _lock[\"busy\"] = False\n",
    "\n",
    "start_box.observe(on_any_change, names=\"value\")\n",
    "end_box.observe(on_any_change, names=\"value\")\n",
    "start_slider.observe(on_slider_change, names=\"value\")\n",
    "end_slider.observe(on_slider_change, names=\"value\")\n",
    "\n",
    "# Initial draw\n",
    "start0, end0 = clamp_and_sync(default_start, default_end)\n",
    "start_box.value, end_box.value = start0, end0\n",
    "start_slider.value, end_slider.value = start0, end0\n",
    "redraw(start0, end0)\n",
    "\n",
    "display(widgets.VBox([\n",
    "    widgets.HBox([start_box, end_box]),\n",
    "    start_slider,\n",
    "    end_slider,\n",
    "    out\n",
    "]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cell 8 — Hydrogen subsidy sanity check (annualised)\n\nThis final cell computes a simple, transparent check for the hydrogen subsidy calculation using the selected dispatch:\n\n1. Compute annual charged energy (MWh of electricity into the electrolyser):\n   \\[\n   E_{ch,year} = \\text{year\\_scale}\\sum_t c_t\\Delta t\n   \\]\n2. Convert to annual hydrogen energy on an HHV basis:\n   \\[\n   E_{H2,year}^{HHV} = \\eta_{ch}\\,E_{ch,year}\n   \\]\n3. Multiply by the chosen subsidy rate (€/MWh_HHV):\n   \\[\n   \\text{Subsidy}_{year} = s_{H2}\\cdot E_{H2,year}^{HHV}.\n   \\]\n\nWhy this is useful:\n- The subsidy enters the optimisation objective, so it is easy to “lose track” of units and scaling.\n- This check recomputes the annual subsidy from first principles using the actual dispatch output.\n- If the number looks unrealistic, it immediately tells you where to look: scaling (`year_scale`), units (kWh vs MWh), or the meaning of \\(\\eta_{ch}\\).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8ed9e8d5-5975-4a00-8e8c-e80770c0baed",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float64(2074051.6333318641),\n",
       " np.float64(1451836.143332305),\n",
       " np.float64(551117000.0089428))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "td = TECH[\"Hydrogen\"]\n",
    "df = best[\"dispatch_s0\"]\n",
    "year_scale = 8760/(T*dt)\n",
    "\n",
    "annual_charge_MWh = year_scale * (df[\"charge_MW\"].to_numpy() * dt).sum()\n",
    "annual_h2_MWh_HHV = td[\"eta_ch\"] * annual_charge_MWh\n",
    "annual_h2_subsidy = TECH[\"Hydrogen\"][\"subsidy_on_h2_MWh_HHV\"] * annual_h2_MWh_HHV\n",
    "\n",
    "annual_charge_MWh, annual_h2_MWh_HHV, annual_h2_subsidy\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}