{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "783ea46f-4a01-4b98-b771-5e62c3b7f4ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# 0) Imports\n",
    "# =========================\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "try:\n",
    "    import gurobipy as gp\n",
    "    from gurobipy import GRB\n",
    "except Exception as e:\n",
    "    raise RuntimeError(\n",
    "        \"This notebook cell requires gurobipy + a working Gurobi license.\\n\"\n",
    "        f\"Import error: {repr(e)}\"\n",
    "    )\n",
    "\n",
    "# -------------------------\n",
    "# Helpers\n",
    "# -------------------------\n",
    "def pw_factor(r: float, H: int) -> float:\n",
    "    \"\"\"Present-worth factor P/A(r,H).\"\"\"\n",
    "    if H <= 0:\n",
    "        return 0.0\n",
    "    if abs(r) < 1e-12:\n",
    "        return float(H)\n",
    "    return (1.0 - (1.0 + r) ** (-H)) / r\n",
    "\n",
    "def as_2d(a):\n",
    "    a = np.asarray(a)\n",
    "    if a.ndim == 1:\n",
    "        return a[None, :]\n",
    "    return a\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "95abdafa-ac1d-4d33-8ce7-5362c94531f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_hourly_profile_from_month_hour_csv(\n",
    "    csv_path: str = \"gemini_avg_power_month_hour_2017_2019_long.csv\",\n",
    "    month_col: str = \"month\",\n",
    "    hour_col: str = \"hour\",\n",
    "    value_col: str = \"avg_power\",\n",
    "    base_year: int = 2021,     # non-leap year => 8760 hours\n",
    "    tz: str = \"UTC\",\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Converts a (month, hour)->value table (288 rows) into a chronological 8760-hour profile.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    profile : np.ndarray shape (8760,)\n",
    "        Hourly values for a typical year.\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(csv_path)\n",
    "\n",
    "    required = {month_col, hour_col, value_col}\n",
    "    missing = required - set(df.columns)\n",
    "    if missing:\n",
    "        raise ValueError(f\"Missing columns in {csv_path}: {missing}. Found: {list(df.columns)}\")\n",
    "\n",
    "    df = df[[month_col, hour_col, value_col]].copy()\n",
    "    df[month_col] = df[month_col].astype(int)\n",
    "    df[hour_col] = df[hour_col].astype(int)\n",
    "    df[value_col] = df[value_col].astype(float)\n",
    "\n",
    "    # Ensure full 12x24 coverage\n",
    "    all_pairs = pd.MultiIndex.from_product(\n",
    "        [range(1, 13), range(0, 24)],\n",
    "        names=[month_col, hour_col]\n",
    "    )\n",
    "    df = df.set_index([month_col, hour_col]).reindex(all_pairs)\n",
    "\n",
    "    if df[value_col].isna().any():\n",
    "        missing_pairs = df[df[value_col].isna()].index.tolist()[:10]\n",
    "        raise ValueError(\n",
    "            f\"Incomplete month-hour table in {csv_path}. Missing examples: {missing_pairs}. \"\n",
    "            \"Need all 12*24=288 combinations.\"\n",
    "        )\n",
    "\n",
    "    # Create hourly timestamps for a non-leap year\n",
    "    idx = pd.date_range(\n",
    "        start=f\"{base_year}-01-01\",\n",
    "        end=f\"{base_year+1}-01-01\",\n",
    "        freq=\"h\",\n",
    "        inclusive=\"left\",\n",
    "        tz=tz\n",
    "    )\n",
    "    if len(idx) != 8760:\n",
    "        raise RuntimeError(f\"Expected 8760 hours, got {len(idx)} for base_year={base_year}.\")\n",
    "\n",
    "    tmp = pd.DataFrame({\"ts\": idx})\n",
    "    tmp[\"month\"] = tmp[\"ts\"].dt.month\n",
    "    tmp[\"hour\"] = tmp[\"ts\"].dt.hour\n",
    "\n",
    "    lut = df.reset_index().rename(columns={value_col: \"val\"})\n",
    "    tmp = tmp.merge(lut, on=[\"month\", \"hour\"], how=\"left\")\n",
    "\n",
    "    if tmp[\"val\"].isna().any():\n",
    "        raise RuntimeError(\"Mapping month-hour -> hourly series failed (NaNs after merge).\")\n",
    "\n",
    "    profile = tmp[\"val\"].to_numpy(dtype=float)\n",
    "    profile = np.clip(profile, 0.0, None)\n",
    "    return profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "10ef1a54-06b4-406a-a8f4-3b8beafd47d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded scenarios from: [2020, 2021, 2022, 2023, 2024]\n",
      "prices shape: (S,T)=(5,8760), year_scale=1.0\n",
      "price stats: min=-500.00, mean=110.10, max=872.96\n",
      "surplus shape: (5, 8760), surplus stats: min=239.10, mean=408.54, max=568.30\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# 1) Time series + scenarios (historical day-ahead prices)\n",
    "#    Build scenarios from full years (2020–2025) OR a 1-week test window.\n",
    "# =========================\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "dt = 1.0\n",
    "hours_per_year = 8760.0\n",
    "\n",
    "price_path = \"day_ahead_prices_2020_2025_combined.csv\"\n",
    "ts_col = \"timestamp\"\n",
    "price_col = \"price\"\n",
    "\n",
    "# -------------------------\n",
    "# TEST SWITCH (turn on/off)\n",
    "# -------------------------\n",
    "TEST_MODE = False  # <--- set True to test on a single week\n",
    "TEST_START_UTC = \"2022-01-03 00:00:00\"  # inclusive, UTC\n",
    "TEST_DAYS = 7  # 7 days = 168 hours\n",
    "TEST_TILE_TO_YEAR = False  # set True to repeat the week to 8760 hours\n",
    "\n",
    "dfp = pd.read_csv(price_path)\n",
    "dfp[ts_col] = pd.to_datetime(dfp[ts_col], utc=True, errors=\"coerce\")\n",
    "dfp = dfp.dropna(subset=[ts_col, price_col]).sort_values(ts_col)\n",
    "\n",
    "# If testing, cut down the raw data early (faster than processing everything)\n",
    "if TEST_MODE:\n",
    "    start_ts = pd.Timestamp(TEST_START_UTC, tz=\"UTC\")\n",
    "    end_ts = start_ts + pd.Timedelta(days=TEST_DAYS)\n",
    "    dfp = dfp[(dfp[ts_col] >= start_ts) & (dfp[ts_col] < end_ts)]\n",
    "\n",
    "dfp = dfp.set_index(ts_col)\n",
    "\n",
    "# Ensure hourly grid (handles missing values robustly)\n",
    "price_series = (\n",
    "    dfp[price_col].astype(float)\n",
    "    .resample(\"h\").mean()\n",
    "    .interpolate(\"time\")\n",
    ")\n",
    "\n",
    "if TEST_MODE:\n",
    "    # Ensure exact week slice on the hourly series\n",
    "    start_ts = pd.Timestamp(TEST_START_UTC, tz=\"UTC\")\n",
    "    end_ts = start_ts + pd.Timedelta(days=TEST_DAYS)\n",
    "    price_series = price_series.loc[start_ts : end_ts - pd.Timedelta(hours=1)]\n",
    "\n",
    "    if len(price_series) != 24 * TEST_DAYS:\n",
    "        raise ValueError(\n",
    "            f\"Test window does not have exactly {24*TEST_DAYS} hourly points; got {len(price_series)}. \"\n",
    "            \"Pick a different TEST_START_UTC with full hourly coverage.\"\n",
    "        )\n",
    "\n",
    "    if TEST_TILE_TO_YEAR:\n",
    "        reps = int(hours_per_year // len(price_series))\n",
    "        rem = int(hours_per_year - reps * len(price_series))\n",
    "        tiled = np.concatenate([np.tile(price_series.to_numpy(float), reps),\n",
    "                                price_series.to_numpy(float)[:rem]])\n",
    "        price_series = pd.Series(tiled)  # index not needed for the optimization horizon\n",
    "\n",
    "# Drop Feb 29 only in normal mode so each year has exactly 8760 hours\n",
    "if not TEST_MODE:\n",
    "    is_feb29 = (price_series.index.month == 2) & (price_series.index.day == 29)\n",
    "    price_series = price_series[~is_feb29]\n",
    "\n",
    "# -------------------------\n",
    "# Build scenarios\n",
    "# -------------------------\n",
    "if TEST_MODE and not TEST_TILE_TO_YEAR:\n",
    "    # One scenario = the week (T=168)\n",
    "    prices = price_series.to_numpy(dtype=float)[None, :]  # shape (1,T)\n",
    "    kept_years = [f\"TEST_WEEK_FROM_{TEST_START_UTC}\"]\n",
    "else:\n",
    "    # Each full calendar year = one scenario (T=8760)\n",
    "    all_years = sorted(price_series.index.year.unique())\n",
    "\n",
    "    prices_list = []\n",
    "    kept_years = []\n",
    "    for y in all_years:\n",
    "        ys = price_series[price_series.index.year == y]\n",
    "        if len(ys) == 8760:\n",
    "            prices_list.append(ys.to_numpy(dtype=float))\n",
    "            kept_years.append(y)\n",
    "\n",
    "    if len(prices_list) == 0:\n",
    "        raise ValueError(\"No full 8760-hour years found. Check data coverage and timestamps.\")\n",
    "\n",
    "    prices = np.vstack(prices_list)  # shape (S,T)\n",
    "\n",
    "S, T = prices.shape\n",
    "year_scale = hours_per_year / (T * dt)  # =1.0 in normal mode; >1.0 in week-only test\n",
    "scenario_prob = np.ones(S, dtype=float) / S\n",
    "\n",
    "print(f\"Loaded scenarios from: {kept_years}\")\n",
    "print(f\"prices shape: (S,T)=({S},{T}), year_scale={year_scale}\")\n",
    "print(f\"price stats: min={prices.min():.2f}, mean={prices.mean():.2f}, max={prices.max():.2f}\")\n",
    "\n",
    "def make_surplus_proxy_from_prices(prices_ST, surplus_max_mw=50.0, low_quantile=0.20):\n",
    "    thresh = np.quantile(prices_ST, low_quantile, axis=1, keepdims=True)\n",
    "    return np.where(prices_ST <= thresh, surplus_max_mw, 0.0).astype(float)\n",
    "\n",
    "surplus = make_surplus_proxy_from_prices(prices, surplus_max_mw=50.0, low_quantile=0.20)\n",
    "\n",
    "# =========================\n",
    "# 1b) Surplus (Gemini production profile -> hourly surplus)\n",
    "# =========================\n",
    "\n",
    "gemini_power_path = \"gemini_avg_power_month_hour_2017_2019_long.csv\"  # your attached file name\n",
    "\n",
    "gemini_profile = build_hourly_profile_from_month_hour_csv(\n",
    "    gemini_power_path,\n",
    "    month_col=\"month\",\n",
    "    hour_col=\"hour\",\n",
    "    value_col=\"avg_power\",\n",
    "    base_year=2021,\n",
    "    tz=\"UTC\",\n",
    ")\n",
    "\n",
    "# --- Align Gemini profile to the optimization horizon T ---\n",
    "gemini_profile = np.asarray(gemini_profile, dtype=float).ravel()\n",
    "\n",
    "def _hour_of_year_no_feb29(ts_utc: pd.Timestamp) -> int:\n",
    "    \"\"\"\n",
    "    Returns the hour index (0..8759) of ts within its year, counting hourly steps,\n",
    "    while skipping Feb 29 to stay consistent with the 8760-hour convention.\n",
    "    \"\"\"\n",
    "    if ts_utc.tz is None:\n",
    "        ts_utc = ts_utc.tz_localize(\"UTC\")\n",
    "    y0 = pd.Timestamp(f\"{ts_utc.year}-01-01 00:00:00\", tz=\"UTC\")\n",
    "    rng = pd.date_range(y0, ts_utc, freq=\"h\", inclusive=\"left\")\n",
    "    rng = rng[~((rng.month == 2) & (rng.day == 29))]\n",
    "    return len(rng)\n",
    "\n",
    "def align_profile_to_T(profile_1d: np.ndarray, T: int, start_hour: int = 0) -> np.ndarray:\n",
    "    profile_1d = np.asarray(profile_1d, dtype=float).ravel()\n",
    "    n = len(profile_1d)\n",
    "\n",
    "    if n == T:\n",
    "        return profile_1d\n",
    "\n",
    "    # Common case: full-year profile but shorter test horizon -> slice from start_hour\n",
    "    if n == 8760 and T < 8760:\n",
    "        start_hour = int(start_hour) % 8760\n",
    "        end = start_hour + T\n",
    "        if end <= 8760:\n",
    "            return profile_1d[start_hour:end]\n",
    "        else:\n",
    "            # wrap around year-end\n",
    "            return np.concatenate([profile_1d[start_hour:], profile_1d[:end - 8760]])\n",
    "\n",
    "    # If profile shorter than T -> tile up to T\n",
    "    if n < T:\n",
    "        reps = int(np.ceil(T / n))\n",
    "        return np.tile(profile_1d, reps)[:T]\n",
    "\n",
    "    # If profile longer than T -> truncate\n",
    "    return profile_1d[:T]\n",
    "\n",
    "# Choose start hour for slicing in TEST_MODE (if available)\n",
    "start_hour = 0\n",
    "if \"TEST_MODE\" in globals() and TEST_MODE and \"TEST_START_UTC\" in globals():\n",
    "    start_ts = pd.Timestamp(TEST_START_UTC, tz=\"UTC\")\n",
    "    start_hour = _hour_of_year_no_feb29(start_ts)\n",
    "\n",
    "gemini_profile = align_profile_to_T(gemini_profile, T, start_hour=start_hour)\n",
    "\n",
    "# Final safety check\n",
    "if len(gemini_profile) != T:\n",
    "    raise ValueError(f\"Gemini profile length {len(gemini_profile)} does not match T={T} after alignment.\")\n",
    "\n",
    "# Interpretation choice:\n",
    "# surplus[t] = available power that can be used to charge storage (MW).\n",
    "# If you assume you can divert a fraction of Gemini output to storage:\n",
    "curtailment_fraction = 1.0   # set e.g. 0.3 if only 30% is realistically available\n",
    "surplus = np.tile((curtailment_fraction * gemini_profile)[None, :], (S, 1))\n",
    "\n",
    "# Optional: add mild year-to-year variability (keeps same shape but different per scenario)\n",
    "rng = np.random.default_rng(42)\n",
    "year_sigma = 0.10  # 10% multiplicative variation\n",
    "year_scale_factors = rng.normal(1.0, year_sigma, size=(S, 1))\n",
    "surplus = np.clip(surplus * year_scale_factors, 0.0, None)\n",
    "\n",
    "print(f\"surplus shape: {surplus.shape}, surplus stats: min={surplus.min():.2f}, mean={surplus.mean():.2f}, max={surplus.max():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "86acf34b-e9f3-4cb3-b178-99bcc5eb6320",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# 2) Technology data (PLACEHOLDERS: fill with your estimates)\n",
    "#    Subsidy structures reflect what you already collected.\n",
    "# =========================\n",
    "\n",
    "# Convert doc values:\n",
    "# Hydropower subsidy example: 0.1693 €/kWh in 2024 => 169.3 €/MWh (15 years)\n",
    "hydro_sub_eur_per_MWh = 0.1693 * 1000.0\n",
    "\n",
    "# Hydrogen electrolysis subsidy example: 0.3796 €/kWh_HHV (15 years)\n",
    "# We'll apply it to produced H2_HHV = eta_ch * charged_electricity\n",
    "h2_sub_eur_per_MWh_HHV = 0.3796 * 1000.0\n",
    "\n",
    "TECH = {\n",
    "    \"PHS\": {\n",
    "        \"eta_ch\": 0.90,\n",
    "        \"eta_dis\": 0.90,\n",
    "        \"self_dis\": 0.0,             # per step fraction\n",
    "        \"Emax\": 5000.0,              # MWh_store\n",
    "        \"Pch_max\": 500.0,            # MW\n",
    "        \"Pdis_max\": 500.0,           # MW\n",
    "        \"capex_E\": 150000.0,         # €/MWh_store (placeholder)\n",
    "        \"capex_Pch\": 50000.0,        # €/MW (placeholder)\n",
    "        \"capex_Pdis\": 50000.0,       # €/MW (placeholder)\n",
    "        \"fom_E\": 2000.0,             # €/MWh_store/year (placeholder)\n",
    "        \"fom_P\": 5000.0,             # €/MW/year (placeholder)\n",
    "        \"vom_ch\": 0.5,               # €/MWh_e (placeholder)\n",
    "        \"vom_dis\": 0.5,              # €/MWh_e (placeholder)\n",
    "        \"subsidy_on_discharge_eur_per_MWh_e\": hydro_sub_eur_per_MWh,\n",
    "        \"subsidy_on_h2_MWh_HHV\": 0.0,\n",
    "        \"capex_grant_per_MWh_store\": 0.0,\n",
    "        \"capex_grant_cap_total\": 0.0,\n",
    "        \"capex_discount_factor\": 0.0,  # e.g., 0.10 for ~10% EIA proxy\n",
    "        \"salvage_frac\": 0.10,\n",
    "    },\n",
    "    \"Flywheel\": {\n",
    "        \"eta_ch\": 0.92,\n",
    "        \"eta_dis\": 0.92,\n",
    "        \"self_dis\": 0.001,           # demo\n",
    "        \"Emax\": 200.0,\n",
    "        \"Pch_max\": 200.0,\n",
    "        \"Pdis_max\": 200.0,\n",
    "        \"capex_E\": 400000.0,         # placeholder\n",
    "        \"capex_Pch\": 80000.0,        # placeholder\n",
    "        \"capex_Pdis\": 80000.0,       # placeholder\n",
    "        \"fom_E\": 6000.0,             # placeholder\n",
    "        \"fom_P\": 8000.0,             # placeholder\n",
    "        \"vom_ch\": 1.0,\n",
    "        \"vom_dis\": 1.0,\n",
    "        \"subsidy_on_discharge_eur_per_MWh_e\": 0.0,\n",
    "        \"subsidy_on_h2_MWh_HHV\": 0.0,\n",
    "        \"capex_grant_per_MWh_store\": 0.0,\n",
    "        \"capex_grant_cap_total\": 0.0,\n",
    "        \"capex_discount_factor\": 0.10,  # EIA proxy from your notes\n",
    "        \"salvage_frac\": 0.15,\n",
    "    },\n",
    "    \"Battery\": {\n",
    "        \"eta_ch\": 0.95,\n",
    "        \"eta_dis\": 0.95,\n",
    "        \"self_dis\": 0.0005,\n",
    "        \"Emax\": 1000.0,\n",
    "        \"Pch_max\": 500.0,\n",
    "        \"Pdis_max\": 500.0,\n",
    "        \"capex_E\": 250000.0,         # placeholder\n",
    "        \"capex_Pch\": 60000.0,        # placeholder\n",
    "        \"capex_Pdis\": 60000.0,       # placeholder\n",
    "        \"fom_E\": 5000.0,             # placeholder\n",
    "        \"fom_P\": 7000.0,             # placeholder\n",
    "        \"vom_ch\": 2.0,\n",
    "        \"vom_dis\": 2.0,\n",
    "        \"subsidy_on_discharge_eur_per_MWh_e\": 0.0,\n",
    "        \"subsidy_on_h2_MWh_HHV\": 0.0,\n",
    "        # SPRILA example (big company): 70 €/kWh => 70,000 €/MWh (cap applies)\n",
    "        \"capex_grant_per_MWh_store\": 70000.0,   # €/MWh_store\n",
    "        \"capex_grant_cap_total\": 350000.0,      # € cap (from your doc table)\n",
    "        \"capex_discount_factor\": 0.10,          # EIA proxy if you apply it\n",
    "        \"salvage_frac\": 0.10,\n",
    "    },\n",
    "    \"Hydrogen\": {\n",
    "        # Interpret SOC as stored H2 energy (MWh_HHV).\n",
    "        # eta_ch: electricity -> H2_HHV conversion\n",
    "        # eta_dis: H2_HHV -> electricity conversion\n",
    "        \"eta_ch\": 0.70,\n",
    "        \"eta_dis\": 0.55,\n",
    "        \"self_dis\": 0.0,\n",
    "        \"Emax\": 20000.0,             # MWh_HHV\n",
    "        \"Pch_max\": 1000.0,           # MW_e into electrolyser\n",
    "        \"Pdis_max\": 500.0,           # MW_e out from fuel cell/turbine\n",
    "        \"capex_E\": 20000.0,          # €/MWh_HHV storage (placeholder)\n",
    "        \"capex_Pch\": 500000.0,       # €/MW_e electrolysis (placeholder)\n",
    "        \"capex_Pdis\": 700000.0,      # €/MW_e power block (placeholder)\n",
    "        \"fom_E\": 300.0,              # €/MWh_HHV/year (placeholder)\n",
    "        \"fom_P\": 15000.0,            # €/MW/year (placeholder)\n",
    "        \"vom_ch\": 1.0,\n",
    "        \"vom_dis\": 3.0,\n",
    "        \"subsidy_on_discharge_eur_per_MWh_e\": 0.0,\n",
    "        # Apply subsidy on produced H2_HHV over 15 years (from your doc)\n",
    "        \"subsidy_on_h2_MWh_HHV\": h2_sub_eur_per_MWh_HHV,\n",
    "        \"capex_grant_per_MWh_store\": 0.0,\n",
    "        \"capex_grant_cap_total\": 0.0,\n",
    "        \"capex_discount_factor\": 0.0,\n",
    "        \"salvage_frac\": 0.05,\n",
    "    },\n",
    "}\n",
    "\n",
    "# Economic settings (fill with course-consistent assumptions)\n",
    "discount_rate = 0.08\n",
    "H_years = 25\n",
    "subsidy_years = 15\n",
    "PW_op = pw_factor(discount_rate, H_years)\n",
    "PW_sub = pw_factor(discount_rate, min(H_years, subsidy_years))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "64740dc3-1e03-45a6-90a4-48729f8be0f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_one_tech(tech_name, prices, surplus, scenario_prob, dt, year_scale,\n",
    "                   discount_rate, H_years, subsidy_years, output_flag=0,\n",
    "                   time_limit=600, prevent_simultaneous=True,\n",
    "                   force_frac_ub=None, force_min_E=None, force_min_P=None):\n",
    "\n",
    "    td = TECH[tech_name]\n",
    "    prices = as_2d(prices)\n",
    "    surplus = as_2d(surplus)\n",
    "    S, T = prices.shape\n",
    "\n",
    "    PW_op = pw_factor(discount_rate, H_years)\n",
    "    PW_sub = pw_factor(discount_rate, min(H_years, subsidy_years))\n",
    "\n",
    "    m = gp.Model(f\"storage_{tech_name}\")\n",
    "    m.Params.OutputFlag = output_flag\n",
    "    if time_limit is not None:\n",
    "        m.Params.TimeLimit = time_limit\n",
    "\n",
    "    # If we add binaries, this becomes a MILP. These settings keep it stable/fast for your size.\n",
    "    if prevent_simultaneous:\n",
    "        m.Params.MIPGap = 0.05\n",
    "\n",
    "    # -------------------------\n",
    "    # Design vars\n",
    "    # -------------------------\n",
    "    E = m.addVar(lb=0.0, ub=td[\"Emax\"], name=\"E\")                 # MWh_store (or MWh_HHV for hydrogen)\n",
    "    Pch = m.addVar(lb=0.0, ub=td[\"Pch_max\"], name=\"Pch\")          # MW\n",
    "    Pdis = m.addVar(lb=0.0, ub=td[\"Pdis_max\"], name=\"Pdis\")       # MW\n",
    "\n",
    "    # Optional one-time CAPEX grant (linearised min(rate*E, cap))\n",
    "    grant = m.addVar(lb=0.0, ub=td[\"capex_grant_cap_total\"], name=\"capex_grant\")\n",
    "    if td[\"capex_grant_cap_total\"] > 0 and td[\"capex_grant_per_MWh_store\"] > 0:\n",
    "        m.addConstr(grant <= td[\"capex_grant_per_MWh_store\"] * E, name=\"grant_rate\")\n",
    "        m.addConstr(grant <= td[\"capex_grant_cap_total\"], name=\"grant_cap\")\n",
    "    else:\n",
    "        m.addConstr(grant == 0.0, name=\"no_grant\")\n",
    "\n",
    "    # -------------------------\n",
    "    # Operational vars\n",
    "    # -------------------------\n",
    "    c = m.addVars(S, T, lb=0.0, name=\"c\")       # MW charging\n",
    "    d = m.addVars(S, T, lb=0.0, name=\"d\")       # MW discharging\n",
    "    soc = m.addVars(S, T+1, lb=0.0, name=\"soc\") # MWh state of charge\n",
    "\n",
    "    # NEW: mode binaries to prevent simultaneous charge/discharge\n",
    "    # z[s,t] = 1 => charging allowed, discharging forced to 0\n",
    "    # z[s,t] = 0 => discharging allowed, charging forced to 0\n",
    "    if prevent_simultaneous:\n",
    "        z = m.addVars(S, T, vtype=GRB.BINARY, name=\"isCharging\")\n",
    "    else:\n",
    "        z = None\n",
    "\n",
    "    eta_ch = td[\"eta_ch\"]\n",
    "    eta_dis = td[\"eta_dis\"]\n",
    "    self_dis = td[\"self_dis\"]\n",
    "\n",
    "    # Big-M constants (must be constants, not variables)\n",
    "    M_ch = float(td[\"Pch_max\"])\n",
    "    M_dis = float(td[\"Pdis_max\"])\n",
    "\n",
    "    # -------------------------\n",
    "    # Constraints\n",
    "    # -------------------------\n",
    "    for s in range(S):\n",
    "        m.addConstr(soc[s, 0] <= E, name=f\"soc0_ub[{s}]\")\n",
    "        m.addConstr(soc[s, 0] >= 0.0, name=f\"soc0_lb[{s}]\")\n",
    "        m.addConstr(soc[s, T] == soc[s, 0], name=f\"cyclic[{s}]\")\n",
    "\n",
    "        for t in range(T):\n",
    "            m.addConstr(soc[s, t] <= E, name=f\"soc_ub[{s},{t}]\")\n",
    "\n",
    "            # Power bounds by installed capacities\n",
    "            m.addConstr(c[s, t] <= Pch, name=f\"c_ub_by_Pch[{s},{t}]\")\n",
    "            m.addConstr(d[s, t] <= Pdis, name=f\"d_ub_by_Pdis[{s},{t}]\")\n",
    "\n",
    "            # Charging limited by available surplus/curtailment\n",
    "            m.addConstr(c[s, t] <= float(surplus[s, t]), name=f\"surplus[{s},{t}]\")\n",
    "\n",
    "            # NEW: forbid simultaneous charging and discharging\n",
    "            if prevent_simultaneous:\n",
    "                m.addConstr(c[s, t] <= M_ch * z[s, t], name=f\"noSim_c[{s},{t}]\")\n",
    "                m.addConstr(d[s, t] <= M_dis * (1 - z[s, t]), name=f\"noSim_d[{s},{t}]\")\n",
    "\n",
    "            # SOC dynamics\n",
    "            m.addConstr(\n",
    "                soc[s, t+1]\n",
    "                ==\n",
    "                (1.0 - self_dis) * soc[s, t]\n",
    "                + eta_ch * c[s, t] * dt\n",
    "                - (d[s, t] * dt) / eta_dis,\n",
    "                name=f\"dyn[{s},{t}]\"\n",
    "            )\n",
    "    # ============================================================\n",
    "    # Counterfactual: force a non-zero investment to explain \"why 0?\"\n",
    "    # ============================================================\n",
    "\n",
    "    # Ensure variables have valid internal indices before reading attributes like UB\n",
    "    m.update()\n",
    "\n",
    "    def _safe_ub(var, td, fallback_keys):\n",
    "        \"\"\"Try Var.UB; if that fails, fall back to tech-data keys; else +inf.\"\"\"\n",
    "        try:\n",
    "            return float(var.UB)\n",
    "        except Exception:\n",
    "            for k in fallback_keys:\n",
    "                if k in td and td[k] is not None:\n",
    "                    try:\n",
    "                        return float(td[k])\n",
    "                    except Exception:\n",
    "                        pass\n",
    "            return float(\"inf\")\n",
    "\n",
    "    def _finite_pos(x):\n",
    "        try:\n",
    "            x = float(x)\n",
    "            return np.isfinite(x) and x > 0.0\n",
    "        except Exception:\n",
    "            return False\n",
    "\n",
    "    applied_any = False\n",
    "\n",
    "    if force_frac_ub is not None:\n",
    "        ub_E   = _safe_ub(E,   td, [\"E_max\", \"E_ub\", \"E_max_MWh\", \"E_max_store\"])\n",
    "        ub_Pch = _safe_ub(Pch, td, [\"Pch_max\", \"Pch_ub\", \"P_ch_max\", \"P_max_ch\"])\n",
    "        ub_Pdis= _safe_ub(Pdis,td, [\"Pdis_max\",\"Pdis_ub\",\"P_dis_max\",\"P_max_dis\"])\n",
    "\n",
    "        if _finite_pos(ub_E):\n",
    "            m.addConstr(E >= float(force_frac_ub) * ub_E, name=\"force_E_fracUB\")\n",
    "            applied_any = True\n",
    "        if _finite_pos(ub_Pch):\n",
    "            m.addConstr(Pch >= float(force_frac_ub) * ub_Pch, name=\"force_Pch_fracUB\")\n",
    "            applied_any = True\n",
    "        if _finite_pos(ub_Pdis):\n",
    "            m.addConstr(Pdis >= float(force_frac_ub) * ub_Pdis, name=\"force_Pdis_fracUB\")\n",
    "            applied_any = True\n",
    "\n",
    "        # Fallback: if we couldn't apply any UB-based constraint, still force some investment\n",
    "        if not applied_any and force_min_E is None and force_min_P is None:\n",
    "            eps = 1e-3\n",
    "            m.addConstr(E + Pch + Pdis >= eps, name=\"force_some_invest_eps\")\n",
    "\n",
    "    if force_min_E is not None:\n",
    "        m.addConstr(E >= float(force_min_E), name=\"force_E_min\")\n",
    "\n",
    "    if force_min_P is not None:\n",
    "        m.addConstr(Pch + Pdis >= float(force_min_P), name=\"force_P_total_min\")\n",
    "\n",
    "\n",
    "    # -------------------------\n",
    "    # Economics\n",
    "    # -------------------------\n",
    "    capex_raw = td[\"capex_E\"] * E + td[\"capex_Pch\"] * Pch + td[\"capex_Pdis\"] * Pdis\n",
    "    capex_eff = (1.0 - td[\"capex_discount_factor\"]) * capex_raw - grant\n",
    "\n",
    "    fom = td[\"fom_E\"] * E + td[\"fom_P\"] * (Pch + Pdis)\n",
    "\n",
    "    sub_on_dis = td[\"subsidy_on_discharge_eur_per_MWh_e\"]\n",
    "    sub_on_h2  = td[\"subsidy_on_h2_MWh_HHV\"]\n",
    "\n",
    "    exp_annual_cash = gp.LinExpr()\n",
    "    for s in range(S):\n",
    "        prob = float(scenario_prob[s])\n",
    "        scen_expr = gp.LinExpr()\n",
    "\n",
    "        for t in range(T):\n",
    "            price = float(prices[s, t])\n",
    "\n",
    "            # arbitrage revenue: sell d, buy c\n",
    "            scen_expr += year_scale * (price * (d[s, t] - c[s, t]) * dt)\n",
    "\n",
    "            # variable O&M\n",
    "            scen_expr += year_scale * (-(td[\"vom_ch\"] * c[s, t] * dt + td[\"vom_dis\"] * d[s, t] * dt))\n",
    "\n",
    "            # subsidy on discharge (if any)\n",
    "            if sub_on_dis != 0.0:\n",
    "                scen_expr += year_scale * (sub_on_dis * d[s, t] * dt)\n",
    "\n",
    "            # subsidy on H2 produced (if any): eta_ch * charged electricity\n",
    "            if sub_on_h2 != 0.0:\n",
    "                scen_expr += year_scale * (sub_on_h2 * (eta_ch * c[s, t] * dt))\n",
    "\n",
    "        scen_expr += -fom\n",
    "        exp_annual_cash += prob * scen_expr\n",
    "\n",
    "    # subsidy-only part for correct 15y vs H horizon discounting\n",
    "    exp_annual_subsidy = gp.LinExpr()\n",
    "    for s in range(S):\n",
    "        prob = float(scenario_prob[s])\n",
    "        sub_expr = gp.LinExpr()\n",
    "        for t in range(T):\n",
    "            if sub_on_dis != 0.0:\n",
    "                sub_expr += year_scale * (sub_on_dis * d[s, t] * dt)\n",
    "            if sub_on_h2 != 0.0:\n",
    "                sub_expr += year_scale * (sub_on_h2 * (eta_ch * c[s, t] * dt))\n",
    "        exp_annual_subsidy += prob * sub_expr\n",
    "\n",
    "    salvage = td[\"salvage_frac\"] * capex_eff\n",
    "    salvage_pv = salvage / ((1.0 + discount_rate) ** H_years)\n",
    "\n",
    "    NPV = -capex_eff + PW_op * exp_annual_cash + (PW_sub - PW_op) * exp_annual_subsidy + salvage_pv\n",
    "    m.setObjective(NPV, GRB.MAXIMIZE)\n",
    "    m.Params.OutputFlag = int(output_flag)\n",
    "    m.Params.LogToConsole = int(output_flag)\n",
    "    m.Params.TimeLimit = float(time_limit)\n",
    "\n",
    "    t0 = time.perf_counter()\n",
    "    m.optimize()\n",
    "    runtime_sec = time.perf_counter() - t0\n",
    "\n",
    "    if m.Status not in (GRB.OPTIMAL, GRB.TIME_LIMIT, GRB.SUBOPTIMAL):\n",
    "        return {\"tech\": tech_name, \"status\": int(m.Status), \"npv\": None}\n",
    "\n",
    "    E_val = float(E.X)\n",
    "    Pch_val = float(Pch.X)\n",
    "    Pdis_val = float(Pdis.X)\n",
    "    npv_val = float(m.ObjVal)\n",
    "\n",
    "    c0 = np.array([c[0, t].X for t in range(T)])\n",
    "    d0 = np.array([d[0, t].X for t in range(T)])\n",
    "    soc0 = np.array([soc[0, t].X for t in range(T+1)])\n",
    "    soc_pct = (soc0[:-1] / E_val * 100.0) if E_val > 1e-9 else np.zeros(T)\n",
    "\n",
    "    out = {\n",
    "        \"tech\": tech_name,\n",
    "        \"status\": int(m.Status),\n",
    "        \"npv\": npv_val,\n",
    "        \"E\": E_val,\n",
    "        \"Pch\": Pch_val,\n",
    "        \"Pdis\": Pdis_val,\n",
    "        \"dispatch_s0\": pd.DataFrame({\n",
    "            \"t\": np.arange(T),\n",
    "            \"price\": prices[0],\n",
    "            \"surplus\": surplus[0],\n",
    "            \"charge_MW\": c0,\n",
    "            \"discharge_MW\": d0,\n",
    "            \"soc_MWh\": soc0[:-1],\n",
    "            \"soc_pct\": soc_pct,          # NEW\n",
    "        }),\n",
    "    }\n",
    "    \n",
    "\n",
    "    # Optional quick diagnostic: overlap should be zero by construction when prevent_simultaneous=True\n",
    "    if prevent_simultaneous:\n",
    "        out[\"simultaneous_hours_s0\"] = int(np.sum((c0 > 1e-6) & (d0 > 1e-6)))\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16dad337-c121-464e-bc62-9b956ce4824d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set parameter Username\n",
      "Set parameter LicenseID to value 2661894\n",
      "Academic license - for non-commercial use only - expires 2026-05-07\n",
      "Set parameter OutputFlag to value 1\n",
      "Set parameter TimeLimit to value 600\n",
      "Set parameter MIPGap to value 0.05\n",
      "Set parameter OutputFlag to value 1\n",
      "Set parameter LogToConsole to value 1\n",
      "Set parameter TimeLimit to value 600\n",
      "Gurobi Optimizer version 12.0.3 build v12.0.3rc0 (win64 - Windows 11+.0 (26200.2))\n",
      "\n",
      "CPU model: Intel(R) Core(TM) i7-10750H CPU @ 2.60GHz, instruction set [SSE2|AVX|AVX2]\n",
      "Thread count: 6 physical cores, 12 logical processors, using up to 12 threads\n",
      "\n",
      "Non-default parameters:\n",
      "TimeLimit  600\n",
      "MIPGap  0.05\n",
      "\n",
      "Optimize a model with 306616 rows, 175209 columns and 657026 nonzeros\n",
      "Model fingerprint: 0xeb73fc15\n",
      "Variable types: 131409 continuous, 43800 integer (43800 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [9e-01, 5e+02]\n",
      "  Objective range  [2e-02, 2e+05]\n",
      "  Bounds range     [1e+00, 5e+03]\n",
      "  RHS range        [2e+02, 6e+02]\n",
      "Found heuristic solution: objective -0.0000000\n",
      "Presolve removed 43816 rows and 6 columns\n",
      "Presolve time: 1.69s\n",
      "Presolved: 262800 rows, 175203 columns, 613200 nonzeros\n",
      "Variable types: 131403 continuous, 43800 integer (43800 binary)\n",
      "Root relaxation presolved: 219000 rows, 131403 columns, 525600 nonzeros\n",
      "\n",
      "Deterministic concurrent LP optimizer: primal simplex, dual simplex, and barrier\n",
      "Showing barrier log only...\n",
      "\n",
      "Root barrier log...\n",
      "\n",
      "Ordering time: 0.16s\n",
      "\n",
      "Barrier statistics:\n",
      " Dense cols : 3\n",
      " AA' NZ     : 4.818e+05\n",
      " Factor NZ  : 2.868e+06 (roughly 160 MB of memory)\n",
      " Factor Ops : 5.704e+07 (less than 1 second per iteration)\n",
      " Threads    : 1\n",
      "\n",
      "                  Objective                Residual\n",
      "Iter       Primal          Dual         Primal    Dual     Compl     Time\n",
      "   0   7.60664965e+08  1.62967672e+12  1.39e+02 1.12e+03  6.74e+06     6s\n",
      "   1   6.37390124e+08  1.69806888e+11  1.48e+01 1.61e+03  4.86e+05     6s\n",
      "   2   6.40914581e+08  2.84137244e+10  9.94e+00 1.60e+02  7.54e+04     6s\n",
      "   3   8.47543574e+08  8.46703787e+09  1.88e+00 3.09e+01  1.86e+04     7s\n",
      "   4   1.47221639e+09  3.81084734e+09  7.86e-01 6.61e+00  5.59e+03     7s\n",
      "   5   1.75191880e+09  3.02220672e+09  5.57e-01 2.67e+00  3.02e+03     8s\n",
      "   6   1.93994762e+09  2.81939140e+09  3.93e-01 1.67e+00  2.09e+03     8s\n",
      "   7   2.06456096e+09  2.71378292e+09  2.79e-01 1.16e+00  1.54e+03     8s\n",
      "   8   2.16811368e+09  2.56604975e+09  1.81e-01 5.80e-01  9.44e+02     8s\n",
      "   9   2.23615300e+09  2.47721003e+09  1.17e-01 3.09e-01  5.71e+02     9s\n",
      "  10   2.28159539e+09  2.42970419e+09  7.53e-02 1.17e-01  3.50e+02     9s\n",
      "  11   2.30943330e+09  2.40174128e+09  5.01e-02 4.61e-02  2.18e+02     9s\n",
      "  12   2.33128324e+09  2.38402711e+09  3.12e-02 7.17e-03  1.24e+02     9s\n",
      "  13   2.34920615e+09  2.37385290e+09  1.51e-02 3.89e-09  5.79e+01    10s\n",
      "  14   2.35555220e+09  2.37065695e+09  9.61e-03 2.81e-09  3.55e+01    10s\n",
      "  15   2.35874403e+09  2.36946982e+09  6.80e-03 3.46e-12  2.52e+01    10s\n",
      "  16   2.36007030e+09  2.36868113e+09  5.66e-03 3.54e-12  2.02e+01    10s\n",
      "  17   2.36206100e+09  2.36776727e+09  4.05e-03 3.15e-12  1.34e+01    10s\n",
      "  18   2.36315131e+09  2.36725753e+09  3.22e-03 1.26e-08  9.62e+00    11s\n",
      "  19   2.36424435e+09  2.36712150e+09  2.33e-03 1.24e-07  6.75e+00    11s\n",
      "  20   2.36468317e+09  2.36703812e+09  1.91e-03 3.32e-06  5.52e+00    11s\n",
      "  21   2.36501430e+09  2.36695278e+09  1.59e-03 6.27e-06  4.54e+00    12s\n",
      "  22   2.36529042e+09  2.36688290e+09  1.33e-03 6.14e-06  3.73e+00    12s\n",
      "  23   2.36570529e+09  2.36682551e+09  9.87e-04 1.81e-05  2.63e+00    12s\n",
      "  24   2.36612850e+09  2.36678492e+09  5.87e-04 3.65e-09  1.54e+00    13s\n",
      "  25   2.36631916e+09  2.36675727e+09  3.98e-04 3.48e-09  1.03e+00    13s\n",
      "  26   2.36660987e+09  2.36670856e+09  7.80e-05 3.07e-12  2.31e-01    14s\n",
      "  27   2.36665918e+09  2.36669024e+09  2.74e-05 3.64e-09  7.27e-02    14s\n",
      "  28   2.36668202e+09  2.36668819e+09  4.81e-06 4.56e-09  1.44e-02    14s\n",
      "  29   2.36668705e+09  2.36668745e+09  7.92e-07 1.26e-08  9.24e-04    15s\n",
      "  30   2.36668726e+09  2.36668727e+09  4.67e-08 1.26e-06  1.98e-05    15s\n",
      "  31   2.36668726e+09  2.36668726e+09  3.12e-08 1.40e-07  8.32e-10    15s\n",
      "\n",
      "Barrier solved model in 31 iterations and 15.27 seconds (6.37 work units)\n",
      "Optimal objective 2.36668726e+09\n",
      "\n",
      "\n",
      "Root crossover log...\n",
      "\n",
      "   44692 DPushes remaining with DInf 0.0000000e+00                15s\n",
      "       0 DPushes remaining with DInf 0.0000000e+00                17s\n",
      "\n",
      "      16 PPushes remaining with PInf 0.0000000e+00                17s\n",
      "       0 PPushes remaining with PInf 0.0000000e+00                17s\n",
      "\n",
      "  Push phase complete: Pinf 0.0000000e+00, Dinf 3.6933141e-09     17s\n",
      "\n",
      "\n",
      "Root simplex log...\n",
      "\n",
      "Iteration    Objective       Primal Inf.    Dual Inf.      Time\n",
      "   33090    2.3666873e+09   0.000000e+00   0.000000e+00     17s\n",
      "Concurrent spin time: 0.01s\n",
      "\n",
      "Solved with barrier\n",
      "   33090    2.3666873e+09   0.000000e+00   0.000000e+00     18s\n",
      "\n",
      "Root relaxation: objective 2.366687e+09, 33090 iterations, 13.67 seconds (5.19 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0 2.3667e+09    0 13605   -0.00000 2.3667e+09      -     -   20s\n",
      "H    0     0                    2.133966e+09 2.3667e+09  10.9%     -   46s\n",
      "H    0     0                    2.134053e+09 2.3667e+09  10.9%     -   47s\n",
      "     0     0 2.3411e+09    0 12278 2.1341e+09 2.3411e+09  9.70%     -   59s\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import inspect\n",
    "from IPython.display import display\n",
    "\n",
    "# -------------------------\n",
    "# 1) Baseline solves\n",
    "# -------------------------\n",
    "results = []\n",
    "for tech_name in TECH.keys():\n",
    "    res = solve_one_tech(\n",
    "        tech_name=tech_name,\n",
    "        prices=prices,\n",
    "        surplus=surplus,\n",
    "        scenario_prob=scenario_prob,\n",
    "        dt=dt,\n",
    "        year_scale=year_scale,\n",
    "        discount_rate=discount_rate,\n",
    "        H_years=H_years,\n",
    "        subsidy_years=subsidy_years,\n",
    "        output_flag=1,\n",
    "        time_limit=600.0,\n",
    "        prevent_simultaneous=True,\n",
    "    )\n",
    "    results.append(res)\n",
    "\n",
    "summary = pd.DataFrame([{\n",
    "    \"tech\": r[\"tech\"],\n",
    "    \"status\": r[\"status\"],\n",
    "    \"NPV\": r.get(\"npv\", np.nan),\n",
    "    \"E (MWh_store)\": r.get(\"E\", np.nan),\n",
    "    \"Pch (MW)\": r.get(\"Pch\", np.nan),\n",
    "    \"Pdis (MW)\": r.get(\"Pdis\", np.nan),\n",
    "    \"simultaneous_hours_s0\": r.get(\"simultaneous_hours_s0\", np.nan),\n",
    "} for r in results]).sort_values(\"NPV\", ascending=False)\n",
    "\n",
    "# Mark true \"do-nothing\" solutions\n",
    "NPV_TOL = 1e-6\n",
    "CAP_TOL = 1e-6\n",
    "summary[\"is_zero_solution\"] = (\n",
    "    summary[\"NPV\"].apply(lambda x: np.isfinite(x) and abs(float(x)) <= NPV_TOL)\n",
    "    & summary[\"E (MWh_store)\"].fillna(0.0).abs().le(CAP_TOL)\n",
    "    & summary[\"Pch (MW)\"].fillna(0.0).abs().le(CAP_TOL)\n",
    "    & summary[\"Pdis (MW)\"].fillna(0.0).abs().le(CAP_TOL)\n",
    ")\n",
    "\n",
    "display(summary)\n",
    "\n",
    "zero_techs = summary.loc[summary[\"is_zero_solution\"], \"tech\"].tolist()\n",
    "print(\"Technologieën met 0-oplossing:\", zero_techs)\n",
    "\n",
    "# -------------------------\n",
    "# 2) Counterfactual forced-investment solves for 0-techs\n",
    "# -------------------------\n",
    "cf_summary = pd.DataFrame()\n",
    "best_cf_summary = pd.DataFrame()\n",
    "\n",
    "if len(zero_techs) > 0:\n",
    "    # This requires that solve_one_tech has been patched to accept force_frac_ub (and/or force_min_*).\n",
    "    sig = inspect.signature(solve_one_tech)\n",
    "    if \"force_frac_ub\" not in sig.parameters:\n",
    "        raise RuntimeError(\n",
    "            \"solve_one_tech mist parameter 'force_frac_ub'. \"\n",
    "            \"Patch eerst solve_one_tech met force_frac_ub/force_min_E/force_min_P support.\"\n",
    "        )\n",
    "\n",
    "    fracs = [0.05, 0.10, 0.25]  # adjust if desired\n",
    "    cf_results = []\n",
    "\n",
    "    for tech_name in zero_techs:\n",
    "        for frac in fracs:\n",
    "            res_cf = solve_one_tech(\n",
    "                tech_name=tech_name,\n",
    "                prices=prices,\n",
    "                surplus=surplus,\n",
    "                scenario_prob=scenario_prob,\n",
    "                dt=dt,\n",
    "                year_scale=year_scale,\n",
    "                discount_rate=discount_rate,\n",
    "                H_years=H_years,\n",
    "                subsidy_years=subsidy_years,\n",
    "                output_flag=0,\n",
    "                time_limit=60.0,\n",
    "                prevent_simultaneous=True,\n",
    "                force_frac_ub=frac,     # <-- forces non-zero invest (fraction of UB)\n",
    "            )\n",
    "            res_cf[\"force_frac_ub\"] = frac\n",
    "            cf_results.append(res_cf)\n",
    "\n",
    "    cf_summary = pd.DataFrame([{\n",
    "        \"tech\": r[\"tech\"],\n",
    "        \"force_frac_ub\": r.get(\"force_frac_ub\", np.nan),\n",
    "        \"status\": r.get(\"status\", None),\n",
    "        \"NPV\": r.get(\"npv\", np.nan),\n",
    "        \"E (MWh_store)\": r.get(\"E\", np.nan),\n",
    "        \"Pch (MW)\": r.get(\"Pch\", np.nan),\n",
    "        \"Pdis (MW)\": r.get(\"Pdis\", np.nan),\n",
    "    } for r in cf_results]).sort_values([\"tech\", \"force_frac_ub\"])\n",
    "\n",
    "    print(\"\\nCounterfactuals (forced investment):\")\n",
    "    display(cf_summary)\n",
    "\n",
    "    # Pick best forced case per tech (highest NPV among forced cases)\n",
    "    best_cf_summary = (\n",
    "        cf_summary[np.isfinite(cf_summary[\"NPV\"])]\n",
    "        .sort_values([\"tech\", \"NPV\"], ascending=[True, False])\n",
    "        .groupby(\"tech\", as_index=False)\n",
    "        .head(1)\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "\n",
    "    print(\"\\nBest forced case per 0-tech (highest NPV among forced runs):\")\n",
    "    display(best_cf_summary)\n",
    "\n",
    "    # Show breakdowns for the best forced case (this is the \"why 0?\" evidence)\n",
    "    # Build lookup for the actual result dicts\n",
    "    cf_lookup = {(r[\"tech\"], r.get(\"force_frac_ub\", None)): r for r in cf_results}\n",
    "\n",
    "    for _, row in best_cf_summary.iterrows():\n",
    "        tech = row[\"tech\"]\n",
    "        frac = float(row[\"force_frac_ub\"])\n",
    "        rbest = cf_lookup.get((tech, frac), None)\n",
    "\n",
    "        print(\"\\n\" + \"=\" * 110)\n",
    "        print(f\"TECH: {tech} | forced frac_ub={frac:.2f}\")\n",
    "        print(f\"NPV={row['NPV']:.6g} | E={row['E (MWh_store)']:.6g} | Pch={row['Pch (MW)']:.6g} | Pdis={row['Pdis (MW)']:.6g}\")\n",
    "\n",
    "        print(\"\\nNPV breakdown (forced):\")\n",
    "        display(pd.Series((rbest or {}).get(\"npv_breakdown\", {})))\n",
    "\n",
    "        print(\"\\nScenario breakdown (forced):\")\n",
    "        display((rbest or {}).get(\"scenario_breakdown\", pd.DataFrame()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb3ef1c-29c5-419f-af61-0a0ec33491b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Battery', 7975027.174600467)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# =========================\n",
    "# 5) Best alternative + its dispatch (scenario 0)\n",
    "# =========================\n",
    "best = max([r for r in results if r[\"npv\"] is not None], key=lambda x: x[\"npv\"])\n",
    "best[\"tech\"], best[\"npv\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4784fe32-d67b-4d7f-b385-bb9ec0b22380",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8897fcd320334124ad7c82333a4a6fc8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntText(value=0, description='start t'), IntText(value=24, description='end t'))…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "df = best[\"dispatch_s0\"]\n",
    "\n",
    "t = df[\"t\"].to_numpy()\n",
    "price = df[\"price\"].to_numpy()\n",
    "charge = df[\"charge_MW\"].to_numpy()\n",
    "discharge = df[\"discharge_MW\"].to_numpy()\n",
    "\n",
    "soc_mwh = df[\"soc_MWh\"].to_numpy()\n",
    "soc_pct = df[\"soc_pct\"].to_numpy()\n",
    "\n",
    "t_min = int(np.nanmin(t))\n",
    "t_max = int(np.nanmax(t))\n",
    "\n",
    "default_start = max(t_min, 0)\n",
    "default_end = min(t_max, default_start + 24)\n",
    "if default_end <= default_start:\n",
    "    default_end = min(t_max, default_start + 1)\n",
    "\n",
    "def build_fig():\n",
    "    fig = make_subplots(\n",
    "        rows=3, cols=1,\n",
    "        shared_xaxes=True,\n",
    "        vertical_spacing=0.06,\n",
    "        subplot_titles=(\n",
    "            f\"Scenario 0 price - {best['tech']}\",\n",
    "            f\"Charge / discharge - {best['tech']}\",\n",
    "            f\"State of charge - {best['tech']}\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "    fig.add_trace(go.Scatter(x=t, y=price, mode=\"lines\", name=\"Price (€/MWh)\"), row=1, col=1)\n",
    "    fig.add_trace(go.Scatter(x=t, y=charge, mode=\"lines\", name=\"Charge (MW)\"), row=2, col=1)\n",
    "    fig.add_trace(go.Scatter(x=t, y=discharge, mode=\"lines\", name=\"Discharge (MW)\"), row=2, col=1)\n",
    "    fig.add_trace(go.Scatter(x=t, y=soc_pct, mode=\"lines\", name=\"SOC (%)\"), row=3, col=1)\n",
    "\n",
    "    fig.update_yaxes(title_text=\"€/MWh\", row=1, col=1)\n",
    "    fig.update_yaxes(title_text=\"MW\", row=2, col=1)\n",
    "    fig.update_yaxes(title_text=\"Energy\", row=3, col=1)\n",
    "    fig.update_yaxes(title_text=\"SOC (%)\", row=3, col=1, range=[0, 100])\n",
    "    fig.update_xaxes(title_text=\"t\", row=3, col=1)\n",
    "\n",
    "    fig.update_layout(\n",
    "        hovermode=\"x unified\",\n",
    "        height=850,\n",
    "        legend=dict(orientation=\"h\", yanchor=\"bottom\", y=1.02, xanchor=\"left\", x=0),\n",
    "    )\n",
    "\n",
    "    # Optional: range slider on bottom axis (still useful in addition to manual range)\n",
    "    fig.update_xaxes(rangeslider_visible=True, row=3, col=1)\n",
    "    return fig\n",
    "\n",
    "# ---- Controls (start/end inputs + sliders) ----\n",
    "start_box = widgets.IntText(value=default_start, description=\"start t\")\n",
    "end_box   = widgets.IntText(value=default_end, description=\"end t\")\n",
    "\n",
    "start_slider = widgets.IntSlider(\n",
    "    value=default_start, min=t_min, max=t_max-1, step=1,\n",
    "    description=\"start\", continuous_update=False, layout=widgets.Layout(width=\"700px\")\n",
    ")\n",
    "end_slider = widgets.IntSlider(\n",
    "    value=default_end, min=t_min+1, max=t_max, step=1,\n",
    "    description=\"end\", continuous_update=False, layout=widgets.Layout(width=\"700px\")\n",
    ")\n",
    "\n",
    "out = widgets.Output()\n",
    "_lock = {\"busy\": False}\n",
    "\n",
    "def clamp_and_sync(start, end):\n",
    "    start = int(max(t_min, min(start, t_max - 1)))\n",
    "    end   = int(max(start + 1, min(end, t_max)))\n",
    "\n",
    "    # keep end slider feasible\n",
    "    end_slider.min = start + 1\n",
    "    if end < end_slider.min:\n",
    "        end = end_slider.min\n",
    "\n",
    "    return start, end\n",
    "\n",
    "def redraw(start, end):\n",
    "    fig = build_fig()\n",
    "    fig.update_xaxes(range=[start, end])  # applies to all shared x-axes\n",
    "    with out:\n",
    "        clear_output(wait=True)\n",
    "        display(fig)\n",
    "\n",
    "def on_any_change(_):\n",
    "    if _lock[\"busy\"]:\n",
    "        return\n",
    "    _lock[\"busy\"] = True\n",
    "    try:\n",
    "        # take values from boxes (authoritative)\n",
    "        start, end = clamp_and_sync(start_box.value, end_box.value)\n",
    "\n",
    "        # sync everything\n",
    "        start_box.value = start\n",
    "        end_box.value = end\n",
    "        start_slider.value = start\n",
    "        end_slider.value = end\n",
    "\n",
    "        redraw(start, end)\n",
    "    finally:\n",
    "        _lock[\"busy\"] = False\n",
    "\n",
    "def on_slider_change(_):\n",
    "    if _lock[\"busy\"]:\n",
    "        return\n",
    "    _lock[\"busy\"] = True\n",
    "    try:\n",
    "        start, end = clamp_and_sync(start_slider.value, end_slider.value)\n",
    "\n",
    "        start_box.value = start\n",
    "        end_box.value = end\n",
    "        start_slider.value = start\n",
    "        end_slider.value = end\n",
    "\n",
    "        redraw(start, end)\n",
    "    finally:\n",
    "        _lock[\"busy\"] = False\n",
    "\n",
    "start_box.observe(on_any_change, names=\"value\")\n",
    "end_box.observe(on_any_change, names=\"value\")\n",
    "start_slider.observe(on_slider_change, names=\"value\")\n",
    "end_slider.observe(on_slider_change, names=\"value\")\n",
    "\n",
    "# Initial draw\n",
    "start0, end0 = clamp_and_sync(default_start, default_end)\n",
    "start_box.value, end_box.value = start0, end0\n",
    "start_slider.value, end_slider.value = start0, end0\n",
    "redraw(start0, end0)\n",
    "\n",
    "display(widgets.VBox([\n",
    "    widgets.HBox([start_box, end_box]),\n",
    "    start_slider,\n",
    "    end_slider,\n",
    "    out\n",
    "]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ed9e8d5-5975-4a00-8e8c-e80770c0baed",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float64(2031575.419357773),\n",
       " np.float64(1422102.793550441),\n",
       " np.float64(539830220.4317473))"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "td = TECH[\"Hydrogen\"]\n",
    "df = best[\"dispatch_s0\"]\n",
    "year_scale = 8760/(T*dt)\n",
    "\n",
    "annual_charge_MWh = year_scale * (df[\"charge_MW\"].to_numpy() * dt).sum()\n",
    "annual_h2_MWh_HHV = td[\"eta_ch\"] * annual_charge_MWh\n",
    "annual_h2_subsidy = TECH[\"Hydrogen\"][\"subsidy_on_h2_MWh_HHV\"] * annual_h2_MWh_HHV\n",
    "\n",
    "annual_charge_MWh, annual_h2_MWh_HHV, annual_h2_subsidy\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
