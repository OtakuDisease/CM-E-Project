{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "783ea46f-4a01-4b98-b771-5e62c3b7f4ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# 0) Imports\n",
    "# =========================\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "try:\n",
    "    import gurobipy as gp\n",
    "    from gurobipy import GRB\n",
    "except Exception as e:\n",
    "    raise RuntimeError(\n",
    "        \"This notebook cell requires gurobipy + a working Gurobi license.\\n\"\n",
    "        f\"Import error: {repr(e)}\"\n",
    "    )\n",
    "\n",
    "# -------------------------\n",
    "# Helpers\n",
    "# -------------------------\n",
    "def pw_factor(r: float, H: int) -> float:\n",
    "    \"\"\"Present-worth factor P/A(r,H).\"\"\"\n",
    "    if H <= 0:\n",
    "        return 0.0\n",
    "    if abs(r) < 1e-12:\n",
    "        return float(H)\n",
    "    return (1.0 - (1.0 + r) ** (-H)) / r\n",
    "\n",
    "def as_2d(a):\n",
    "    a = np.asarray(a)\n",
    "    if a.ndim == 1:\n",
    "        return a[None, :]\n",
    "    return a\n",
    "\n",
    "# -------------------------\n",
    "# Cashflow helpers (construction delays, drift, CAPEX schedules)\n",
    "# -------------------------\n",
    "def pw_factor_shifted(r: float, H: int, start_delay_years: int = 0) -> float:\n",
    "    \"\"\"Present-worth factor for an annual cashflow received at end of each year,\n",
    "    starting after `start_delay_years` full years (i.e., first cashflow at end of year start_delay_years+1).\"\"\"\n",
    "    start_delay_years = int(max(0, start_delay_years))\n",
    "    if H <= start_delay_years:\n",
    "        return 0.0\n",
    "    return (1.0 + r) ** (-start_delay_years) * pw_factor(r, H - start_delay_years)\n",
    "\n",
    "def pw_factor_growth_shifted(r: float, g: float, H: int, start_delay_years: int = 0) -> float:\n",
    "    \"\"\"Present-worth factor for an annual cashflow received at end of each year that grows by (1+g) per year.\n",
    "    Growth applies to the *cashflow level* in year k relative to year 0 (k=0..H-1).\n",
    "    Cashflows start after `start_delay_years` full years (first at end of year start_delay_years+1).\"\"\"\n",
    "    start_delay_years = int(max(0, start_delay_years))\n",
    "    if H <= start_delay_years:\n",
    "        return 0.0\n",
    "\n",
    "    # PV = sum_{k=start_delay..H-1} (1+g)^k / (1+r)^{k+1} = (1/(1+r)) * sum_{k=start_delay..H-1} q^k\n",
    "    if abs(r) < 1e-12:\n",
    "        # r ~ 0: PV = sum_{k=start_delay..H-1} (1+g)^k\n",
    "        if abs(g) < 1e-12:\n",
    "            return float(H - start_delay_years)\n",
    "        return ((1.0 + g) ** start_delay_years) * ((1.0 + g) ** (H - start_delay_years) - 1.0) / g\n",
    "\n",
    "    q = (1.0 + g) / (1.0 + r)\n",
    "    if abs(q - 1.0) < 1e-12:\n",
    "        # q ~ 1 => each term is ~1/(1+r); start_delay adds a q^start_delay factor ~1\n",
    "        return (H - start_delay_years) / (1.0 + r)\n",
    "\n",
    "    geom = (q ** start_delay_years) * (1.0 - q ** (H - start_delay_years)) / (1.0 - q)\n",
    "    return geom / (1.0 + r)\n",
    "\n",
    "def build_capex_multiplier_series(\n",
    "    H: int,\n",
    "    lifetime_years: int | None,\n",
    "    construction_years: int = 0,\n",
    "    capex_payment_profile: list[float] | None = None,\n",
    "    replacement_required: bool = True,\n",
    "    capex_escalation_annual: float = 0.0,\n",
    ") -> np.ndarray:\n",
    "    \"\"\"Return an array mult[y] such that PV(CAPEX) = CAPEX_base * sum_y mult[y] / (1+r)^y.\n",
    "\n",
    "    - CAPEX_base is the (discounted/grant-adjusted) CAPEX associated with the chosen design (E,Pch,Pdis).\n",
    "    - construction_years spreads each build over multiple years (payments at the *start* of each year y).\n",
    "    - lifetime_years triggers reinvestment every `lifetime_years` (if replacement_required=True).\n",
    "    - capex_escalation_annual scales replacement CAPEX at install year y0 by (1+capex_escalation_annual)^y0.\n",
    "    \"\"\"\n",
    "    H = int(H)\n",
    "    if H <= 0:\n",
    "        return np.zeros(0, dtype=float)\n",
    "\n",
    "    construction_years = int(max(0, construction_years))\n",
    "    if construction_years == 0:\n",
    "        construction_years = 1\n",
    "\n",
    "    if capex_payment_profile is None:\n",
    "        capex_payment_profile = [1.0 / construction_years] * construction_years\n",
    "    if len(capex_payment_profile) != construction_years:\n",
    "        raise ValueError(\"capex_payment_profile length must equal construction_years (after zero->one adjustment).\")\n",
    "    if abs(sum(capex_payment_profile) - 1.0) > 1e-6:\n",
    "        # Normalise safely\n",
    "        s = float(sum(capex_payment_profile))\n",
    "        capex_payment_profile = [float(x) / s for x in capex_payment_profile]\n",
    "\n",
    "    if lifetime_years is None or lifetime_years <= 0 or (not replacement_required):\n",
    "        install_years = [0]\n",
    "    else:\n",
    "        L = int(lifetime_years)\n",
    "        install_years = list(range(0, H, L))\n",
    "\n",
    "    mult = np.zeros(H, dtype=float)\n",
    "    for y0 in install_years:\n",
    "        growth = (1.0 + capex_escalation_annual) ** y0\n",
    "        for j, frac in enumerate(capex_payment_profile):\n",
    "            y = y0 + j\n",
    "            if y >= H:\n",
    "                break\n",
    "            mult[y] += float(frac) * growth\n",
    "    return mult\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "95abdafa-ac1d-4d33-8ce7-5362c94531f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_hourly_profile_from_month_hour_csv(\n",
    "    csv_path: str = \"gemini_avg_power_month_hour_2017_2019_long.csv\",\n",
    "    month_col: str = \"month\",\n",
    "    hour_col: str = \"hour\",\n",
    "    value_col: str = \"avg_power\",\n",
    "    base_year: int = 2021,     # non-leap year => 8760 hours\n",
    "    tz: str = \"UTC\",\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Converts a (month, hour)->value table (288 rows) into a chronological 8760-hour profile.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    profile : np.ndarray shape (8760,)\n",
    "        Hourly values for a typical year.\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(csv_path)\n",
    "\n",
    "    required = {month_col, hour_col, value_col}\n",
    "    missing = required - set(df.columns)\n",
    "    if missing:\n",
    "        raise ValueError(f\"Missing columns in {csv_path}: {missing}. Found: {list(df.columns)}\")\n",
    "\n",
    "    df = df[[month_col, hour_col, value_col]].copy()\n",
    "    df[month_col] = df[month_col].astype(int)\n",
    "    df[hour_col] = df[hour_col].astype(int)\n",
    "    df[value_col] = df[value_col].astype(float)\n",
    "\n",
    "    # Ensure full 12x24 coverage\n",
    "    all_pairs = pd.MultiIndex.from_product(\n",
    "        [range(1, 13), range(0, 24)],\n",
    "        names=[month_col, hour_col]\n",
    "    )\n",
    "    df = df.set_index([month_col, hour_col]).reindex(all_pairs)\n",
    "\n",
    "    if df[value_col].isna().any():\n",
    "        missing_pairs = df[df[value_col].isna()].index.tolist()[:10]\n",
    "        raise ValueError(\n",
    "            f\"Incomplete month-hour table in {csv_path}. Missing examples: {missing_pairs}. \"\n",
    "            \"Need all 12*24=288 combinations.\"\n",
    "        )\n",
    "\n",
    "    # Create hourly timestamps for a non-leap year\n",
    "    idx = pd.date_range(\n",
    "        start=f\"{base_year}-01-01\",\n",
    "        end=f\"{base_year+1}-01-01\",\n",
    "        freq=\"h\",\n",
    "        inclusive=\"left\",\n",
    "        tz=tz\n",
    "    )\n",
    "    if len(idx) != 8760:\n",
    "        raise RuntimeError(f\"Expected 8760 hours, got {len(idx)} for base_year={base_year}.\")\n",
    "\n",
    "    tmp = pd.DataFrame({\"ts\": idx})\n",
    "    tmp[\"month\"] = tmp[\"ts\"].dt.month\n",
    "    tmp[\"hour\"] = tmp[\"ts\"].dt.hour\n",
    "\n",
    "    lut = df.reset_index().rename(columns={value_col: \"val\"})\n",
    "    tmp = tmp.merge(lut, on=[\"month\", \"hour\"], how=\"left\")\n",
    "\n",
    "    if tmp[\"val\"].isna().any():\n",
    "        raise RuntimeError(\"Mapping month-hour -> hourly series failed (NaNs after merge).\")\n",
    "\n",
    "    profile = tmp[\"val\"].to_numpy(dtype=float)\n",
    "    profile = np.clip(profile, 0.0, None)\n",
    "    return profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "10ef1a54-06b4-406a-a8f4-3b8beafd47d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scenario mode: synthetic_3cases | scenarios=['BEST_2020', 'NORMAL_SYNTH', 'BAD_2022']\n",
      "prices shape: (S,T)=(3,8760), year_scale=1\n",
      "price stats: min=-384.93, mean=118.27, max=1091.10\n",
      "Estimated price drift (annual): +18.2091%  (override via PRICE_DRIFT_ANNUAL_OVERRIDE)\n",
      "Surplus mode: gemini | surplus shape: (3, 8760)\n",
      "surplus stats: min=266.16, mean=417.05, max=558.43\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# 1) Price scenarios + surplus\n",
    "#\n",
    "# Goal:\n",
    "# - Keep the optimization model at \"one-year resolution\" (T=8760) but allow long horizons (H_years up to 100)\n",
    "# - Provide: (i) scenario year-profiles (best/normal/bad) and (ii) a drift parameter for long-run price level change\n",
    "# - Provide optional explicit multi-year price paths for reporting/plotting (not used directly in the MILP)\n",
    "# =========================\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "dt = 1.0\n",
    "hours_per_year = 8760\n",
    "\n",
    "# -------------------------\n",
    "# Paths (work both in notebook folder and in /mnt/data)\n",
    "# -------------------------\n",
    "def _resolve_path(p: str) -> str:\n",
    "    pth = Path(p)\n",
    "    if pth.exists():\n",
    "        return str(pth)\n",
    "    alt = Path(\"/mnt/data\") / p\n",
    "    if alt.exists():\n",
    "        return str(alt)\n",
    "    return str(pth)  # let pandas raise a clear error\n",
    "\n",
    "price_path = _resolve_path(\"day_ahead_prices_2020_2025_combined.csv\")\n",
    "ts_col = \"timestamp\"\n",
    "price_col = \"price\"\n",
    "\n",
    "# Gemini profile (month, hour) -> 8760 hourly profile\n",
    "gemini_power_path = _resolve_path(r\"C:\\Users\\User\\OneDrive\\Univerity of Twente\\IEM\\Module 6\\CM&E\\Project\\CM-E-Project\\gemini_avg_power_month_hour_2017_2019_long.csv\")\n",
    "\n",
    "# -------------------------\n",
    "# Test mode (optional)\n",
    "# -------------------------\n",
    "TEST_MODE = False          # True => use a short window\n",
    "TEST_START_UTC = \"2022-01-03 00:00:00\"  # inclusive, UTC\n",
    "TEST_DAYS = 7              # 7 days = 168 hours\n",
    "TEST_TILE_TO_YEAR = False  # True => repeat the short window to 8760 hours\n",
    "\n",
    "# -------------------------\n",
    "# Scenario mode\n",
    "# -------------------------\n",
    "# \"historical_years\"   => each full calendar year in the dataset becomes a scenario\n",
    "# \"synthetic_3cases\"   => build best/normal/bad year-profiles + estimate drift for long horizons\n",
    "SCENARIO_MODE = \"synthetic_3cases\"\n",
    "\n",
    "# Manual override if you want (example: -0.03 for -3%/yr)\n",
    "PRICE_DRIFT_ANNUAL_OVERRIDE = None\n",
    "\n",
    "# Volatility scaling inside each scenario profile (keeps seasonality, changes sd)\n",
    "BEST_VOL_MULT = 0.85\n",
    "NORMAL_VOL_MULT = 1.00\n",
    "BAD_VOL_MULT = 1.35\n",
    "\n",
    "# Optional level shifts (€/MWh) applied after volatility scaling\n",
    "BEST_LEVEL_SHIFT = 0.0\n",
    "NORMAL_LEVEL_SHIFT = 0.0\n",
    "BAD_LEVEL_SHIFT = 0.0\n",
    "\n",
    "# Scenario probabilities (must sum to 1)\n",
    "SCENARIO_PROB = {\"BEST\": 1/3, \"NORMAL\": 1/3, \"BAD\": 1/3}\n",
    "\n",
    "# -------------------------\n",
    "# Load and clean prices (hourly grid, interpolate gaps, drop Feb-29)\n",
    "# -------------------------\n",
    "dfp = pd.read_csv(r\"C:\\Users\\User\\OneDrive\\Univerity of Twente\\IEM\\Module 6\\CM&E\\Project\\CM-E-Project\\day_ahead_prices_2020_2025_combined.csv\")\n",
    "dfp[ts_col] = pd.to_datetime(dfp[ts_col], utc=True, errors=\"coerce\")\n",
    "dfp = dfp.dropna(subset=[ts_col, price_col]).sort_values(ts_col).set_index(ts_col)\n",
    "\n",
    "# If testing, cut down early (faster)\n",
    "if TEST_MODE:\n",
    "    start_ts = pd.Timestamp(TEST_START_UTC, tz=\"UTC\")\n",
    "    end_ts = start_ts + pd.Timedelta(days=TEST_DAYS)\n",
    "    dfp = dfp[(dfp.index >= start_ts) & (dfp.index < end_ts)]\n",
    "\n",
    "price_series = (\n",
    "    dfp[price_col].astype(float)\n",
    "    .resample(\"h\").mean()\n",
    "    .interpolate(\"time\")\n",
    ")\n",
    "\n",
    "# Drop Feb 29 so any \"calendar year\" is exactly 8760 hours\n",
    "is_feb29 = (price_series.index.month == 2) & (price_series.index.day == 29)\n",
    "price_series = price_series[~is_feb29]\n",
    "\n",
    "# -------------------------\n",
    "# Build scenario year-profiles\n",
    "# -------------------------\n",
    "def _extract_full_year_arrays(ps: pd.Series) -> dict[int, np.ndarray]:\n",
    "    years = sorted(ps.index.year.unique())\n",
    "    out = {}\n",
    "    for y in years:\n",
    "        ys = ps[ps.index.year == y]\n",
    "        if len(ys) == hours_per_year:\n",
    "            out[int(y)] = ys.to_numpy(dtype=float)\n",
    "    return out\n",
    "\n",
    "def _robust_drift_estimate(year_means: pd.Series) -> float:\n",
    "    '''\n",
    "    Estimate annual drift as a geometric growth rate from annual average prices.\n",
    "    Uses a robust outlier filter (MAD) so a single spike-year (e.g., 2022) doesn't dominate.\n",
    "    Returns g such that expected level scales by (1+g)^year.\n",
    "    '''\n",
    "    if len(year_means) < 2:\n",
    "        return 0.0\n",
    "\n",
    "    med = float(year_means.median())\n",
    "    mad = float(np.median(np.abs(year_means.values - med)))\n",
    "    if mad <= 1e-12:\n",
    "        keep = year_means\n",
    "    else:\n",
    "        sigma = 1.4826 * mad\n",
    "        keep = year_means[np.abs(year_means - med) <= 3.0 * sigma]\n",
    "        if len(keep) < 2:\n",
    "            keep = year_means\n",
    "\n",
    "    x = (keep.index.to_numpy(dtype=float) - float(keep.index.min()))\n",
    "    y = np.log(np.clip(keep.to_numpy(dtype=float), 1e-6, None))\n",
    "    slope = float(np.polyfit(x, y, 1)[0])\n",
    "    return float(np.exp(slope) - 1.0)\n",
    "\n",
    "def _vol_level_transform(p: np.ndarray, vol_mult: float, level_shift: float) -> np.ndarray:\n",
    "    mu = float(np.mean(p))\n",
    "    return (mu + vol_mult * (p - mu) + level_shift).astype(float)\n",
    "\n",
    "full_years = _extract_full_year_arrays(price_series)\n",
    "\n",
    "if TEST_MODE and not TEST_TILE_TO_YEAR:\n",
    "    # One scenario = the week (T=168)\n",
    "    prices = price_series.to_numpy(dtype=float)[None, :]\n",
    "    kept_years = [f\"TEST_WEEK_FROM_{TEST_START_UTC}\"]\n",
    "    scenario_names = kept_years\n",
    "    price_drift_annual = 0.0\n",
    "else:\n",
    "    if TEST_MODE and TEST_TILE_TO_YEAR:\n",
    "        # Repeat test window to 8760 (index no longer needed for optimization)\n",
    "        reps = hours_per_year // len(price_series)\n",
    "        rem = hours_per_year - reps * len(price_series)\n",
    "        tiled = np.concatenate([\n",
    "            np.tile(price_series.to_numpy(float), reps),\n",
    "            price_series.to_numpy(float)[:rem],\n",
    "        ])\n",
    "        prices = tiled[None, :]\n",
    "        kept_years = [f\"TEST_TILED_FROM_{TEST_START_UTC}\"]\n",
    "        scenario_names = kept_years\n",
    "        price_drift_annual = 0.0\n",
    "\n",
    "    else:\n",
    "        if len(full_years) == 0:\n",
    "            raise ValueError(\"No full 8760-hour years found in the price dataset after cleaning.\")\n",
    "\n",
    "        year_means = pd.Series({y: float(np.mean(arr)) for y, arr in full_years.items()}).sort_index()\n",
    "\n",
    "        # Identify best and bad years from available full years\n",
    "        bad_year = 2022 if 2022 in full_years else int(year_means.idxmax())\n",
    "        best_year = int(year_means.idxmin())\n",
    "\n",
    "        if SCENARIO_MODE == \"historical_years\":\n",
    "            kept_years = sorted(full_years.keys())\n",
    "            prices = np.vstack([full_years[y] for y in kept_years])\n",
    "            scenario_names = [str(y) for y in kept_years]\n",
    "\n",
    "        elif SCENARIO_MODE == \"synthetic_3cases\":\n",
    "            # Build NORMAL from a mean seasonal profile (hour-of-year) + a block-bootstrap residual.\n",
    "            years_for_normal = [y for y in full_years.keys() if y != bad_year] or list(full_years.keys())\n",
    "            mat = np.vstack([full_years[y] for y in years_for_normal])  # (Ny,8760)\n",
    "            seasonal_mean = mat.mean(axis=0)\n",
    "            resid = mat - seasonal_mean  # (Ny,8760)\n",
    "\n",
    "            rng = np.random.default_rng(42)\n",
    "            block = 24  # daily blocks\n",
    "            n_blocks = hours_per_year // block  # 365\n",
    "            resid_blocks = resid.reshape(resid.shape[0], n_blocks, block)\n",
    "            pick_y = rng.integers(0, resid.shape[0], size=n_blocks)\n",
    "            pick_b = rng.integers(0, n_blocks, size=n_blocks)\n",
    "            boot = resid_blocks[pick_y, pick_b].reshape(-1)\n",
    "\n",
    "            normal_raw = seasonal_mean + boot\n",
    "            best_raw = full_years[best_year]\n",
    "            bad_raw = full_years[bad_year]\n",
    "\n",
    "            best = _vol_level_transform(best_raw, BEST_VOL_MULT, BEST_LEVEL_SHIFT)\n",
    "            normal = _vol_level_transform(normal_raw, NORMAL_VOL_MULT, NORMAL_LEVEL_SHIFT)\n",
    "            bad = _vol_level_transform(bad_raw, BAD_VOL_MULT, BAD_LEVEL_SHIFT)\n",
    "\n",
    "            prices = np.vstack([best, normal, bad])\n",
    "            kept_years = [f\"BEST_{best_year}\", \"NORMAL_SYNTH\", f\"BAD_{bad_year}\"]\n",
    "            scenario_names = kept_years\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown SCENARIO_MODE={SCENARIO_MODE}\")\n",
    "\n",
    "        # Drift estimate (unless overridden)\n",
    "        drift_est = _robust_drift_estimate(year_means)\n",
    "        price_drift_annual = float(drift_est if PRICE_DRIFT_ANNUAL_OVERRIDE is None else PRICE_DRIFT_ANNUAL_OVERRIDE)\n",
    "\n",
    "# Scenario probabilities vector aligned with 'scenario_names'\n",
    "if (not TEST_MODE) and (SCENARIO_MODE == \"synthetic_3cases\"):\n",
    "    scenario_prob = np.array([SCENARIO_PROB[\"BEST\"], SCENARIO_PROB[\"NORMAL\"], SCENARIO_PROB[\"BAD\"]], dtype=float)\n",
    "    scenario_prob = scenario_prob / scenario_prob.sum()\n",
    "else:\n",
    "    S_tmp = int(np.asarray(prices).shape[0])\n",
    "    scenario_prob = np.ones(S_tmp, dtype=float) / S_tmp\n",
    "\n",
    "prices = np.asarray(prices, dtype=float)\n",
    "S, T = prices.shape\n",
    "year_scale = float(hours_per_year / (T * dt))  # =1.0 for T=8760; >1.0 for test windows\n",
    "\n",
    "print(f\"Scenario mode: {SCENARIO_MODE} | scenarios={scenario_names}\")\n",
    "print(f\"prices shape: (S,T)=({S},{T}), year_scale={year_scale:.6g}\")\n",
    "print(f\"price stats: min={prices.min():.2f}, mean={prices.mean():.2f}, max={prices.max():.2f}\")\n",
    "print(f\"Estimated price drift (annual): {price_drift_annual:+.4%}  (override via PRICE_DRIFT_ANNUAL_OVERRIDE)\")\n",
    "\n",
    "# -------------------------\n",
    "# Surplus (choose proxy from low prices OR Gemini profile)\n",
    "# -------------------------\n",
    "def make_surplus_proxy_from_prices(prices_ST: np.ndarray, surplus_max_mw: float = 50.0, low_quantile: float = 0.20) -> np.ndarray:\n",
    "    thresh = np.quantile(prices_ST, low_quantile, axis=1, keepdims=True)\n",
    "    return np.where(prices_ST <= thresh, surplus_max_mw, 0.0).astype(float)\n",
    "\n",
    "# Build Gemini 8760-hour profile (avg power by month-hour)\n",
    "gemini_profile = build_hourly_profile_from_month_hour_csv(\n",
    "    gemini_power_path,\n",
    "    month_col=\"month\",\n",
    "    hour_col=\"hour\",\n",
    "    value_col=\"avg_power\",\n",
    "    base_year=2021,\n",
    "    tz=\"UTC\",\n",
    ")\n",
    "gemini_profile = np.asarray(gemini_profile, dtype=float).ravel()\n",
    "\n",
    "if len(gemini_profile) != hours_per_year:\n",
    "    raise ValueError(f\"Gemini profile length {len(gemini_profile)} must be {hours_per_year} after build.\")\n",
    "\n",
    "if T == hours_per_year:\n",
    "    gemini_aligned = gemini_profile\n",
    "else:\n",
    "    gemini_aligned = gemini_profile[:T]\n",
    "\n",
    "curtailment_fraction = 1.0  # set e.g. 0.3 if only 30% is realistically available\n",
    "surplus_gemini_1y = np.clip(curtailment_fraction * gemini_aligned, 0.0, None)\n",
    "\n",
    "# Per-scenario surplus (optionally vary year-to-year)\n",
    "rng = np.random.default_rng(42)\n",
    "year_sigma = 0.10  # 10% multiplicative variation across scenarios\n",
    "scale_factors = rng.normal(1.0, year_sigma, size=(S, 1))\n",
    "\n",
    "surplus_gemini = np.clip(np.tile(surplus_gemini_1y[None, :], (S, 1)) * scale_factors, 0.0, None)\n",
    "surplus_proxy = make_surplus_proxy_from_prices(prices, surplus_max_mw=50.0, low_quantile=0.20)\n",
    "\n",
    "SURPLUS_MODE = \"gemini\"  # \"gemini\" or \"proxy\"\n",
    "surplus = surplus_gemini if SURPLUS_MODE.lower() == \"gemini\" else surplus_proxy\n",
    "\n",
    "print(f\"Surplus mode: {SURPLUS_MODE} | surplus shape: {surplus.shape}\")\n",
    "print(f\"surplus stats: min={surplus.min():.2f}, mean={surplus.mean():.2f}, max={surplus.max():.2f}\")\n",
    "\n",
    "# -------------------------\n",
    "# Optional helper: explicit multi-year hourly price paths (for reporting/plots).\n",
    "# Not used directly by the MILP (keeps the optimization size manageable for H_years up to 100).\n",
    "# -------------------------\n",
    "def generate_multi_year_price_cube(\n",
    "    base_prices_ST: np.ndarray,\n",
    "    H_years: int,\n",
    "    price_drift_annual: float = 0.0,\n",
    "    vol_growth_annual: float = 0.0,\n",
    ") -> np.ndarray:\n",
    "    '''\n",
    "    Returns price_cube[S,H,T]. Year y applies:\n",
    "      level_y = (1+price_drift_annual)^y\n",
    "      vol_y   = (1+vol_growth_annual)^y\n",
    "      p_y,t = level_y * (mu + vol_y*(p0_t - mu))\n",
    "    where mu is the within-year mean of p0 in each scenario.\n",
    "    '''\n",
    "    base_prices_ST = np.asarray(base_prices_ST, dtype=float)\n",
    "    S0, T0 = base_prices_ST.shape\n",
    "    H_years = int(H_years)\n",
    "    mu = base_prices_ST.mean(axis=1, keepdims=True)  # (S,1)\n",
    "    centered = base_prices_ST - mu\n",
    "    cube = np.zeros((S0, H_years, T0), dtype=float)\n",
    "    for y in range(H_years):\n",
    "        level = (1.0 + price_drift_annual) ** y\n",
    "        vol = (1.0 + vol_growth_annual) ** y\n",
    "        cube[:, y, :] = level * (mu + vol * centered)\n",
    "    return cube\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "86acf34b-e9f3-4cb3-b178-99bcc5eb6320",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# 2) Technology data (PLACEHOLDERS: fill with your estimates)\n",
    "#    Subsidy structures reflect what you already collected.\n",
    "# =========================\n",
    "\n",
    "# Convert doc values:\n",
    "# Hydropower subsidy example: 0.1693 €/kWh in 2024 => 169.3 €/MWh (15 years)\n",
    "hydro_sub_eur_per_MWh = 0.1693 * 1000.0\n",
    "\n",
    "# Hydrogen electrolysis subsidy example: 0.3796 €/kWh_HHV (15 years)\n",
    "# We'll apply it to produced H2_HHV = eta_ch * charged_electricity\n",
    "h2_sub_eur_per_MWh_HHV = 0.3796 * 1000.0\n",
    "\n",
    "TECH = {\n",
    "    \"PHS\": {\n",
    "        \"eta_ch\": 0.90,\n",
    "        \"eta_dis\": 0.90,\n",
    "        \"self_dis\": 0.0,             # per step fraction\n",
    "        \"Emax\": 5000.0,              # MWh_store\n",
    "        \"Pch_max\": 500.0,            # MW\n",
    "        \"Pdis_max\": 500.0,           # MW\n",
    "        \"capex_E\": 150000.0,         # €/MWh_store (placeholder)\n",
    "        \"capex_Pch\": 50000.0,        # €/MW (placeholder)\n",
    "        \"capex_Pdis\": 50000.0,       # €/MW (placeholder)\n",
    "        \"fom_E\": 2000.0,             # €/MWh_store/year (placeholder)\n",
    "        \"fom_P\": 5000.0,             # €/MW/year (placeholder)\n",
    "        \"vom_ch\": 0.5,               # €/MWh_e (placeholder)\n",
    "        \"vom_dis\": 0.5,              # €/MWh_e (placeholder)\n",
    "        \"subsidy_on_discharge_eur_per_MWh_e\": hydro_sub_eur_per_MWh,\n",
    "        \"subsidy_on_h2_MWh_HHV\": 0.0,\n",
    "        \"capex_grant_per_MWh_store\": 0.0,\n",
    "        \"capex_grant_cap_total\": 0.0,\n",
    "        \"capex_discount_factor\": 0.0,  # e.g., 0.10 for ~10% proxy\n",
    "        \"salvage_frac\": 0.10,\n",
    "\n",
    "        # Multi-year CAPEX / lifetime modelling\n",
    "        \"lifetime_years\": 60,\n",
    "        \"replacement_required\": True,\n",
    "        \"capex_escalation_annual\": 0.0,      # + => more expensive over time; - => cheaper\n",
    "        \"capex_payment_years\": 10,           # example: spread CAPEX over 10 years\n",
    "        \"capex_payment_profile\": None,       # None => equal split over capex_payment_years\n",
    "        \"commissioning_delay_years\": 10,     # example: no operating cashflows before year 10\n",
    "        \"grant_repeats\": False,              # grant only on first build by default\n",
    "    },\n",
    "    \"Flywheel\": {\n",
    "        \"eta_ch\": 0.92,\n",
    "        \"eta_dis\": 0.92,\n",
    "        \"self_dis\": 0.001,\n",
    "        \"Emax\": 200.0,\n",
    "        \"Pch_max\": 200.0,\n",
    "        \"Pdis_max\": 200.0,\n",
    "        \"capex_E\": 400000.0,         # placeholder\n",
    "        \"capex_Pch\": 80000.0,        # placeholder\n",
    "        \"capex_Pdis\": 80000.0,       # placeholder\n",
    "        \"fom_E\": 6000.0,             # placeholder\n",
    "        \"fom_P\": 8000.0,             # placeholder\n",
    "        \"vom_ch\": 1.0,\n",
    "        \"vom_dis\": 1.0,\n",
    "        \"subsidy_on_discharge_eur_per_MWh_e\": 0.0,\n",
    "        \"subsidy_on_h2_MWh_HHV\": 0.0,\n",
    "        \"capex_grant_per_MWh_store\": 0.0,\n",
    "        \"capex_grant_cap_total\": 0.0,\n",
    "        \"capex_discount_factor\": 0.10,\n",
    "        \"salvage_frac\": 0.10,\n",
    "\n",
    "        \"lifetime_years\": 20,\n",
    "        \"replacement_required\": True,\n",
    "        \"capex_escalation_annual\": 0.0,\n",
    "        \"capex_payment_years\": 1,\n",
    "        \"capex_payment_profile\": [1.0],\n",
    "        \"commissioning_delay_years\": 0,\n",
    "        \"grant_repeats\": False,\n",
    "    },\n",
    "    \"Battery\": {\n",
    "        \"eta_ch\": 0.95,\n",
    "        \"eta_dis\": 0.95,\n",
    "        \"self_dis\": 0.0005,\n",
    "        \"Emax\": 1000.0,\n",
    "        \"Pch_max\": 500.0,\n",
    "        \"Pdis_max\": 500.0,\n",
    "        \"capex_E\": 250000.0,         # placeholder\n",
    "        \"capex_Pch\": 60000.0,        # placeholder\n",
    "        \"capex_Pdis\": 60000.0,       # placeholder\n",
    "        \"fom_E\": 5000.0,             # placeholder\n",
    "        \"fom_P\": 7000.0,             # placeholder\n",
    "        \"vom_ch\": 2.0,\n",
    "        \"vom_dis\": 2.0,\n",
    "        \"subsidy_on_discharge_eur_per_MWh_e\": 0.0,\n",
    "        \"subsidy_on_h2_MWh_HHV\": 0.0,\n",
    "        # SPRILA example (big company): 70 €/kWh => 70,000 €/MWh (cap applies)\n",
    "        \"capex_grant_per_MWh_store\": 70000.0,   # €/MWh_store\n",
    "        \"capex_grant_cap_total\": 350000.0,      # € cap (from your doc table)\n",
    "        \"capex_discount_factor\": 0.10,\n",
    "        \"salvage_frac\": 0.10,\n",
    "\n",
    "        \"lifetime_years\": 12,\n",
    "        \"replacement_required\": True,\n",
    "        \"capex_escalation_annual\": 0.0,\n",
    "        \"capex_payment_years\": 1,\n",
    "        \"capex_payment_profile\": [1.0],\n",
    "        \"commissioning_delay_years\": 0,\n",
    "        \"grant_repeats\": False,\n",
    "    },\n",
    "    \"Hydrogen\": {\n",
    "        # Interpret SOC as stored H2 energy (MWh_HHV).\n",
    "        # eta_ch: electricity -> H2_HHV conversion\n",
    "        # eta_dis: H2_HHV -> electricity conversion\n",
    "        \"eta_ch\": 0.70,\n",
    "        \"eta_dis\": 0.55,\n",
    "        \"self_dis\": 0.0,\n",
    "        \"Emax\": 20000.0,             # MWh_HHV\n",
    "        \"Pch_max\": 1000.0,           # MW_e into electrolyser\n",
    "        \"Pdis_max\": 500.0,           # MW_e out from fuel cell/turbine\n",
    "        \"capex_E\": 20000.0,          # €/MWh_HHV storage (placeholder)\n",
    "        \"capex_Pch\": 500000.0,       # €/MW_e electrolysis (placeholder)\n",
    "        \"capex_Pdis\": 700000.0,      # €/MW_e power block (placeholder)\n",
    "        \"fom_E\": 300.0,              # €/MWh_HHV/year (placeholder)\n",
    "        \"fom_P\": 15000.0,            # €/MW/year (placeholder)\n",
    "        \"vom_ch\": 1.0,\n",
    "        \"vom_dis\": 3.0,\n",
    "        \"subsidy_on_discharge_eur_per_MWh_e\": 0.0,\n",
    "        # Apply subsidy on produced H2_HHV over 15 years (from your doc)\n",
    "        \"subsidy_on_h2_MWh_HHV\": h2_sub_eur_per_MWh_HHV,\n",
    "        \"capex_grant_per_MWh_store\": 0.0,\n",
    "        \"capex_grant_cap_total\": 0.0,\n",
    "        \"capex_discount_factor\": 0.0,\n",
    "        \"salvage_frac\": 0.05,\n",
    "\n",
    "        \"lifetime_years\": 25,\n",
    "        \"replacement_required\": True,\n",
    "        \"capex_escalation_annual\": 0.0,\n",
    "        \"capex_payment_years\": 1,\n",
    "        \"capex_payment_profile\": [1.0],\n",
    "        \"commissioning_delay_years\": 0,\n",
    "        \"grant_repeats\": False,\n",
    "    },\n",
    "}\n",
    "\n",
    "# Economic settings (course-consistent assumptions)\n",
    "discount_rate = 0.08\n",
    "H_years = 25\n",
    "subsidy_years = 15\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "64740dc3-1e03-45a6-90a4-48729f8be0f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_one_tech(\n",
    "    tech_name,\n",
    "    prices,\n",
    "    surplus,\n",
    "    scenario_prob,\n",
    "    dt,\n",
    "    year_scale,\n",
    "    discount_rate,\n",
    "    H_years,\n",
    "    subsidy_years,\n",
    "    output_flag=0,\n",
    "    time_limit=60,\n",
    "    prevent_simultaneous=True,\n",
    "    force_frac_ub=None,\n",
    "    force_min_E=None,\n",
    "    force_min_P=None,\n",
    "    price_drift_annual=None,\n",
    "):\n",
    "    \"\"\"Solve design + dispatch for one technology, with:\n",
    "    - price scenarios (S,T) for a representative year\n",
    "    - long-horizon NPV with optional annual price drift (applies to price-dependent cashflows)\n",
    "    - multi-year CAPEX schedules + replacements (lifetime) + commissioning delays\n",
    "    \"\"\"\n",
    "\n",
    "    td = TECH[tech_name]\n",
    "    prices = as_2d(prices)\n",
    "    surplus = as_2d(surplus)\n",
    "    scenario_prob = np.asarray(scenario_prob, dtype=float)\n",
    "    scenario_prob = scenario_prob / scenario_prob.sum()\n",
    "\n",
    "    S, T = prices.shape\n",
    "\n",
    "    # Default drift: use global variable if present; else 0\n",
    "    if price_drift_annual is None:\n",
    "        price_drift_annual = float(globals().get(\"price_drift_annual\", 0.0))\n",
    "    price_drift_annual = float(price_drift_annual)\n",
    "\n",
    "    r = float(discount_rate)\n",
    "    H_years = int(H_years)\n",
    "    subsidy_years = int(subsidy_years)\n",
    "\n",
    "    commissioning_delay = int(max(0, td.get(\"commissioning_delay_years\", 0)))\n",
    "\n",
    "    # PV factors\n",
    "    PW_ops = pw_factor_shifted(r, H_years, commissioning_delay)                        # constant annual amounts (VOM/FOM)\n",
    "    PW_price = pw_factor_growth_shifted(r, price_drift_annual, H_years, commissioning_delay)  # price-dependent part\n",
    "\n",
    "    # Subsidy applies for the first `subsidy_years` years of operation (starting at commissioning)\n",
    "    H_sub_total = min(H_years, commissioning_delay + max(0, subsidy_years))\n",
    "    PW_sub = pw_factor_shifted(r, H_sub_total, commissioning_delay)\n",
    "\n",
    "    # CAPEX schedule / replacements\n",
    "    lifetime_years = td.get(\"lifetime_years\", None)\n",
    "    replacement_required = bool(td.get(\"replacement_required\", True))\n",
    "    capex_escalation_annual = float(td.get(\"capex_escalation_annual\", 0.0))\n",
    "    capex_payment_years = int(max(0, td.get(\"capex_payment_years\", 0)))\n",
    "    capex_payment_profile = td.get(\"capex_payment_profile\", None)\n",
    "\n",
    "    capex_mult = build_capex_multiplier_series(\n",
    "        H=H_years,\n",
    "        lifetime_years=lifetime_years,\n",
    "        construction_years=capex_payment_years,\n",
    "        capex_payment_profile=capex_payment_profile,\n",
    "        replacement_required=replacement_required,\n",
    "        capex_escalation_annual=capex_escalation_annual,\n",
    "    )\n",
    "    PV_capex_factor = float(np.sum(capex_mult / (1.0 + r) ** np.arange(len(capex_mult))))\n",
    "\n",
    "    # Salvage on the last installed asset (prorated by remaining life)\n",
    "    salvage_frac = float(td.get(\"salvage_frac\", 0.0))\n",
    "    if lifetime_years is None or (not replacement_required) or lifetime_years <= 0:\n",
    "        install_years = [0]\n",
    "        L = H_years\n",
    "    else:\n",
    "        L = int(lifetime_years)\n",
    "        install_years = list(range(0, H_years, L))\n",
    "    last_install = int(max(install_years))\n",
    "    used_years_last = H_years - last_install\n",
    "    remaining_years_last = max(L - used_years_last, 0)\n",
    "    salvage_effective_frac = 0.0 if L <= 0 else salvage_frac * (remaining_years_last / L)\n",
    "    salvage_growth = (1.0 + capex_escalation_annual) ** last_install\n",
    "    salvage_pv_factor = float(salvage_effective_frac * salvage_growth / (1.0 + r) ** H_years)\n",
    "\n",
    "    # -------------------------\n",
    "    # Build model\n",
    "    # -------------------------\n",
    "    m = gp.Model(f\"storage_{tech_name}\")\n",
    "    m.Params.OutputFlag = output_flag\n",
    "    if time_limit is not None:\n",
    "        m.Params.TimeLimit = time_limit\n",
    "    if prevent_simultaneous:\n",
    "        m.Params.MIPGap = 0.05\n",
    "\n",
    "    # -------------------------\n",
    "    # Design vars\n",
    "    # -------------------------\n",
    "    E = m.addVar(lb=0.0, ub=td[\"Emax\"], name=\"E\")          # MWh_store (or MWh_HHV for hydrogen)\n",
    "    Pch = m.addVar(lb=0.0, ub=td[\"Pch_max\"], name=\"Pch\")   # MW\n",
    "    Pdis = m.addVar(lb=0.0, ub=td[\"Pdis_max\"], name=\"Pdis\")# MW\n",
    "\n",
    "    # Optional one-time CAPEX grant (linearised min(rate*E, cap))\n",
    "    grant = m.addVar(lb=0.0, ub=td[\"capex_grant_cap_total\"], name=\"capex_grant\")\n",
    "    if td[\"capex_grant_cap_total\"] > 0 and td[\"capex_grant_per_MWh_store\"] > 0:\n",
    "        m.addConstr(grant <= td[\"capex_grant_per_MWh_store\"] * E, name=\"grant_rate\")\n",
    "        m.addConstr(grant <= td[\"capex_grant_cap_total\"], name=\"grant_cap\")\n",
    "    else:\n",
    "        m.addConstr(grant == 0.0, name=\"no_grant\")\n",
    "\n",
    "    # -------------------------\n",
    "    # Operational vars\n",
    "    # -------------------------\n",
    "    c = m.addVars(S, T, lb=0.0, name=\"c\")         # MW charging\n",
    "    d = m.addVars(S, T, lb=0.0, name=\"d\")         # MW discharging\n",
    "    soc = m.addVars(S, T + 1, lb=0.0, name=\"soc\") # MWh state of charge\n",
    "\n",
    "    if prevent_simultaneous:\n",
    "        z = m.addVars(S, T, vtype=GRB.BINARY, name=\"isCharging\")\n",
    "    else:\n",
    "        z = None\n",
    "\n",
    "    eta_ch = float(td[\"eta_ch\"])\n",
    "    eta_dis = float(td[\"eta_dis\"])\n",
    "    self_dis = float(td[\"self_dis\"])\n",
    "\n",
    "    M_ch = float(td[\"Pch_max\"])\n",
    "    M_dis = float(td[\"Pdis_max\"])\n",
    "\n",
    "    # -------------------------\n",
    "    # Constraints\n",
    "    # -------------------------\n",
    "    for s in range(S):\n",
    "        m.addConstr(soc[s, 0] <= E, name=f\"soc0_ub[{s}]\")\n",
    "        m.addConstr(soc[s, 0] >= 0.0, name=f\"soc0_lb[{s}]\")\n",
    "        m.addConstr(soc[s, T] == soc[s, 0], name=f\"cyclic[{s}]\")  # steady-state year\n",
    "\n",
    "        for t in range(T):\n",
    "            m.addConstr(soc[s, t] <= E, name=f\"soc_ub[{s},{t}]\")\n",
    "            m.addConstr(c[s, t] <= Pch, name=f\"pch[{s},{t}]\")\n",
    "            m.addConstr(d[s, t] <= Pdis, name=f\"pdis[{s},{t}]\")\n",
    "            m.addConstr(c[s, t] <= float(surplus[s, t]), name=f\"surplus[{s},{t}]\")\n",
    "            if prevent_simultaneous:\n",
    "                m.addConstr(c[s, t] <= M_ch * z[s, t], name=f\"noSim_c[{s},{t}]\")\n",
    "                m.addConstr(d[s, t] <= M_dis * (1 - z[s, t]), name=f\"noSim_d[{s},{t}]\")\n",
    "            m.addConstr(\n",
    "                soc[s, t + 1]\n",
    "                == (1.0 - self_dis) * soc[s, t]\n",
    "                + eta_ch * c[s, t] * dt\n",
    "                - (d[s, t] * dt) / eta_dis,\n",
    "                name=f\"dyn[{s},{t}]\"\n",
    "            )\n",
    "\n",
    "    # ============================================================\n",
    "    # Counterfactual: force a non-zero investment to explain \"why 0?\"\n",
    "    # ============================================================\n",
    "    m.update()\n",
    "\n",
    "    def _safe_ub(var, td, fallback_keys):\n",
    "        try:\n",
    "            return float(var.UB)\n",
    "        except Exception:\n",
    "            for k in fallback_keys:\n",
    "                if k in td and td[k] is not None:\n",
    "                    try:\n",
    "                        return float(td[k])\n",
    "                    except Exception:\n",
    "                        pass\n",
    "            return float(\"inf\")\n",
    "\n",
    "    def _finite_pos(x):\n",
    "        try:\n",
    "            x = float(x)\n",
    "            return np.isfinite(x) and x > 0.0\n",
    "        except Exception:\n",
    "            return False\n",
    "\n",
    "    applied_any = False\n",
    "\n",
    "    if force_frac_ub is not None:\n",
    "        ub_E = _safe_ub(E, td, [\"Emax\"])\n",
    "        ub_Pch = _safe_ub(Pch, td, [\"Pch_max\"])\n",
    "        ub_Pdis = _safe_ub(Pdis, td, [\"Pdis_max\"])\n",
    "        if not (_finite_pos(ub_E) and _finite_pos(ub_Pch) and _finite_pos(ub_Pdis)):\n",
    "            raise RuntimeError(\"Cannot apply force_frac_ub: non-finite UB(s) detected.\")\n",
    "\n",
    "        frac = float(force_frac_ub)\n",
    "        if frac <= 0.0 or frac >= 1.0:\n",
    "            raise ValueError(\"force_frac_ub must be in (0,1).\")\n",
    "\n",
    "        m.addConstr(E >= frac * ub_E, name=\"force_E_min\")\n",
    "        m.addConstr(Pch >= frac * ub_Pch, name=\"force_Pch_min\")\n",
    "        m.addConstr(Pdis >= frac * ub_Pdis, name=\"force_Pdis_min\")\n",
    "        applied_any = True\n",
    "\n",
    "    if force_min_E is not None:\n",
    "        m.addConstr(E >= float(force_min_E), name=\"force_E_abs_min\")\n",
    "        applied_any = True\n",
    "\n",
    "    if force_min_P is not None:\n",
    "        m.addConstr(Pch + Pdis >= float(force_min_P), name=\"force_P_total_min\")\n",
    "        applied_any = True\n",
    "\n",
    "    # -------------------------\n",
    "    # Economics (annual cashflow components)\n",
    "    # -------------------------\n",
    "    capex_raw = td[\"capex_E\"] * E + td[\"capex_Pch\"] * Pch + td[\"capex_Pdis\"] * Pdis\n",
    "    capex_net = (1.0 - float(td.get(\"capex_discount_factor\", 0.0))) * capex_raw  # CAPEX after discount factor, before grant\n",
    "\n",
    "    fom = td[\"fom_E\"] * E + td[\"fom_P\"] * (Pch + Pdis)  # €/year, costs\n",
    "\n",
    "    sub_on_dis = float(td.get(\"subsidy_on_discharge_eur_per_MWh_e\", 0.0))\n",
    "    sub_on_h2 = float(td.get(\"subsidy_on_h2_MWh_HHV\", 0.0))\n",
    "\n",
    "    exp_annual_arbitrage = gp.LinExpr()\n",
    "    exp_annual_vom = gp.LinExpr()\n",
    "    exp_annual_subsidy = gp.LinExpr()\n",
    "\n",
    "    for s in range(S):\n",
    "        scen_arbitrage = gp.LinExpr()\n",
    "        scen_vom = gp.LinExpr()\n",
    "        scen_sub = gp.LinExpr()\n",
    "\n",
    "        for t in range(T):\n",
    "            p = float(prices[s, t])\n",
    "            scen_arbitrage += p * (d[s, t] - c[s, t]) * dt\n",
    "            scen_vom += -(float(td[\"vom_ch\"]) * c[s, t] + float(td[\"vom_dis\"]) * d[s, t]) * dt\n",
    "            if sub_on_dis != 0.0:\n",
    "                scen_sub += sub_on_dis * d[s, t] * dt\n",
    "            if sub_on_h2 != 0.0:\n",
    "                # subsidy on produced H2_HHV (MWh_HHV) = eta_ch * charged electricity (MWh_e)\n",
    "                scen_sub += sub_on_h2 * (eta_ch * c[s, t] * dt)\n",
    "\n",
    "        w = float(scenario_prob[s])\n",
    "        exp_annual_arbitrage += w * scen_arbitrage\n",
    "        exp_annual_vom += w * scen_vom\n",
    "        exp_annual_subsidy += w * scen_sub\n",
    "\n",
    "    # Scale short test windows up to annualised values\n",
    "    exp_annual_arbitrage *= float(year_scale)\n",
    "    exp_annual_vom *= float(year_scale)\n",
    "    exp_annual_subsidy *= float(year_scale)\n",
    "\n",
    "    # PV terms\n",
    "    pv_capex_cost = -PV_capex_factor * capex_net + grant  # grant is one-time at t=0 (default)\n",
    "    pv_salvage = salvage_pv_factor * capex_net            # salvage is a fraction of last installed CAPEX\n",
    "    pv_ops_const = PW_ops * (exp_annual_vom - fom)        # constant annual costs (VOM + FOM)\n",
    "    pv_price = PW_price * exp_annual_arbitrage            # price-dependent part with drift\n",
    "    pv_sub = PW_sub * exp_annual_subsidy                  # subsidies only for subsidy_years of operation\n",
    "\n",
    "    m.setObjective(pv_capex_cost + pv_salvage + pv_ops_const + pv_price + pv_sub, GRB.MAXIMIZE)\n",
    "\n",
    "    m.optimize()\n",
    "\n",
    "    if m.Status not in (GRB.OPTIMAL, GRB.TIME_LIMIT, GRB.SUBOPTIMAL):\n",
    "        return {\"tech\": tech_name, \"status\": int(m.Status), \"npv\": None}\n",
    "\n",
    "    # -------------------------\n",
    "    # Collect results\n",
    "    # -------------------------\n",
    "    E_val = float(E.X)\n",
    "    Pch_val = float(Pch.X)\n",
    "    Pdis_val = float(Pdis.X)\n",
    "    npv_val = float(m.ObjVal)\n",
    "\n",
    "    c0 = np.array([c[0, t].X for t in range(T)], dtype=float)\n",
    "    d0 = np.array([d[0, t].X for t in range(T)], dtype=float)\n",
    "    soc0 = np.array([soc[0, t].X for t in range(T + 1)], dtype=float)\n",
    "    soc_pct = (soc0[:-1] / E_val * 100.0) if E_val > 1e-9 else np.zeros(T)\n",
    "\n",
    "    # Numeric breakdown (recompute with solution values)\n",
    "    # Annual expectations\n",
    "    arb_s = []\n",
    "    vom_s = []\n",
    "    sub_s = []\n",
    "    for s in range(S):\n",
    "        arb = float(np.sum(prices[s, :] * (np.array([d[s, t].X for t in range(T)]) - np.array([c[s, t].X for t in range(T)])) * dt))\n",
    "        vom = -float(np.sum((float(td[\"vom_ch\"]) * np.array([c[s, t].X for t in range(T)]) + float(td[\"vom_dis\"]) * np.array([d[s, t].X for t in range(T)])) * dt))\n",
    "        sub = 0.0\n",
    "        if sub_on_dis != 0.0:\n",
    "            sub += float(sub_on_dis * np.sum(np.array([d[s, t].X for t in range(T)]) * dt))\n",
    "        if sub_on_h2 != 0.0:\n",
    "            sub += float(sub_on_h2 * np.sum(eta_ch * np.array([c[s, t].X for t in range(T)]) * dt))\n",
    "        arb_s.append(arb * year_scale)\n",
    "        vom_s.append(vom * year_scale)\n",
    "        sub_s.append(sub * year_scale)\n",
    "\n",
    "    exp_arb_num = float(np.dot(scenario_prob, arb_s))\n",
    "    exp_vom_num = float(np.dot(scenario_prob, vom_s))\n",
    "    exp_sub_num = float(np.dot(scenario_prob, sub_s))\n",
    "    fom_num = float(td[\"fom_E\"] * E_val + td[\"fom_P\"] * (Pch_val + Pdis_val))\n",
    "\n",
    "    capex_raw_num = float(td[\"capex_E\"] * E_val + td[\"capex_Pch\"] * Pch_val + td[\"capex_Pdis\"] * Pdis_val)\n",
    "    capex_net_num = float((1.0 - float(td.get(\"capex_discount_factor\", 0.0))) * capex_raw_num)\n",
    "    grant_num = float(grant.X)\n",
    "\n",
    "    pv_capex_num = -PV_capex_factor * capex_net_num + grant_num\n",
    "    pv_salvage_num = salvage_pv_factor * capex_net_num\n",
    "    pv_price_num = PW_price * exp_arb_num\n",
    "    pv_ops_num = PW_ops * (exp_vom_num - fom_num)\n",
    "    pv_sub_num = PW_sub * exp_sub_num\n",
    "\n",
    "    npv_breakdown = {\n",
    "        \"PV_CAPEX\": pv_capex_num,\n",
    "        \"PV_SALVAGE\": pv_salvage_num,\n",
    "        \"PV_PRICE_ARBITRAGE\": pv_price_num,\n",
    "        \"PV_VOM_FOM\": pv_ops_num,\n",
    "        \"PV_SUBSIDY\": pv_sub_num,\n",
    "        \"NPV_TOTAL\": pv_capex_num + pv_salvage_num + pv_price_num + pv_ops_num + pv_sub_num,\n",
    "    }\n",
    "\n",
    "    scenario_breakdown = pd.DataFrame({\n",
    "        \"scenario\": scenario_names if \"scenario_names\" in globals() and len(globals().get(\"scenario_names\", [])) == S else [f\"s{s}\" for s in range(S)],\n",
    "        \"prob\": scenario_prob,\n",
    "        \"annual_arbitrage\": arb_s,\n",
    "        \"annual_vom\": vom_s,\n",
    "        \"annual_subsidy\": sub_s,\n",
    "    })\n",
    "\n",
    "    out = {\n",
    "        \"tech\": tech_name,\n",
    "        \"status\": int(m.Status),\n",
    "        \"npv\": npv_val,\n",
    "        \"E\": E_val,\n",
    "        \"Pch\": Pch_val,\n",
    "        \"Pdis\": Pdis_val,\n",
    "        \"assumptions\": {\n",
    "            \"discount_rate\": r,\n",
    "            \"H_years\": H_years,\n",
    "            \"subsidy_years\": subsidy_years,\n",
    "            \"commissioning_delay_years\": commissioning_delay,\n",
    "            \"price_drift_annual\": price_drift_annual,\n",
    "            \"PV_capex_factor\": PV_capex_factor,\n",
    "            \"PW_ops\": PW_ops,\n",
    "            \"PW_price\": PW_price,\n",
    "            \"PW_sub\": PW_sub,\n",
    "            \"salvage_pv_factor\": salvage_pv_factor,\n",
    "            \"lifetime_years\": lifetime_years,\n",
    "            \"capex_payment_years\": capex_payment_years,\n",
    "            \"capex_escalation_annual\": capex_escalation_annual,\n",
    "        },\n",
    "        \"npv_breakdown\": npv_breakdown,\n",
    "        \"scenario_breakdown\": scenario_breakdown,\n",
    "        \"capex_mult_by_year\": capex_mult,\n",
    "        \"dispatch_s0\": pd.DataFrame({\n",
    "            \"t\": np.arange(T),\n",
    "            \"price\": prices[0],\n",
    "            \"surplus\": surplus[0],\n",
    "            \"charge_MW\": c0,\n",
    "            \"discharge_MW\": d0,\n",
    "            \"soc_MWh\": soc0[:-1],\n",
    "            \"soc_pct\": soc_pct,\n",
    "        }),\n",
    "    }\n",
    "\n",
    "    if prevent_simultaneous:\n",
    "        out[\"simultaneous_hours_s0\"] = int(np.sum((c0 > 1e-6) & (d0 > 1e-6)))\n",
    "\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "16dad337-c121-464e-bc62-9b956ce4824d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set parameter Username\n",
      "Set parameter LicenseID to value 2661894\n",
      "Academic license - for non-commercial use only - expires 2026-05-07\n",
      "Set parameter OutputFlag to value 1\n",
      "Set parameter TimeLimit to value 60\n",
      "Set parameter MIPGap to value 0.05\n",
      "Gurobi Optimizer version 12.0.3 build v12.0.3rc0 (win64 - Windows 11+.0 (26200.2))\n",
      "\n",
      "CPU model: Intel(R) Core(TM) i7-10750H CPU @ 2.60GHz, instruction set [SSE2|AVX|AVX2]\n",
      "Thread count: 6 physical cores, 12 logical processors, using up to 12 threads\n",
      "\n",
      "Non-default parameters:\n",
      "TimeLimit  60\n",
      "MIPGap  0.05\n",
      "\n",
      "Optimize a model with 183970 rows, 105127 columns and 394216 nonzeros\n",
      "Model fingerprint: 0x0b2afe89\n",
      "Variable types: 78847 continuous, 26280 integer (26280 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [9e-01, 5e+02]\n",
      "  Objective range  [3e-02, 1e+05]\n",
      "  Bounds range     [1e+00, 5e+03]\n",
      "  RHS range        [3e+02, 6e+02]\n",
      "Found heuristic solution: objective -0.0000000\n",
      "Presolve removed 26290 rows and 4 columns\n",
      "Presolve time: 1.10s\n",
      "Presolved: 157680 rows, 105123 columns, 367920 nonzeros\n",
      "Variable types: 78843 continuous, 26280 integer (26280 binary)\n",
      "Root relaxation presolved: 131400 rows, 78843 columns, 315360 nonzeros\n",
      "\n",
      "Deterministic concurrent LP optimizer: primal and dual simplex\n",
      "Showing primal log only...\n",
      "\n",
      "\n",
      "Root simplex log...\n",
      "\n",
      "Iteration    Objective       Primal Inf.    Dual Inf.      Time\n",
      "   63743    7.8578846e+03   0.000000e+00   3.788224e+08      5s\n",
      "   64823    1.0505509e+04   0.000000e+00   4.449488e+08     10s\n",
      "Concurrent spin time: 0.00s\n",
      "\n",
      "Solved with dual simplex\n",
      "\n",
      "Root simplex log...\n",
      "\n",
      "Iteration    Objective       Primal Inf.    Dual Inf.      Time\n",
      "    6252    6.9222748e+09   0.000000e+00   0.000000e+00     10s\n",
      "\n",
      "Root relaxation: objective 6.922275e+09, 6252 iterations, 8.51 seconds (7.85 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0 6.9223e+09    0  793   -0.00000 6.9223e+09      -     -   11s\n",
      "H    0     0                    6.914418e+09 6.9223e+09  0.11%     -   12s\n",
      "\n",
      "Explored 1 nodes (14008 simplex iterations) in 12.75 seconds (9.97 work units)\n",
      "Thread count was 12 (of 12 available processors)\n",
      "\n",
      "Solution count 2: 6.91442e+09 -0 \n",
      "\n",
      "Optimal solution found (tolerance 5.00e-02)\n",
      "Best objective 6.914418117602e+09, best bound 6.922274761215e+09, gap 0.1136%\n",
      "Set parameter OutputFlag to value 1\n",
      "Set parameter TimeLimit to value 60\n",
      "Set parameter MIPGap to value 0.05\n",
      "Gurobi Optimizer version 12.0.3 build v12.0.3rc0 (win64 - Windows 11+.0 (26200.2))\n",
      "\n",
      "CPU model: Intel(R) Core(TM) i7-10750H CPU @ 2.60GHz, instruction set [SSE2|AVX|AVX2]\n",
      "Thread count: 6 physical cores, 12 logical processors, using up to 12 threads\n",
      "\n",
      "Non-default parameters:\n",
      "TimeLimit  60\n",
      "MIPGap  0.05\n",
      "\n",
      "Optimize a model with 183970 rows, 105127 columns and 394216 nonzeros\n",
      "Model fingerprint: 0x2ff95d89\n",
      "Variable types: 78847 continuous, 26280 integer (26280 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [9e-01, 2e+02]\n",
      "  Objective range  [8e-02, 5e+05]\n",
      "  Bounds range     [1e+00, 2e+02]\n",
      "  RHS range        [2e+02, 6e+02]\n",
      "Found heuristic solution: objective -0.0000000\n",
      "Presolve removed 26290 rows and 4 columns\n",
      "Presolve time: 1.09s\n",
      "Presolved: 157680 rows, 105123 columns, 367920 nonzeros\n",
      "Variable types: 78843 continuous, 26280 integer (26280 binary)\n",
      "Root relaxation presolved: 131400 rows, 78843 columns, 315360 nonzeros\n",
      "\n",
      "Deterministic concurrent LP optimizer: primal and dual simplex\n",
      "Showing primal log only...\n",
      "\n",
      "\n",
      "Root simplex log...\n",
      "\n",
      "Iteration    Objective       Primal Inf.    Dual Inf.      Time\n",
      "   57833    9.2947701e+03   0.000000e+00   2.115171e+08      5s\n",
      "Concurrent spin time: 0.00s\n",
      "\n",
      "Solved with dual simplex\n",
      "\n",
      "Root simplex log...\n",
      "\n",
      "Iteration    Objective       Primal Inf.    Dual Inf.      Time\n",
      "   28963    7.7253265e+08   0.000000e+00   0.000000e+00      6s\n",
      "\n",
      "Root relaxation: objective 7.725327e+08, 28963 iterations, 4.63 seconds (3.37 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0 7.7253e+08    0  758   -0.00000 7.7253e+08      -     -    6s\n",
      "H    0     0                    7.594242e+08 7.7253e+08  1.73%     -    9s\n",
      "\n",
      "Explored 1 nodes (29602 simplex iterations) in 9.18 seconds (5.65 work units)\n",
      "Thread count was 12 (of 12 available processors)\n",
      "\n",
      "Solution count 2: 7.59424e+08 -0 \n",
      "\n",
      "Optimal solution found (tolerance 5.00e-02)\n",
      "Best objective 7.594241597184e+08, best bound 7.725326524923e+08, gap 1.7261%\n",
      "Set parameter OutputFlag to value 1\n",
      "Set parameter TimeLimit to value 60\n",
      "Set parameter MIPGap to value 0.05\n",
      "Gurobi Optimizer version 12.0.3 build v12.0.3rc0 (win64 - Windows 11+.0 (26200.2))\n",
      "\n",
      "CPU model: Intel(R) Core(TM) i7-10750H CPU @ 2.60GHz, instruction set [SSE2|AVX|AVX2]\n",
      "Thread count: 6 physical cores, 12 logical processors, using up to 12 threads\n",
      "\n",
      "Non-default parameters:\n",
      "TimeLimit  60\n",
      "MIPGap  0.05\n",
      "\n",
      "Optimize a model with 183971 rows, 105127 columns and 394218 nonzeros\n",
      "Model fingerprint: 0x1f4b41a1\n",
      "Variable types: 78847 continuous, 26280 integer (26280 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [9e-01, 7e+04]\n",
      "  Objective range  [2e-01, 4e+05]\n",
      "  Bounds range     [1e+00, 4e+05]\n",
      "  RHS range        [3e+02, 4e+05]\n",
      "Found heuristic solution: objective -0.0000000\n",
      "Presolve removed 26290 rows and 3 columns\n",
      "Presolve time: 0.78s\n",
      "Presolved: 157681 rows, 105124 columns, 367922 nonzeros\n",
      "Variable types: 78844 continuous, 26280 integer (26280 binary)\n",
      "Root relaxation presolved: 131401 rows, 78844 columns, 315362 nonzeros\n",
      "\n",
      "Deterministic concurrent LP optimizer: primal and dual simplex\n",
      "Showing primal log only...\n",
      "\n",
      "\n",
      "Root simplex log...\n",
      "\n",
      "Iteration    Objective       Primal Inf.    Dual Inf.      Time\n",
      "   54654    1.0129893e+04   0.000000e+00   4.121073e+08      5s\n",
      "Concurrent spin time: 0.00s\n",
      "\n",
      "Solved with dual simplex\n",
      "\n",
      "Root simplex log...\n",
      "\n",
      "Iteration    Objective       Primal Inf.    Dual Inf.      Time\n",
      "   35654    3.9455678e+09   0.000000e+00   0.000000e+00      9s\n",
      "\n",
      "Root relaxation: objective 3.945568e+09, 35654 iterations, 7.98 seconds (5.19 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0 3.9456e+09    0  536   -0.00000 3.9456e+09      -     -    9s\n",
      "H    0     0                    3.934254e+09 3.9456e+09  0.29%     -   14s\n",
      "\n",
      "Explored 1 nodes (37868 simplex iterations) in 14.28 seconds (8.57 work units)\n",
      "Thread count was 12 (of 12 available processors)\n",
      "\n",
      "Solution count 2: 3.93425e+09 -0 \n",
      "\n",
      "Optimal solution found (tolerance 5.00e-02)\n",
      "Best objective 3.934253542884e+09, best bound 3.945567793280e+09, gap 0.2876%\n",
      "Set parameter OutputFlag to value 1\n",
      "Set parameter TimeLimit to value 60\n",
      "Set parameter MIPGap to value 0.05\n",
      "Gurobi Optimizer version 12.0.3 build v12.0.3rc0 (win64 - Windows 11+.0 (26200.2))\n",
      "\n",
      "CPU model: Intel(R) Core(TM) i7-10750H CPU @ 2.60GHz, instruction set [SSE2|AVX|AVX2]\n",
      "Thread count: 6 physical cores, 12 logical processors, using up to 12 threads\n",
      "\n",
      "Non-default parameters:\n",
      "TimeLimit  60\n",
      "MIPGap  0.05\n",
      "\n",
      "Optimize a model with 183970 rows, 105127 columns and 394216 nonzeros\n",
      "Model fingerprint: 0x15a4544a\n",
      "Variable types: 78847 continuous, 26280 integer (26280 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [7e-01, 1e+03]\n",
      "  Objective range  [5e-02, 9e+05]\n",
      "  Bounds range     [1e+00, 2e+04]\n",
      "  RHS range        [3e+02, 6e+02]\n",
      "Found heuristic solution: objective -0.0000000\n",
      "Presolve removed 26290 rows and 4 columns\n",
      "Presolve time: 0.63s\n",
      "Presolved: 157680 rows, 105123 columns, 367920 nonzeros\n",
      "Variable types: 78843 continuous, 26280 integer (26280 binary)\n",
      "Root relaxation presolved: 131400 rows, 78843 columns, 315360 nonzeros\n",
      "\n",
      "Deterministic concurrent LP optimizer: primal and dual simplex\n",
      "Showing primal log only...\n",
      "\n",
      "\n",
      "Root simplex log...\n",
      "\n",
      "Iteration    Objective       Primal Inf.    Dual Inf.      Time\n",
      "   58063    6.8071390e+03   0.000000e+00   2.611806e+08      5s\n",
      "   59493    1.0020572e+04   0.000000e+00   3.030340e+08     10s\n",
      "   60573    1.3368644e+04   0.000000e+00   2.839470e+08     16s\n",
      "   61653    1.7125510e+04   0.000000e+00   2.388983e+08     21s\n",
      "   62613    2.1786070e+04   0.000000e+00   6.657971e+08     25s\n",
      "Concurrent spin time: 0.00s\n",
      "\n",
      "Solved with dual simplex\n",
      "\n",
      "Root simplex log...\n",
      "\n",
      "Iteration    Objective       Primal Inf.    Dual Inf.      Time\n",
      "   20764    5.4854741e+09   0.000000e+00   0.000000e+00     26s\n",
      "\n",
      "Root relaxation: objective 5.485474e+09, 20764 iterations, 24.87 seconds (24.47 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0 5.4855e+09    0   88   -0.00000 5.4855e+09      -     -   26s\n",
      "H    0     0                    5.484055e+09 5.4855e+09  0.03%     -   29s\n",
      "\n",
      "Explored 1 nodes (23847 simplex iterations) in 29.21 seconds (26.67 work units)\n",
      "Thread count was 12 (of 12 available processors)\n",
      "\n",
      "Solution count 2: 5.48405e+09 -0 \n",
      "\n",
      "Optimal solution found (tolerance 5.00e-02)\n",
      "Best objective 5.484054961456e+09, best bound 5.485474113560e+09, gap 0.0259%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tech</th>\n",
       "      <th>status</th>\n",
       "      <th>NPV</th>\n",
       "      <th>E (MWh_store)</th>\n",
       "      <th>Pch (MW)</th>\n",
       "      <th>Pdis (MW)</th>\n",
       "      <th>simultaneous_hours_s0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PHS</td>\n",
       "      <td>2</td>\n",
       "      <td>6.914418e+09</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hydrogen</td>\n",
       "      <td>2</td>\n",
       "      <td>5.484055e+09</td>\n",
       "      <td>20000.0</td>\n",
       "      <td>508.719511</td>\n",
       "      <td>500.000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Battery</td>\n",
       "      <td>2</td>\n",
       "      <td>3.934254e+09</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>500.000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Flywheel</td>\n",
       "      <td>2</td>\n",
       "      <td>7.594242e+08</td>\n",
       "      <td>200.0</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>183.816</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       tech  status           NPV  E (MWh_store)    Pch (MW)  Pdis (MW)  \\\n",
       "0       PHS       2  6.914418e+09         5000.0  500.000000    500.000   \n",
       "3  Hydrogen       2  5.484055e+09        20000.0  508.719511    500.000   \n",
       "2   Battery       2  3.934254e+09         1000.0  500.000000    500.000   \n",
       "1  Flywheel       2  7.594242e+08          200.0  200.000000    183.816   \n",
       "\n",
       "   simultaneous_hours_s0  \n",
       "0                      0  \n",
       "3                      0  \n",
       "2                      0  \n",
       "1                      0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No technologies with NPV≈0 in baseline solve.\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# 3) Baseline solves\n",
    "# =========================\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "results = []\n",
    "for tech_name in TECH.keys():\n",
    "    res = solve_one_tech(\n",
    "        tech_name=tech_name,\n",
    "        prices=prices,\n",
    "        surplus=surplus,\n",
    "        scenario_prob=scenario_prob,\n",
    "        dt=dt,\n",
    "        year_scale=year_scale,\n",
    "        discount_rate=discount_rate,\n",
    "        H_years=H_years,\n",
    "        subsidy_years=subsidy_years,\n",
    "        output_flag=1,\n",
    "        time_limit=60.0,\n",
    "        prevent_simultaneous=True,\n",
    "        price_drift_annual=price_drift_annual,\n",
    "    )\n",
    "    results.append(res)\n",
    "\n",
    "summary = pd.DataFrame([{\n",
    "    \"tech\": r[\"tech\"],\n",
    "    \"status\": r[\"status\"],\n",
    "    \"NPV\": r.get(\"npv\", np.nan),\n",
    "    \"E (MWh_store)\": r.get(\"E\", np.nan),\n",
    "    \"Pch (MW)\": r.get(\"Pch\", np.nan),\n",
    "    \"Pdis (MW)\": r.get(\"Pdis\", np.nan),\n",
    "    \"simultaneous_hours_s0\": r.get(\"simultaneous_hours_s0\", np.nan),\n",
    "} for r in results]).sort_values(\"NPV\", ascending=False)\n",
    "\n",
    "display(summary)\n",
    "\n",
    "# -------------------------\n",
    "# Counterfactual diagnostics: if a tech optimises to ~0, force a small build to see why\n",
    "# -------------------------\n",
    "r0_list = [r for r in results if (r.get(\"npv\") is not None) and (abs(float(r.get(\"npv\", 0.0))) < 1e-6)]\n",
    "\n",
    "if len(r0_list) > 0:\n",
    "    print(f\"Found {len(r0_list)} technology(ies) with NPV≈0. Running counterfactual forced-build solves...\")\n",
    "    for r0 in r0_list:\n",
    "        tech_name = r0[\"tech\"]\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(f\"Counterfactual (force 10% of UB) for: {tech_name}\")\n",
    "\n",
    "        rbest = solve_one_tech(\n",
    "            tech_name=tech_name,\n",
    "            prices=prices,\n",
    "            surplus=surplus,\n",
    "            scenario_prob=scenario_prob,\n",
    "            dt=dt,\n",
    "            year_scale=year_scale,\n",
    "            discount_rate=discount_rate,\n",
    "            H_years=H_years,\n",
    "            subsidy_years=subsidy_years,\n",
    "            output_flag=1,\n",
    "            time_limit=60.0,\n",
    "            prevent_simultaneous=True,\n",
    "            force_frac_ub=0.10,\n",
    "            price_drift_annual=price_drift_annual,\n",
    "        )\n",
    "\n",
    "        display(pd.Series((rbest or {}).get(\"npv_breakdown\", {}), name=f\"{tech_name} npv_breakdown\"))\n",
    "        display((rbest or {}).get(\"scenario_breakdown\", pd.DataFrame()).head())\n",
    "else:\n",
    "    print(\"No technologies with NPV≈0 in baseline solve.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8eb3ef1c-29c5-419f-af61-0a0ec33491b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('PHS', 6914418117.602101)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# =========================\n",
    "# 5) Best alternative + its dispatch (scenario 0)\n",
    "# =========================\n",
    "best = max([r for r in results if r[\"npv\"] is not None], key=lambda x: x[\"npv\"])\n",
    "best[\"tech\"], best[\"npv\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4784fe32-d67b-4d7f-b385-bb9ec0b22380",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0ca69f6ce9f4de8a5cc027cf3fe5518",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntText(value=0, description='start t'), IntText(value=24, description='end t'))…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "df = best[\"dispatch_s0\"]\n",
    "\n",
    "t = df[\"t\"].to_numpy()\n",
    "price = df[\"price\"].to_numpy()\n",
    "charge = df[\"charge_MW\"].to_numpy()\n",
    "discharge = df[\"discharge_MW\"].to_numpy()\n",
    "\n",
    "soc_mwh = df[\"soc_MWh\"].to_numpy()\n",
    "soc_pct = df[\"soc_pct\"].to_numpy()\n",
    "\n",
    "t_min = int(np.nanmin(t))\n",
    "t_max = int(np.nanmax(t))\n",
    "\n",
    "default_start = max(t_min, 0)\n",
    "default_end = min(t_max, default_start + 24)\n",
    "if default_end <= default_start:\n",
    "    default_end = min(t_max, default_start + 1)\n",
    "\n",
    "def build_fig():\n",
    "    fig = make_subplots(\n",
    "        rows=3, cols=1,\n",
    "        shared_xaxes=True,\n",
    "        vertical_spacing=0.06,\n",
    "        subplot_titles=(\n",
    "            f\"Scenario 0 price - {best['tech']}\",\n",
    "            f\"Charge / discharge - {best['tech']}\",\n",
    "            f\"State of charge - {best['tech']}\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "    fig.add_trace(go.Scatter(x=t, y=price, mode=\"lines\", name=\"Price (€/MWh)\"), row=1, col=1)\n",
    "    fig.add_trace(go.Scatter(x=t, y=charge, mode=\"lines\", name=\"Charge (MW)\"), row=2, col=1)\n",
    "    fig.add_trace(go.Scatter(x=t, y=discharge, mode=\"lines\", name=\"Discharge (MW)\"), row=2, col=1)\n",
    "    fig.add_trace(go.Scatter(x=t, y=soc_pct, mode=\"lines\", name=\"SOC (%)\"), row=3, col=1)\n",
    "\n",
    "    fig.update_yaxes(title_text=\"€/MWh\", row=1, col=1)\n",
    "    fig.update_yaxes(title_text=\"MW\", row=2, col=1)\n",
    "    fig.update_yaxes(title_text=\"Energy\", row=3, col=1)\n",
    "    fig.update_yaxes(title_text=\"SOC (%)\", row=3, col=1, range=[0, 100])\n",
    "    fig.update_xaxes(title_text=\"t\", row=3, col=1)\n",
    "\n",
    "    fig.update_layout(\n",
    "        hovermode=\"x unified\",\n",
    "        height=850,\n",
    "        legend=dict(orientation=\"h\", yanchor=\"bottom\", y=1.02, xanchor=\"left\", x=0),\n",
    "    )\n",
    "\n",
    "    # Optional: range slider on bottom axis (still useful in addition to manual range)\n",
    "    fig.update_xaxes(rangeslider_visible=True, row=3, col=1)\n",
    "    return fig\n",
    "\n",
    "# ---- Controls (start/end inputs + sliders) ----\n",
    "start_box = widgets.IntText(value=default_start, description=\"start t\")\n",
    "end_box   = widgets.IntText(value=default_end, description=\"end t\")\n",
    "\n",
    "start_slider = widgets.IntSlider(\n",
    "    value=default_start, min=t_min, max=t_max-1, step=1,\n",
    "    description=\"start\", continuous_update=False, layout=widgets.Layout(width=\"700px\")\n",
    ")\n",
    "end_slider = widgets.IntSlider(\n",
    "    value=default_end, min=t_min+1, max=t_max, step=1,\n",
    "    description=\"end\", continuous_update=False, layout=widgets.Layout(width=\"700px\")\n",
    ")\n",
    "\n",
    "out = widgets.Output()\n",
    "_lock = {\"busy\": False}\n",
    "\n",
    "def clamp_and_sync(start, end):\n",
    "    start = int(max(t_min, min(start, t_max - 1)))\n",
    "    end   = int(max(start + 1, min(end, t_max)))\n",
    "\n",
    "    # keep end slider feasible\n",
    "    end_slider.min = start + 1\n",
    "    if end < end_slider.min:\n",
    "        end = end_slider.min\n",
    "\n",
    "    return start, end\n",
    "\n",
    "def redraw(start, end):\n",
    "    fig = build_fig()\n",
    "    fig.update_xaxes(range=[start, end])  # applies to all shared x-axes\n",
    "    with out:\n",
    "        clear_output(wait=True)\n",
    "        display(fig)\n",
    "\n",
    "def on_any_change(_):\n",
    "    if _lock[\"busy\"]:\n",
    "        return\n",
    "    _lock[\"busy\"] = True\n",
    "    try:\n",
    "        # take values from boxes (authoritative)\n",
    "        start, end = clamp_and_sync(start_box.value, end_box.value)\n",
    "\n",
    "        # sync everything\n",
    "        start_box.value = start\n",
    "        end_box.value = end\n",
    "        start_slider.value = start\n",
    "        end_slider.value = end\n",
    "\n",
    "        redraw(start, end)\n",
    "    finally:\n",
    "        _lock[\"busy\"] = False\n",
    "\n",
    "def on_slider_change(_):\n",
    "    if _lock[\"busy\"]:\n",
    "        return\n",
    "    _lock[\"busy\"] = True\n",
    "    try:\n",
    "        start, end = clamp_and_sync(start_slider.value, end_slider.value)\n",
    "\n",
    "        start_box.value = start\n",
    "        end_box.value = end\n",
    "        start_slider.value = start\n",
    "        end_slider.value = end\n",
    "\n",
    "        redraw(start, end)\n",
    "    finally:\n",
    "        _lock[\"busy\"] = False\n",
    "\n",
    "start_box.observe(on_any_change, names=\"value\")\n",
    "end_box.observe(on_any_change, names=\"value\")\n",
    "start_slider.observe(on_slider_change, names=\"value\")\n",
    "end_slider.observe(on_slider_change, names=\"value\")\n",
    "\n",
    "# Initial draw\n",
    "start0, end0 = clamp_and_sync(default_start, default_end)\n",
    "start_box.value, end_box.value = start0, end0\n",
    "start_slider.value, end_slider.value = start0, end0\n",
    "redraw(start0, end0)\n",
    "\n",
    "display(widgets.VBox([\n",
    "    widgets.HBox([start_box, end_box]),\n",
    "    start_slider,\n",
    "    end_slider,\n",
    "    out\n",
    "]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8ed9e8d5-5975-4a00-8e8c-e80770c0baed",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float64(2074051.6333318641),\n",
       " np.float64(1451836.143332305),\n",
       " np.float64(551117000.0089428))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "td = TECH[\"Hydrogen\"]\n",
    "df = best[\"dispatch_s0\"]\n",
    "year_scale = 8760/(T*dt)\n",
    "\n",
    "annual_charge_MWh = year_scale * (df[\"charge_MW\"].to_numpy() * dt).sum()\n",
    "annual_h2_MWh_HHV = td[\"eta_ch\"] * annual_charge_MWh\n",
    "annual_h2_subsidy = TECH[\"Hydrogen\"][\"subsidy_on_h2_MWh_HHV\"] * annual_h2_MWh_HHV\n",
    "\n",
    "annual_charge_MWh, annual_h2_MWh_HHV, annual_h2_subsidy\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
